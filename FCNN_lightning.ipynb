{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c9476f48",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#import\n",
    "import math\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import randint\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "448ad181",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#notebook { padding-top:0px !important;margin-left:-30px !important; } .container { width:100% !important; } .end_space { min-height:0px !important; } </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make screen wide\n",
    "from IPython.core.display import display, HTML\n",
    "from IPython import get_ipython as get_ipython\n",
    "display(HTML(\n",
    "    '<style>'\n",
    "        '#notebook { padding-top:0px !important;margin-left:-30px !important; } ' \n",
    "        '.container { width:100% !important; } '\n",
    "        '.end_space { min-height:0px !important; } '\n",
    "    '</style>'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f325ea",
   "metadata": {},
   "source": [
    "# FCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87c50fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss function\n",
    "lr\n",
    "optimizer\n",
    "architecture\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3385a3cf",
   "metadata": {
    "code_folding": [
     0,
     14
    ]
   },
   "outputs": [],
   "source": [
    "class InterpolDataSet(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.len = len(labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        feature = self.features[index]\n",
    "        label = self.labels[index]\n",
    "        return feature, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class InterpolDataModule(pl.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.df = None\n",
    "    \n",
    "    def setup(self, stage):\n",
    "        # data reading\n",
    "        df = pd.read_csv('./data/clasdb_pi_plus_n.txt', delimiter='\\t', header=None)\n",
    "        df.columns = ['Ebeam', 'W', 'Q2', 'cos_theta', 'phi', 'dsigma_dOmega', 'error', 'id']\n",
    "\n",
    "        df.loc[8314:65671, 'Ebeam'] = 5.754\n",
    "        df['phi'] = df.phi.apply(lambda x: math.radians(x))\n",
    "        df = df.drop('id', axis=1)\n",
    "        df = df.iloc[df[['Ebeam', 'W', 'Q2', 'cos_theta', 'phi']].drop_duplicates().index]\n",
    "        self.df = df\n",
    "        \n",
    "        #train test split\n",
    "        feature_data = df[['Ebeam', 'W', 'Q2', 'cos_theta', 'phi']]\n",
    "        label_data = df['dsigma_dOmega']\n",
    "        \n",
    "        train_feature_data, test_feature_data, train_label_data, test_label_data = train_test_split(feature_data, label_data, \n",
    "                                                                                                    test_size=0.1, random_state=42)\n",
    "        \n",
    "        \n",
    "        self.train_dataset = InterpolDataSet(torch.tensor(train_feature_data.values, dtype=torch.float32), \n",
    "                                             torch.tensor(train_label_data.values, dtype=torch.float32))\n",
    "        self.test_dataset = InterpolDataSet(torch.tensor(test_feature_data.values, dtype=torch.float32), \n",
    "                                            torch.tensor(test_label_data.values, dtype=torch.float32))\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(dataset = self.train_dataset, batch_size = 8, shuffle = False, num_workers=0)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(dataset = self.test_dataset, batch_size = 8, shuffle = False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3140eb5",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class InterpolRegressor(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(InterpolRegressor, self).__init__()\n",
    "        \n",
    "        input_dim = 5\n",
    "        hidden_dim_1 = 60\n",
    "        hidden_dim_2 = 80\n",
    "        hidden_dim_3 = 100\n",
    "        hidden_dim_4 = 120\n",
    "        hidden_dim_5 = 140\n",
    "        hidden_dim_6 = 100\n",
    "        hidden_dim_7 = 80\n",
    "        hidden_dim_8 = 60\n",
    "        output_dim = 1\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "                    nn.Linear(input_dim, hidden_dim_1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_dim_1, hidden_dim_2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_dim_2, hidden_dim_3),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_dim_3, hidden_dim_4),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_dim_4, hidden_dim_5),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_dim_5, hidden_dim_6),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_dim_6, hidden_dim_7),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_dim_7, hidden_dim_8),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_dim_8, output_dim)\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = nn.MSELoss()\n",
    "        loss = loss(y_hat.reshape(-1), y)\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        global ta\n",
    "        ta = batch\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = nn.MSELoss()\n",
    "        loss = loss(y_hat.reshape(-1), y)\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f462da56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | net  | Sequential | 69.5 K\n",
      "------------------------------------\n",
      "69.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "69.5 K    Total params\n",
      "0.278     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrey.golda/.pyenv/versions/3.9.0/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/andrey.golda/.pyenv/versions/3.9.0/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01722a14c1f34805b2fdb34e3f75d4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrey.golda/.pyenv/versions/3.9.0/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:52: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "data_module = InterpolDataModule()\n",
    "model = InterpolRegressor()\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=3,\n",
    "                     accelerator='cpu')\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a5d0a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.forward(data_module.train_dataset.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a107dcd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0297163"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(preds.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5db84ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
