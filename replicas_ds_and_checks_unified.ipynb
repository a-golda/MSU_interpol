{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-03T23:58:41.510295Z",
     "start_time": "2024-12-03T23:58:39.253530Z"
    }
   },
   "source": [
    "#import\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import tqdm\n",
    "import math\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import lightning.pytorch as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import spatial\n",
    "from scipy.stats import chisquare, kstest\n",
    "from scipy.optimize import curve_fit\n",
    "from torchmetrics import MeanAbsoluteError\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import Callback, LearningRateMonitor, ModelCheckpoint"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "#model\n",
    "hyperparams_dict = {\n",
    "        'energy': 5.754,\n",
    "        'scale_data': False,\n",
    "        'augment': False,\n",
    "        'add_abc': False,\n",
    "        'abc_loss_factor': 1,\n",
    "        'augment_factor': 20,\n",
    "        'test_size': 0.001,\n",
    "        'batch_size': 256,\n",
    "        'net_architecture': [9,60,80,100,120,140,240,340,440,640,2000,1040,640,340,240,140,100,80,60,20,1],\n",
    "        'activation_function': nn.ReLU(),\n",
    "        'loss_func': 'RMSELoss()',\n",
    "        'optim_func': torch.optim.Adam,\n",
    "        'max_epochs': 2000,\n",
    "        'es_min_delta': 0.00001,\n",
    "        'es_patience': 50,\n",
    "        'lr': 0.001,\n",
    "        'lr_factor':0.5,\n",
    "        'lr_patience': 5,\n",
    "        'lr_cooldown': 20,\n",
    "    }\n",
    "\n",
    "if True:\n",
    "    class RMSELoss(torch.nn.Module):\n",
    "        def __init__(self, add_abc=False):\n",
    "            super(RMSELoss,self).__init__()\n",
    "            self.add_abc = add_abc\n",
    "\n",
    "        @staticmethod\n",
    "        def func_cos(x, a, b, c):\n",
    "            return a + b*torch.cos(2*x) + c*torch.cos(x)\n",
    "\n",
    "        def forward(self, x, y_hat, y, w, A, B, C):\n",
    "            if self.add_abc:\n",
    "                phi = x[:, 4]\n",
    "                criterion = torch.sqrt(torch.mean(w*(y_hat - y)**2)/torch.sum(w)) + \\\n",
    "                            torch.mul(hyperparams_dict.get('abc_loss_factor'), torch.mean(torch.abs(w*y - self.func_cos(phi,A,B,C)))/torch.sum(w))\n",
    "            else:\n",
    "                criterion = torch.sqrt(torch.mean(w * (y_hat - y) ** 2) / torch.sum(w))\n",
    "            return criterion\n",
    "\n",
    "    global_losss_function = RMSELoss()\n",
    "\n",
    "    #params\n",
    "    project_name = \"MSU_interpol_unified_notebooks\"\n",
    "\n",
    "    logger_path = './wandb_local_logs'\n",
    "    data_path = './data/clasdb_pi_plus_n.txt'\n",
    "\n",
    "\n",
    "    logger_full_path = os.path.join(logger_path, project_name, 'spring-feather-42')\n",
    "\n",
    "    os.makedirs(logger_full_path, exist_ok=True)\n",
    "    logging.basicConfig(encoding='utf-8',\n",
    "                        level=logging.DEBUG,\n",
    "                        format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                        handlers=[logging.FileHandler(os.path.join(logger_full_path, 'logs.log'), mode='w'),\n",
    "                                  logging.StreamHandler(sys.stdout)],\n",
    "                        force=True)\n",
    "\n",
    "        # define dataset and net\n",
    "    class InterpolDataSet(Dataset):\n",
    "        def __init__(self, features, labels, weights, A, B, C):\n",
    "            self.features = features\n",
    "            self.labels = labels\n",
    "            self.weights = weights\n",
    "            self.A = A\n",
    "            self.B = B\n",
    "            self.C = C\n",
    "            self.len = len(labels)\n",
    "    \n",
    "        def __getitem__(self, index):\n",
    "            feature = self.features[index]\n",
    "            label = self.labels[index]\n",
    "            weights = self.weights[index]\n",
    "            A = self.A[index]\n",
    "            B = self.B[index]\n",
    "            C = self.C[index]\n",
    "            return feature, label, weights, A, B, C\n",
    "    \n",
    "        def __len__(self):\n",
    "            return self.len\n",
    "    \n",
    "    \n",
    "    class InterpolDataModule(pl.LightningDataModule):\n",
    "        def __init__(self, hyperparams):\n",
    "            super().__init__()\n",
    "            self.df = None\n",
    "            self.hyperparams = hyperparams\n",
    "            self.train_dataset = None\n",
    "            self.val_dataset = None\n",
    "    \n",
    "        def augment(self, new_augm):\n",
    "            augm = pd.Series({'Ebeam': np.random.normal(loc=new_augm.Ebeam, scale=new_augm.Ebeam / 30),\n",
    "                              'W': np.random.normal(loc=new_augm.W, scale=new_augm.W / 30),\n",
    "                              'Q2': np.random.normal(loc=new_augm.Q2, scale=new_augm.Q2 / 30),\n",
    "                              'cos_theta': np.clip(\n",
    "                                  np.random.normal(loc=new_augm.cos_theta, scale=abs(new_augm.cos_theta / 30)), -1, 1),\n",
    "                              'phi': np.clip(np.random.normal(loc=new_augm.phi, scale=new_augm.phi / 30), 0, 2 * np.pi),\n",
    "                              'dsigma_dOmega': np.random.normal(loc=new_augm.dsigma_dOmega, scale=new_augm.error / 3),\n",
    "                              'error': new_augm.error,\n",
    "                              'weight': new_augm.weight,\n",
    "                              })\n",
    "            if self.hyperparams.get('add_abc'):\n",
    "                augm['A'] = new_augm.A\n",
    "                augm['B'] = new_augm.B\n",
    "                augm['C'] = new_augm.C\n",
    "            else:\n",
    "                pass\n",
    "            return augm\n",
    "    \n",
    "        @staticmethod\n",
    "        def func_cos(x, a, b, c):\n",
    "            return a + b * np.cos(2 * x) + c * np.cos(x)\n",
    "    \n",
    "        def get_abc(self, df, E_beam, Q2, W, cos_theta):\n",
    "            df_example_set = df[(df.Ebeam == E_beam) &\n",
    "                                (df.W == W) &\n",
    "                                (df.Q2 == Q2) &\n",
    "                                (df.cos_theta == cos_theta)].sort_values('phi')\n",
    "            # input data\n",
    "            xdata = df_example_set.phi\n",
    "            ydata = df_example_set.dsigma_dOmega\n",
    "            ydata_error = df_example_set.error\n",
    "            # fitting the data\n",
    "            popt, pcov = curve_fit(self.func_cos, xdata, ydata, sigma=ydata_error, absolute_sigma=True)\n",
    "            a, b, c = popt[0], popt[1], popt[2]\n",
    "    \n",
    "            return a, b, c\n",
    "    \n",
    "        def setup(self, stage):\n",
    "            # data reading and preprocessing\n",
    "            df = pd.read_csv(data_path, delimiter='\\t', header=None)\n",
    "            df.columns = ['Ebeam', 'W', 'Q2', 'cos_theta', 'phi', 'dsigma_dOmega', 'error', 'id']\n",
    "            df.loc[8314:65671, 'Ebeam'] = 5.754  # peculiarity of this dataset.\n",
    "            df = df[~((df.Ebeam == 5.754) & (~df.Q2.isin([1.715, 2.050, 2.445, 2.915, 3.480, 4.155])))] # peculiarity of this dataset #2\n",
    "            df['phi'] = df.phi.apply(lambda x: math.radians(x))\n",
    "            df['weight'] = df['error'].apply(lambda x: x and 1 / x or 100)  # x and 1 / x or 100  is just a reversed error but with validation 1/0 error in this case it will return 100\n",
    "            df = df.drop('id', axis=1)\n",
    "            df = df.drop_duplicates(subset=['Ebeam', 'W', 'Q2', 'cos_theta', 'phi'])\n",
    "            df['cos_phi'] = df['phi'].apply(lambda x: np.cos(x))\n",
    "            df['sin_phi'] = df['phi'].apply(lambda x: np.sin(x))\n",
    "            df['theta'] = np.arccos(df['cos_theta'])\n",
    "            df['sin_theta'] = np.sin(df.theta)\n",
    "    \n",
    "            df = df[df.Ebeam == hyperparams_dict.get('energy')]\n",
    "    \n",
    "            # #train test split\n",
    "            feature_columns = ['Ebeam', 'W', 'Q2', 'theta', 'cos_theta', 'sin_theta', 'phi', 'cos_phi', 'sin_phi']\n",
    "    \n",
    "            df['A'] = None\n",
    "            df['B'] = None\n",
    "            df['C'] = None\n",
    "            feature_columns_with_additional = ['Ebeam', 'W', 'Q2', 'theta', 'cos_theta', 'sin_theta', 'phi', 'cos_phi', 'sin_phi', 'weight', 'A', 'B', 'C']\n",
    "    \n",
    "            if self.hyperparams.get('add_abc'):\n",
    "                for Ebeam in df.Ebeam.unique():\n",
    "                    for Q2 in tqdm.tqdm(df[df.Ebeam == Ebeam].Q2.unique(), desc='ABC Q cycle'):\n",
    "                        for W in df[(df.Ebeam == Ebeam) & (df.Q2 == Q2)].W.unique():\n",
    "                            for cos_theta in df[(df.Ebeam == Ebeam) & (df.Q2 == Q2) & (df.W == W)].cos_theta.unique():\n",
    "                                try:\n",
    "                                    if df.loc[(df.Ebeam == Ebeam) & (df.Q2 == Q2) & (df.W == W) & (\n",
    "                                            df.cos_theta == cos_theta), 'A'].iloc[0] is None:\n",
    "                                        A, B, C = self.get_abc(df, Ebeam, Q2, W, cos_theta)\n",
    "                                        df.loc[(df.Ebeam == Ebeam) & (df.Q2 == Q2) & (df.W == W) & (\n",
    "                                                df.cos_theta == cos_theta), 'A'] = A\n",
    "                                        df.loc[(df.Ebeam == Ebeam) & (df.Q2 == Q2) & (df.W == W) & (\n",
    "                                                df.cos_theta == cos_theta), 'B'] = B\n",
    "                                        df.loc[(df.Ebeam == Ebeam) & (df.Q2 == Q2) & (df.W == W) & (\n",
    "                                                df.cos_theta == cos_theta), 'C'] = C\n",
    "                                    else:\n",
    "                                        pass\n",
    "                                except Exception as e:\n",
    "                                    df.loc[(df.Ebeam == Ebeam) & (df.Q2 == Q2) & (df.W == W) & (\n",
    "                                            df.cos_theta == cos_theta), 'A'] = 0\n",
    "                                    df.loc[(df.Ebeam == Ebeam) & (df.Q2 == Q2) & (df.W == W) & (\n",
    "                                            df.cos_theta == cos_theta), 'B'] = 0\n",
    "                                    df.loc[(df.Ebeam == Ebeam) & (df.Q2 == Q2) & (df.W == W) & (\n",
    "                                            df.cos_theta == cos_theta), 'C'] = 0\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "            feature_data = df[feature_columns_with_additional]\n",
    "            label_data = df['dsigma_dOmega']\n",
    "    \n",
    "            if self.hyperparams.get('scale_data'):\n",
    "                scaler_feature = StandardScaler()\n",
    "                scaler_target = StandardScaler()\n",
    "                feature_data = scaler_feature.fit_transform(feature_data)\n",
    "                label_data = scaler_target.fit_transform(label_data.values.reshape(-1, 1))\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "            if self.hyperparams.get('augment'):\n",
    "                aug_series_list = []\n",
    "                for i in tqdm.tqdm(df.itertuples()):\n",
    "                    for _ in range(self.hyperparams.get('augment_factor')):\n",
    "                        aug_series_list.append(self.augment(i))\n",
    "    \n",
    "                aug_df = pd.DataFrame(aug_series_list)\n",
    "                df = pd.concat([df, aug_df])\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "            self.df = df\n",
    "    \n",
    "            train_feature_data, val_feature_data, train_label_data, val_label_data = train_test_split(feature_data,\n",
    "                                                                                                      label_data,\n",
    "                                                                                                      test_size=self.hyperparams.get(\n",
    "                                                                                                          'test_size'),\n",
    "                                                                                                      random_state=1438)\n",
    "    \n",
    "            self.train_dataset = InterpolDataSet(\n",
    "                torch.tensor(train_feature_data[feature_columns].values, dtype=torch.float32),\n",
    "                torch.tensor(train_label_data.values, dtype=torch.float32),\n",
    "                torch.tensor(train_feature_data['weight'].values, dtype=torch.float32),\n",
    "                torch.tensor(train_feature_data['A'].astype(float).values, dtype=torch.float32),\n",
    "                torch.tensor(train_feature_data['B'].astype(float).values, dtype=torch.float32),\n",
    "                torch.tensor(train_feature_data['C'].astype(float).values, dtype=torch.float32))\n",
    "    \n",
    "            self.val_dataset = InterpolDataSet(torch.tensor(val_feature_data[feature_columns].values, dtype=torch.float32),\n",
    "                                               torch.tensor(val_label_data.values, dtype=torch.float32),\n",
    "                                               torch.tensor(val_feature_data['weight'].values, dtype=torch.float32),\n",
    "                                               torch.tensor(train_feature_data['A'].astype(float).values,\n",
    "                                                            dtype=torch.float32),\n",
    "                                               torch.tensor(train_feature_data['B'].astype(float).values,\n",
    "                                                            dtype=torch.float32),\n",
    "                                               torch.tensor(train_feature_data['C'].astype(float).values,\n",
    "                                                            dtype=torch.float32))\n",
    "    \n",
    "        def train_dataloader(self):\n",
    "            return DataLoader(dataset=self.train_dataset, batch_size=self.hyperparams.get('batch_size'), shuffle=True,\n",
    "                              num_workers=0)\n",
    "    \n",
    "        def val_dataloader(self):\n",
    "            return DataLoader(dataset=self.val_dataset, batch_size=self.hyperparams.get('batch_size'), shuffle=True,\n",
    "                              num_workers=0)\n",
    "    \n",
    "    \n",
    "    class PrintCallbacks(Callback):\n",
    "        def on_train_start(self, trainer, pl_module):\n",
    "            logging.info(\"Training is starting\")\n",
    "    \n",
    "        def on_train_end(self, trainer, pl_module):\n",
    "            logging.info(\"Training is ending\")\n",
    "    \n",
    "        def on_train_epoch_end(self, trainer, pl_module):\n",
    "            epoch_mean = torch.stack(pl_module.training_step_outputs).mean()\n",
    "            logging.info(f\"epoch: {pl_module.current_epoch}; train_loss: {epoch_mean}\")\n",
    "            pl_module.training_step_outputs.clear()\n",
    "    \n",
    "        def on_validation_epoch_end(self, trainer, pl_module):\n",
    "            epoch_mean = torch.stack(pl_module.validation_step_outputs).mean()\n",
    "            logging.info(f\"epoch: {pl_module.current_epoch}; val_loss: {epoch_mean}\")\n",
    "            pl_module.validation_step_outputs.clear()\n",
    "    \n",
    "    \n",
    "    class InterpolRegressor(pl.LightningModule):\n",
    "        def __init__(self, hyperparams):\n",
    "            super(InterpolRegressor, self).__init__()\n",
    "    \n",
    "            self.train_loss, self.train_mae, self.val_loss, self.val_mae = 0, 0, 0, 0\n",
    "            self.hyperparams = hyperparams\n",
    "            self.save_hyperparameters(self.hyperparams)\n",
    "    \n",
    "            self.mae = MeanAbsoluteError()\n",
    "            self.loss_func = global_losss_function\n",
    "    \n",
    "            self.optim = self.hyperparams.get('optim_func')\n",
    "    \n",
    "            self.net_architecture = self.hyperparams.get('net_architecture')\n",
    "            self.activation_function = self.hyperparams.get('activation_function')\n",
    "    \n",
    "            self.training_step_outputs = []\n",
    "            self.validation_step_outputs = []\n",
    "    \n",
    "            self.net = nn.Sequential()\n",
    "            for i in range(1, len(self.net_architecture)):\n",
    "                self.net.append(nn.Linear(self.net_architecture[i - 1], self.net_architecture[i]))\n",
    "                if i != len(self.net_architecture) - 1:\n",
    "                    self.net.append(self.activation_function)\n",
    "                else:\n",
    "                    pass\n",
    "    \n",
    "        def forward(self, x):\n",
    "            return self.net(x)\n",
    "    \n",
    "        def training_step(self, batch, batch_idx):\n",
    "            x, y, w, A, B, C = batch\n",
    "            y_hat = self.forward(x)\n",
    "    \n",
    "            loss = self.loss_func\n",
    "            self.train_loss = loss.forward(x=x, y_hat=y_hat.reshape(-1), y=y, w=w, A=A, B=B, C=C)\n",
    "            self.train_mae = self.mae(y_hat.reshape(-1), y)\n",
    "    \n",
    "            self.log('train_loss', self.train_loss, batch_size=self.hyperparams['batch_size'],\n",
    "                     on_step=False, on_epoch=True, prog_bar=True, sync_dist=True, logger=True)\n",
    "            self.log('train_mae', self.train_mae, batch_size=self.hyperparams['batch_size'],\n",
    "                     on_step=False, on_epoch=True, prog_bar=True, sync_dist=True, logger=True)\n",
    "    \n",
    "            self.training_step_outputs.append(self.train_loss)\n",
    "            return self.train_loss\n",
    "    \n",
    "        def validation_step(self, batch, batch_idx):\n",
    "            x, y, w, A, B, C = batch\n",
    "            y_hat = self.forward(x)\n",
    "    \n",
    "            loss = self.loss_func\n",
    "            self.val_loss = loss.forward(x=x, y_hat=y_hat.reshape(-1), y=y, w=w, A=A, B=B, C=C)\n",
    "            self.val_mae = self.mae(y_hat.reshape(-1), y)\n",
    "    \n",
    "            self.log('val_loss', self.val_loss, batch_size=self.hyperparams['batch_size'],\n",
    "                     on_step=False, on_epoch=True, prog_bar=True, sync_dist=True, logger=True)\n",
    "            self.log('val_mae', self.val_mae, batch_size=self.hyperparams['batch_size'],\n",
    "                     on_step=False, on_epoch=True, prog_bar=True, sync_dist=True, logger=True)\n",
    "    \n",
    "            self.validation_step_outputs.append(self.val_loss)\n",
    "            return self.val_loss\n",
    "    \n",
    "        def on_validation_epoch_end(self):\n",
    "            sch = self.lr_schedulers()\n",
    "            if isinstance(sch, torch.optim.lr_scheduler.ReduceLROnPlateau) and self.trainer.current_epoch != 0:\n",
    "                sch.step(self.trainer.callback_metrics[\"val_loss\"])\n",
    "    \n",
    "        def configure_callbacks(self):\n",
    "            early_stop_callback = EarlyStopping(monitor=\"val_loss\", mode=\"min\",\n",
    "                                                min_delta=self.hyperparams.get('es_min_delta'),\n",
    "                                                patience=self.hyperparams.get('es_patience'),\n",
    "                                                verbose=True)\n",
    "    \n",
    "            checkpoint_callback = ModelCheckpoint(save_top_k=3,\n",
    "                                                  monitor=\"val_loss\",\n",
    "                                                  mode=\"min\",\n",
    "                                                  dirpath=f\"{logger_full_path}/checkpoints\",\n",
    "                                                  filename=\"{exp_name}{val_loss:.5f}-{epoch:02d}\")\n",
    "    \n",
    "            lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "    \n",
    "            print_callback = PrintCallbacks()\n",
    "    \n",
    "            return [early_stop_callback, checkpoint_callback, print_callback, lr_monitor]\n",
    "    \n",
    "        def configure_optimizers(self):\n",
    "            optimizer = self.optim(self.parameters(), lr=self.hyperparams.get('lr'))\n",
    "            lr_optim = ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                         mode='min',\n",
    "                                         factor=self.hyperparams.get('lr_factor'),\n",
    "                                         patience=self.hyperparams.get('lr_patience'),\n",
    "                                         cooldown=self.hyperparams.get('lr_cooldown'),\n",
    "                                         threshold=0.01,\n",
    "                                         verbose=True)\n",
    "            return {\"optimizer\": optimizer,\n",
    "                    \"lr_scheduler\": {\n",
    "                        \"scheduler\": lr_optim,\n",
    "                        \"interval\": \"epoch\",\n",
    "                        \"monitor\": \"val_loss\",\n",
    "                        \"frequency\": 2,\n",
    "                        \"name\": 'lr_scheduler_monitoring'}\n",
    "                    }\n",
    "\n",
    "    data = InterpolDataModule(hyperparams_dict)\n",
    "    data.setup('test')\n",
    "    df = data.df\n",
    "    df_all = df[['Ebeam', 'W', 'Q2', 'theta', 'cos_theta', 'sin_theta', 'phi', 'cos_phi', 'sin_phi']]\n",
    "    df_target = df[['dsigma_dOmega']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T00:16:36.576843Z",
     "start_time": "2024-12-04T00:16:36.402447Z"
    }
   },
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T00:16:36.758979Z",
     "start_time": "2024-12-04T00:16:36.752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df.drop(['A', 'B', 'C'], axis=1)\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       Ebeam     W     Q2  cos_theta       phi  dsigma_dOmega     error  \\\n",
       "8314   5.754  1.11  1.715       -0.1  0.130900        0.24835  0.081150   \n",
       "8315   5.754  1.11  1.715       -0.1  0.392699        0.31508  0.089290   \n",
       "8316   5.754  1.11  1.715       -0.1  0.654498        0.33037  0.097020   \n",
       "8317   5.754  1.11  1.715       -0.1  0.916298        0.22582  0.059600   \n",
       "8318   5.754  1.11  1.715        0.1  0.130900        0.31506  0.095400   \n",
       "...      ...   ...    ...        ...       ...            ...       ...   \n",
       "65666  5.754  1.15  4.155        0.9  3.403392        0.24095  0.071110   \n",
       "65667  5.754  1.15  4.155        0.9  3.926991        0.19967  0.078718   \n",
       "65668  5.754  1.15  4.155        0.9  4.450590        0.10080  0.037233   \n",
       "65669  5.754  1.15  4.155        0.9  4.974188        0.13921  0.065774   \n",
       "65670  5.754  1.15  4.155        0.9  5.497787        0.15595  0.047991   \n",
       "\n",
       "          weight   cos_phi   sin_phi     theta  sin_theta  \n",
       "8314   12.322859  0.991445  0.130526  1.670964   0.994987  \n",
       "8315   11.199462  0.923880  0.382683  1.670964   0.994987  \n",
       "8316   10.307153  0.793353  0.608761  1.670964   0.994987  \n",
       "8317   16.778523  0.608761  0.793353  1.670964   0.994987  \n",
       "8318   10.482180  0.991445  0.130526  1.470629   0.994987  \n",
       "...          ...       ...       ...       ...        ...  \n",
       "65666  14.062691 -0.965926 -0.258819  0.451027   0.435890  \n",
       "65667  12.703601 -0.707107 -0.707107  0.451027   0.435890  \n",
       "65668  26.857784 -0.258819 -0.965926  0.451027   0.435890  \n",
       "65669  15.203686  0.258819 -0.965926  0.451027   0.435890  \n",
       "65670  20.837285  0.707107 -0.707107  0.451027   0.435890  \n",
       "\n",
       "[41299 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ebeam</th>\n",
       "      <th>W</th>\n",
       "      <th>Q2</th>\n",
       "      <th>cos_theta</th>\n",
       "      <th>phi</th>\n",
       "      <th>dsigma_dOmega</th>\n",
       "      <th>error</th>\n",
       "      <th>weight</th>\n",
       "      <th>cos_phi</th>\n",
       "      <th>sin_phi</th>\n",
       "      <th>theta</th>\n",
       "      <th>sin_theta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8314</th>\n",
       "      <td>5.754</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.715</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.130900</td>\n",
       "      <td>0.24835</td>\n",
       "      <td>0.081150</td>\n",
       "      <td>12.322859</td>\n",
       "      <td>0.991445</td>\n",
       "      <td>0.130526</td>\n",
       "      <td>1.670964</td>\n",
       "      <td>0.994987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8315</th>\n",
       "      <td>5.754</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.715</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.392699</td>\n",
       "      <td>0.31508</td>\n",
       "      <td>0.089290</td>\n",
       "      <td>11.199462</td>\n",
       "      <td>0.923880</td>\n",
       "      <td>0.382683</td>\n",
       "      <td>1.670964</td>\n",
       "      <td>0.994987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8316</th>\n",
       "      <td>5.754</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.715</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.654498</td>\n",
       "      <td>0.33037</td>\n",
       "      <td>0.097020</td>\n",
       "      <td>10.307153</td>\n",
       "      <td>0.793353</td>\n",
       "      <td>0.608761</td>\n",
       "      <td>1.670964</td>\n",
       "      <td>0.994987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8317</th>\n",
       "      <td>5.754</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.715</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.916298</td>\n",
       "      <td>0.22582</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>16.778523</td>\n",
       "      <td>0.608761</td>\n",
       "      <td>0.793353</td>\n",
       "      <td>1.670964</td>\n",
       "      <td>0.994987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8318</th>\n",
       "      <td>5.754</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.715</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.130900</td>\n",
       "      <td>0.31506</td>\n",
       "      <td>0.095400</td>\n",
       "      <td>10.482180</td>\n",
       "      <td>0.991445</td>\n",
       "      <td>0.130526</td>\n",
       "      <td>1.470629</td>\n",
       "      <td>0.994987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65666</th>\n",
       "      <td>5.754</td>\n",
       "      <td>1.15</td>\n",
       "      <td>4.155</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.403392</td>\n",
       "      <td>0.24095</td>\n",
       "      <td>0.071110</td>\n",
       "      <td>14.062691</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.451027</td>\n",
       "      <td>0.435890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65667</th>\n",
       "      <td>5.754</td>\n",
       "      <td>1.15</td>\n",
       "      <td>4.155</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.926991</td>\n",
       "      <td>0.19967</td>\n",
       "      <td>0.078718</td>\n",
       "      <td>12.703601</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.451027</td>\n",
       "      <td>0.435890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65668</th>\n",
       "      <td>5.754</td>\n",
       "      <td>1.15</td>\n",
       "      <td>4.155</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.450590</td>\n",
       "      <td>0.10080</td>\n",
       "      <td>0.037233</td>\n",
       "      <td>26.857784</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.451027</td>\n",
       "      <td>0.435890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65669</th>\n",
       "      <td>5.754</td>\n",
       "      <td>1.15</td>\n",
       "      <td>4.155</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.974188</td>\n",
       "      <td>0.13921</td>\n",
       "      <td>0.065774</td>\n",
       "      <td>15.203686</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.451027</td>\n",
       "      <td>0.435890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65670</th>\n",
       "      <td>5.754</td>\n",
       "      <td>1.15</td>\n",
       "      <td>4.155</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5.497787</td>\n",
       "      <td>0.15595</td>\n",
       "      <td>0.047991</td>\n",
       "      <td>20.837285</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.451027</td>\n",
       "      <td>0.435890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41299 rows × 12 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "source": [
    "model = InterpolRegressor.load_from_checkpoint(f'/Users/andrey.golda/Documents/Study/MSU_interpol/wandb_local_logs/MSU_interpol_unified_notebooks_replication/dauntless-cherry-7/checkpoints/exp_name=0val_loss=0.08474-epoch=63.ckpt', hyperparams=hyperparams_dict)\n",
    "model.eval()\n",
    "type(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T00:16:37.338125Z",
     "start_time": "2024-12-04T00:16:37.216886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-04 00:16:37,228 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/wandb_local_logs/MSU_interpol_unified_notebooks_replication/dauntless-cherry-7/checkpoints/exp_name=0val_loss=0.08474-epoch=63.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'activation_function' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_function'])`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "__main__.InterpolRegressor"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T00:16:38.642826Z",
     "start_time": "2024-12-04T00:16:37.925218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if True:\n",
    "    df_grid_parts = np.array_split(df, \n",
    "                                   100)\n",
    "    df_grid_parts_preds = []\n",
    "    for df_grid_part in tqdm.tqdm(df_grid_parts):\n",
    "        df_grid_part_pred_for_pred = df_grid_part[['Ebeam', 'W', 'Q2', 'theta', 'cos_theta', 'sin_theta', 'phi', 'cos_phi', 'sin_phi']]\n",
    "        dsigma_dOmega_predicted = model.to('cpu').forward(torch.tensor(df_grid_part_pred_for_pred.to_numpy(),dtype=torch.float32)).detach()\n",
    "\n",
    "        df_grid_part['dsigma_dOmega_predicted_stage_1'] = dsigma_dOmega_predicted\n",
    "        df_grid_part['dsigma_dOmega_predicted_stage_1'] = abs(df_grid_part.dsigma_dOmega_predicted_stage_1)\n",
    "        df_grid_parts_preds.append(df_grid_part)\n",
    "\n",
    "    df_grid = pd.concat(df_grid_parts_preds)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "100%|██████████| 100/100 [00:00<00:00, 141.35it/s]\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T10:57:38.337346Z",
     "start_time": "2024-12-04T10:57:23.117714Z"
    }
   },
   "cell_type": "code",
   "source": "df_grid['dsigma_dOmega_replica_stage_2'] = df_grid.apply(lambda x: [np.random.normal(x.dsigma_dOmega_predicted_stage_1, x.error) for _ in range(100)], axis=1)",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T10:58:32.876581Z",
     "start_time": "2024-12-04T10:58:32.182586Z"
    }
   },
   "cell_type": "code",
   "source": "df_grid[[f'dsigma_dOmega_replica_{i}' for i in range(100)]] = pd.DataFrame(df_grid.dsigma_dOmega_replica_stage_2.tolist(), index= df_grid.index)",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tj/2cbzjkv53dj9l4yrll73xw400000gq/T/ipykernel_11103/1928231763.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_grid[[f'dsigma_dOmega_replica_{i}' for i in range(100)]] = pd.DataFrame(df_grid.dsigma_dOmega_replica_stage_2.tolist(), index= df_grid.index)\n",
      "/var/folders/tj/2cbzjkv53dj9l4yrll73xw400000gq/T/ipykernel_11103/1928231763.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_grid[[f'dsigma_dOmega_replica_{i}' for i in range(100)]] = pd.DataFrame(df_grid.dsigma_dOmega_replica_stage_2.tolist(), index= df_grid.index)\n",
      "/var/folders/tj/2cbzjkv53dj9l4yrll73xw400000gq/T/ipykernel_11103/1928231763.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_grid[[f'dsigma_dOmega_replica_{i}' for i in range(100)]] = pd.DataFrame(df_grid.dsigma_dOmega_replica_stage_2.tolist(), index= df_grid.index)\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T11:37:34.649602Z",
     "start_time": "2024-12-04T11:37:34.645782Z"
    }
   },
   "cell_type": "code",
   "source": "df_grid.iloc[1][[f'dsigma_dOmega_replica_{i}' for i in range(100)]].std()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08985430786311903"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T11:40:01.587509Z",
     "start_time": "2024-12-04T11:40:01.578741Z"
    }
   },
   "cell_type": "code",
   "source": "df_grid = df_grid.drop(['dsigma_dOmega_replica_stage_2'], axis=1)",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T11:40:36.166849Z",
     "start_time": "2024-12-04T11:40:33.467027Z"
    }
   },
   "cell_type": "code",
   "source": "df_grid.to_csv('./data/df_replicas.csv', index=False)",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T11:45:40.866704Z",
     "start_time": "2024-12-04T11:45:40.853128Z"
    }
   },
   "cell_type": "code",
   "source": "df_grid.head()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Ebeam     W     Q2  cos_theta       phi  dsigma_dOmega    error  \\\n",
       "8314  5.754  1.11  1.715       -0.1  0.130900        0.24835  0.08115   \n",
       "8315  5.754  1.11  1.715       -0.1  0.392699        0.31508  0.08929   \n",
       "8316  5.754  1.11  1.715       -0.1  0.654498        0.33037  0.09702   \n",
       "8317  5.754  1.11  1.715       -0.1  0.916298        0.22582  0.05960   \n",
       "8318  5.754  1.11  1.715        0.1  0.130900        0.31506  0.09540   \n",
       "\n",
       "         weight   cos_phi   sin_phi  ...  dsigma_dOmega_replica_90  \\\n",
       "8314  12.322859  0.991445  0.130526  ...                  0.456779   \n",
       "8315  11.199462  0.923880  0.382683  ...                  0.379562   \n",
       "8316  10.307153  0.793353  0.608761  ...                  0.338091   \n",
       "8317  16.778523  0.608761  0.793353  ...                  0.301245   \n",
       "8318  10.482180  0.991445  0.130526  ...                  0.159650   \n",
       "\n",
       "      dsigma_dOmega_replica_91  dsigma_dOmega_replica_92  \\\n",
       "8314                  0.242684                  0.355436   \n",
       "8315                  0.188648                  0.086467   \n",
       "8316                  0.323754                  0.253096   \n",
       "8317                  0.164911                  0.230826   \n",
       "8318                  0.247945                  0.207566   \n",
       "\n",
       "      dsigma_dOmega_replica_93  dsigma_dOmega_replica_94  \\\n",
       "8314                  0.132730                  0.263770   \n",
       "8315                  0.278314                  0.335859   \n",
       "8316                  0.254849                  0.166222   \n",
       "8317                  0.369455                  0.374570   \n",
       "8318                  0.199702                  0.245507   \n",
       "\n",
       "      dsigma_dOmega_replica_95  dsigma_dOmega_replica_96  \\\n",
       "8314                  0.229353                  0.246379   \n",
       "8315                  0.334705                  0.362535   \n",
       "8316                  0.174750                  0.346885   \n",
       "8317                  0.356591                  0.323423   \n",
       "8318                  0.232958                  0.120615   \n",
       "\n",
       "      dsigma_dOmega_replica_97  dsigma_dOmega_replica_98  \\\n",
       "8314                  0.186208                  0.248920   \n",
       "8315                  0.322924                  0.388838   \n",
       "8316                  0.449737                  0.189549   \n",
       "8317                  0.298632                  0.335021   \n",
       "8318                  0.336341                  0.288613   \n",
       "\n",
       "      dsigma_dOmega_replica_99  \n",
       "8314                  0.368296  \n",
       "8315                  0.407577  \n",
       "8316                  0.257476  \n",
       "8317                  0.196133  \n",
       "8318                  0.281205  \n",
       "\n",
       "[5 rows x 113 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ebeam</th>\n",
       "      <th>W</th>\n",
       "      <th>Q2</th>\n",
       "      <th>cos_theta</th>\n",
       "      <th>phi</th>\n",
       "      <th>dsigma_dOmega</th>\n",
       "      <th>error</th>\n",
       "      <th>weight</th>\n",
       "      <th>cos_phi</th>\n",
       "      <th>sin_phi</th>\n",
       "      <th>...</th>\n",
       "      <th>dsigma_dOmega_replica_90</th>\n",
       "      <th>dsigma_dOmega_replica_91</th>\n",
       "      <th>dsigma_dOmega_replica_92</th>\n",
       "      <th>dsigma_dOmega_replica_93</th>\n",
       "      <th>dsigma_dOmega_replica_94</th>\n",
       "      <th>dsigma_dOmega_replica_95</th>\n",
       "      <th>dsigma_dOmega_replica_96</th>\n",
       "      <th>dsigma_dOmega_replica_97</th>\n",
       "      <th>dsigma_dOmega_replica_98</th>\n",
       "      <th>dsigma_dOmega_replica_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8314</th>\n",
       "      <td>5.754</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.715</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.130900</td>\n",
       "      <td>0.24835</td>\n",
       "      <td>0.08115</td>\n",
       "      <td>12.322859</td>\n",
       "      <td>0.991445</td>\n",
       "      <td>0.130526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456779</td>\n",
       "      <td>0.242684</td>\n",
       "      <td>0.355436</td>\n",
       "      <td>0.132730</td>\n",
       "      <td>0.263770</td>\n",
       "      <td>0.229353</td>\n",
       "      <td>0.246379</td>\n",
       "      <td>0.186208</td>\n",
       "      <td>0.248920</td>\n",
       "      <td>0.368296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8315</th>\n",
       "      <td>5.754</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.715</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.392699</td>\n",
       "      <td>0.31508</td>\n",
       "      <td>0.08929</td>\n",
       "      <td>11.199462</td>\n",
       "      <td>0.923880</td>\n",
       "      <td>0.382683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379562</td>\n",
       "      <td>0.188648</td>\n",
       "      <td>0.086467</td>\n",
       "      <td>0.278314</td>\n",
       "      <td>0.335859</td>\n",
       "      <td>0.334705</td>\n",
       "      <td>0.362535</td>\n",
       "      <td>0.322924</td>\n",
       "      <td>0.388838</td>\n",
       "      <td>0.407577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8316</th>\n",
       "      <td>5.754</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.715</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.654498</td>\n",
       "      <td>0.33037</td>\n",
       "      <td>0.09702</td>\n",
       "      <td>10.307153</td>\n",
       "      <td>0.793353</td>\n",
       "      <td>0.608761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338091</td>\n",
       "      <td>0.323754</td>\n",
       "      <td>0.253096</td>\n",
       "      <td>0.254849</td>\n",
       "      <td>0.166222</td>\n",
       "      <td>0.174750</td>\n",
       "      <td>0.346885</td>\n",
       "      <td>0.449737</td>\n",
       "      <td>0.189549</td>\n",
       "      <td>0.257476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8317</th>\n",
       "      <td>5.754</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.715</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.916298</td>\n",
       "      <td>0.22582</td>\n",
       "      <td>0.05960</td>\n",
       "      <td>16.778523</td>\n",
       "      <td>0.608761</td>\n",
       "      <td>0.793353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301245</td>\n",
       "      <td>0.164911</td>\n",
       "      <td>0.230826</td>\n",
       "      <td>0.369455</td>\n",
       "      <td>0.374570</td>\n",
       "      <td>0.356591</td>\n",
       "      <td>0.323423</td>\n",
       "      <td>0.298632</td>\n",
       "      <td>0.335021</td>\n",
       "      <td>0.196133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8318</th>\n",
       "      <td>5.754</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.715</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.130900</td>\n",
       "      <td>0.31506</td>\n",
       "      <td>0.09540</td>\n",
       "      <td>10.482180</td>\n",
       "      <td>0.991445</td>\n",
       "      <td>0.130526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159650</td>\n",
       "      <td>0.247945</td>\n",
       "      <td>0.207566</td>\n",
       "      <td>0.199702</td>\n",
       "      <td>0.245507</td>\n",
       "      <td>0.232958</td>\n",
       "      <td>0.120615</td>\n",
       "      <td>0.336341</td>\n",
       "      <td>0.288613</td>\n",
       "      <td>0.281205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 113 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Analysis"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T16:27:26.294692Z",
     "start_time": "2024-12-04T16:27:21.423600Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install matplotlib==3.7.3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib==3.7.3\r\n",
      "  Downloading matplotlib-3.7.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.7 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages (from matplotlib==3.7.3) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages (from matplotlib==3.7.3) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages (from matplotlib==3.7.3) (4.55.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages (from matplotlib==3.7.3) (1.4.7)\r\n",
      "Requirement already satisfied: numpy<2,>=1.20 in /Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages (from matplotlib==3.7.3) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages (from matplotlib==3.7.3) (24.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages (from matplotlib==3.7.3) (11.0.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages (from matplotlib==3.7.3) (3.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages (from matplotlib==3.7.3) (2.9.0.post0)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib==3.7.3) (1.16.0)\r\n",
      "Downloading matplotlib-3.7.3-cp311-cp311-macosx_11_0_arm64.whl (7.3 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.3/7.3 MB\u001B[0m \u001B[31m10.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: matplotlib\r\n",
      "  Attempting uninstall: matplotlib\r\n",
      "    Found existing installation: matplotlib 3.9.3\r\n",
      "    Uninstalling matplotlib-3.9.3:\r\n",
      "      Successfully uninstalled matplotlib-3.9.3\r\n",
      "Successfully installed matplotlib-3.7.3\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T16:29:35.073150Z",
     "start_time": "2024-12-04T16:29:34.896100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "# Load the planets dataset and initialize the figure\n",
    "planets = sns.load_dataset(\"planets\")\n",
    "g = sns.JointGrid(data=planets, x=\"year\", y=\"distance\", marginal_ticks=True)\n",
    "\n",
    "# Set a log scaling on the y axis\n",
    "g.ax_joint.set(yscale=\"log\")\n",
    "\n",
    "# Create an inset legend for the histogram colorbar\n",
    "cax = g.figure.add_axes([.15, .55, .02, .2])\n",
    "\n",
    "# Add the joint and marginal histogram plots\n",
    "g.plot_joint(\n",
    "    sns.histplot, discrete=(True, False),\n",
    "    cmap=\"light:#03012d\", pmax=.8, cbar=True, cbar_ax=cax\n",
    ")\n",
    "g.plot_marginals(sns.histplot, element=\"step\", color=\"#03012d\")"
   ],
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.cm' has no attribute 'register_cmap'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[82], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mseaborn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msns\u001B[39;00m\n\u001B[1;32m      2\u001B[0m sns\u001B[38;5;241m.\u001B[39mset_theme(style\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mticks\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Load the planets dataset and initialize the figure\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/seaborn/__init__.py:9\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcategorical\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# noqa: F401,F403\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistributions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# noqa: F401,F403\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmatrix\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# noqa: F401,F403\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmiscplot\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# noqa: F401,F403\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maxisgrid\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# noqa: F401,F403\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/seaborn/matrix.py:12\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcluster\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m hierarchy\n\u001B[0;32m---> 12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cm\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maxisgrid\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Grid\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     15\u001B[0m     despine,\n\u001B[1;32m     16\u001B[0m     axis_ticklabels_overlap,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     19\u001B[0m     _draw_figure,\n\u001B[1;32m     20\u001B[0m )\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/seaborn/cm.py:1582\u001B[0m\n\u001B[1;32m   1579\u001B[0m     _cmap_r \u001B[38;5;241m=\u001B[39m colors\u001B[38;5;241m.\u001B[39mListedColormap(_lut[::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], _name \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_r\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \n\u001B[1;32m   1580\u001B[0m     \u001B[38;5;28mlocals\u001B[39m()[_name \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_r\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m _cmap_r\n\u001B[0;32m-> 1582\u001B[0m     \u001B[43mmpl_cm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mregister_cmap\u001B[49m(_name, _cmap)\n\u001B[1;32m   1583\u001B[0m     mpl_cm\u001B[38;5;241m.\u001B[39mregister_cmap(_name \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_r\u001B[39m\u001B[38;5;124m\"\u001B[39m, _cmap_r)\n\u001B[1;32m   1585\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m colors, mpl_cm\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'matplotlib.cm' has no attribute 'register_cmap'"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T16:29:45.044219Z",
     "start_time": "2024-12-04T16:29:44.601698Z"
    }
   },
   "cell_type": "code",
   "source": "df_10 = pd.read_csv('./data/replicas/df_replicas_10.csv')",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T16:22:28.679038Z",
     "start_time": "2024-12-04T16:22:28.665506Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       Unnamed: 0  Ebeam     W     Q2  cos_theta       phi  dsigma_dOmega  \\\n",
       "0               0  5.754  1.11  1.715       -0.1  0.130900        0.24835   \n",
       "1               1  5.754  1.11  1.715       -0.1  0.392699        0.31508   \n",
       "2               2  5.754  1.11  1.715       -0.1  0.654498        0.33037   \n",
       "3               3  5.754  1.11  1.715       -0.1  0.916298        0.22582   \n",
       "4               4  5.754  1.11  1.715        0.1  0.130900        0.31506   \n",
       "...           ...    ...   ...    ...        ...       ...            ...   \n",
       "41294       41294  5.754  1.15  4.155        0.9  3.403392        0.24095   \n",
       "41295       41295  5.754  1.15  4.155        0.9  3.926991        0.19967   \n",
       "41296       41296  5.754  1.15  4.155        0.9  4.450590        0.10080   \n",
       "41297       41297  5.754  1.15  4.155        0.9  4.974188        0.13921   \n",
       "41298       41298  5.754  1.15  4.155        0.9  5.497787        0.15595   \n",
       "\n",
       "          error     weight   cos_phi  ...  dsigma_dOmega_replica_prediction_1  \\\n",
       "0      0.081150  12.322859  0.991445  ...                            0.189774   \n",
       "1      0.089290  11.199462  0.923880  ...                            0.201751   \n",
       "2      0.097020  10.307153  0.793353  ...                            0.230827   \n",
       "3      0.059600  16.778523  0.608761  ...                            0.292635   \n",
       "4      0.095400  10.482180  0.991445  ...                            0.229467   \n",
       "...         ...        ...       ...  ...                                 ...   \n",
       "41294  0.071110  14.062691 -0.965926  ...                            0.080917   \n",
       "41295  0.078718  12.703601 -0.707107  ...                            0.085034   \n",
       "41296  0.037233  26.857784 -0.258819  ...                            0.091768   \n",
       "41297  0.065774  15.203686  0.258819  ...                            0.101512   \n",
       "41298  0.047991  20.837285  0.707107  ...                            0.101254   \n",
       "\n",
       "       dsigma_dOmega_replica_prediction_2  dsigma_dOmega_replica_prediction_3  \\\n",
       "0                                0.234991                            0.225459   \n",
       "1                                0.270579                            0.273867   \n",
       "2                                0.341890                            0.354447   \n",
       "3                                0.460999                            0.427862   \n",
       "4                                0.275368                            0.244739   \n",
       "...                                   ...                                 ...   \n",
       "41294                            0.098066                            0.111499   \n",
       "41295                            0.085933                            0.110537   \n",
       "41296                            0.081094                            0.107655   \n",
       "41297                            0.081279                            0.093633   \n",
       "41298                            0.074973                            0.080116   \n",
       "\n",
       "       dsigma_dOmega_replica_prediction_4  dsigma_dOmega_replica_prediction_5  \\\n",
       "0                                0.208386                            0.168591   \n",
       "1                                0.225028                            0.192843   \n",
       "2                                0.275502                            0.235233   \n",
       "3                                0.331879                            0.301013   \n",
       "4                                0.228003                            0.183688   \n",
       "...                                   ...                                 ...   \n",
       "41294                            0.097738                            0.099581   \n",
       "41295                            0.108740                            0.086474   \n",
       "41296                            0.110031                            0.078640   \n",
       "41297                            0.095544                            0.089637   \n",
       "41298                            0.093268                            0.081669   \n",
       "\n",
       "       dsigma_dOmega_replica_prediction_6  dsigma_dOmega_replica_prediction_7  \\\n",
       "0                                0.228682                            0.233257   \n",
       "1                                0.219740                            0.259167   \n",
       "2                                0.256140                            0.280812   \n",
       "3                                0.329214                            0.306513   \n",
       "4                                0.286869                            0.268643   \n",
       "...                                   ...                                 ...   \n",
       "41294                            0.108693                            0.111772   \n",
       "41295                            0.115734                            0.133853   \n",
       "41296                            0.126579                            0.130909   \n",
       "41297                            0.126812                            0.113052   \n",
       "41298                            0.125937                            0.106535   \n",
       "\n",
       "       dsigma_dOmega_replica_prediction_8  dsigma_dOmega_replica_prediction_9  \\\n",
       "0                                0.237077                            0.201193   \n",
       "1                                0.258812                            0.253236   \n",
       "2                                0.290993                            0.318898   \n",
       "3                                0.371696                            0.407954   \n",
       "4                                0.268183                            0.232064   \n",
       "...                                   ...                                 ...   \n",
       "41294                            0.085769                            0.097388   \n",
       "41295                            0.084319                            0.115107   \n",
       "41296                            0.091104                            0.127442   \n",
       "41297                            0.107118                            0.123310   \n",
       "41298                            0.100995                            0.112274   \n",
       "\n",
       "       dsigma_dOmega_replica_prediction_10  \n",
       "0                                 0.229529  \n",
       "1                                 0.256817  \n",
       "2                                 0.300997  \n",
       "3                                 0.369746  \n",
       "4                                 0.258227  \n",
       "...                                    ...  \n",
       "41294                             0.115594  \n",
       "41295                             0.099630  \n",
       "41296                             0.100240  \n",
       "41297                             0.115086  \n",
       "41298                             0.121525  \n",
       "\n",
       "[41299 rows x 125 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Ebeam</th>\n",
       "      <th>W</th>\n",
       "      <th>Q2</th>\n",
       "      <th>cos_theta</th>\n",
       "      <th>phi</th>\n",
       "      <th>dsigma_dOmega</th>\n",
       "      <th>error</th>\n",
       "      <th>weight</th>\n",
       "      <th>cos_phi</th>\n",
       "      <th>...</th>\n",
       "      <th>dsigma_dOmega_replica_prediction_1</th>\n",
       "      <th>dsigma_dOmega_replica_prediction_2</th>\n",
       "      <th>dsigma_dOmega_replica_prediction_3</th>\n",
       "      <th>dsigma_dOmega_replica_prediction_4</th>\n",
       "      <th>dsigma_dOmega_replica_prediction_5</th>\n",
       "      <th>dsigma_dOmega_replica_prediction_6</th>\n",
       "      <th>dsigma_dOmega_replica_prediction_7</th>\n",
       "      <th>dsigma_dOmega_replica_prediction_8</th>\n",
       "      <th>dsigma_dOmega_replica_prediction_9</th>\n",
       "      <th>dsigma_dOmega_replica_prediction_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.754</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.715</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.130900</td>\n",
       "      <td>0.24835</td>\n",
       "      <td>0.081150</td>\n",
       "      <td>12.322859</td>\n",
       "      <td>0.991445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189774</td>\n",
       "      <td>0.234991</td>\n",
       "      <td>0.225459</td>\n",
       "      <td>0.208386</td>\n",
       "      <td>0.168591</td>\n",
       "      <td>0.228682</td>\n",
       "      <td>0.233257</td>\n",
       "      <td>0.237077</td>\n",
       "      <td>0.201193</td>\n",
       "      <td>0.229529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.754</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.715</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.392699</td>\n",
       "      <td>0.31508</td>\n",
       "      <td>0.089290</td>\n",
       "      <td>11.199462</td>\n",
       "      <td>0.923880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201751</td>\n",
       "      <td>0.270579</td>\n",
       "      <td>0.273867</td>\n",
       "      <td>0.225028</td>\n",
       "      <td>0.192843</td>\n",
       "      <td>0.219740</td>\n",
       "      <td>0.259167</td>\n",
       "      <td>0.258812</td>\n",
       "      <td>0.253236</td>\n",
       "      <td>0.256817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.754</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.715</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.654498</td>\n",
       "      <td>0.33037</td>\n",
       "      <td>0.097020</td>\n",
       "      <td>10.307153</td>\n",
       "      <td>0.793353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230827</td>\n",
       "      <td>0.341890</td>\n",
       "      <td>0.354447</td>\n",
       "      <td>0.275502</td>\n",
       "      <td>0.235233</td>\n",
       "      <td>0.256140</td>\n",
       "      <td>0.280812</td>\n",
       "      <td>0.290993</td>\n",
       "      <td>0.318898</td>\n",
       "      <td>0.300997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.754</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.715</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.916298</td>\n",
       "      <td>0.22582</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>16.778523</td>\n",
       "      <td>0.608761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292635</td>\n",
       "      <td>0.460999</td>\n",
       "      <td>0.427862</td>\n",
       "      <td>0.331879</td>\n",
       "      <td>0.301013</td>\n",
       "      <td>0.329214</td>\n",
       "      <td>0.306513</td>\n",
       "      <td>0.371696</td>\n",
       "      <td>0.407954</td>\n",
       "      <td>0.369746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.754</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.715</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.130900</td>\n",
       "      <td>0.31506</td>\n",
       "      <td>0.095400</td>\n",
       "      <td>10.482180</td>\n",
       "      <td>0.991445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229467</td>\n",
       "      <td>0.275368</td>\n",
       "      <td>0.244739</td>\n",
       "      <td>0.228003</td>\n",
       "      <td>0.183688</td>\n",
       "      <td>0.286869</td>\n",
       "      <td>0.268643</td>\n",
       "      <td>0.268183</td>\n",
       "      <td>0.232064</td>\n",
       "      <td>0.258227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41294</th>\n",
       "      <td>41294</td>\n",
       "      <td>5.754</td>\n",
       "      <td>1.15</td>\n",
       "      <td>4.155</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.403392</td>\n",
       "      <td>0.24095</td>\n",
       "      <td>0.071110</td>\n",
       "      <td>14.062691</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080917</td>\n",
       "      <td>0.098066</td>\n",
       "      <td>0.111499</td>\n",
       "      <td>0.097738</td>\n",
       "      <td>0.099581</td>\n",
       "      <td>0.108693</td>\n",
       "      <td>0.111772</td>\n",
       "      <td>0.085769</td>\n",
       "      <td>0.097388</td>\n",
       "      <td>0.115594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41295</th>\n",
       "      <td>41295</td>\n",
       "      <td>5.754</td>\n",
       "      <td>1.15</td>\n",
       "      <td>4.155</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.926991</td>\n",
       "      <td>0.19967</td>\n",
       "      <td>0.078718</td>\n",
       "      <td>12.703601</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085034</td>\n",
       "      <td>0.085933</td>\n",
       "      <td>0.110537</td>\n",
       "      <td>0.108740</td>\n",
       "      <td>0.086474</td>\n",
       "      <td>0.115734</td>\n",
       "      <td>0.133853</td>\n",
       "      <td>0.084319</td>\n",
       "      <td>0.115107</td>\n",
       "      <td>0.099630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41296</th>\n",
       "      <td>41296</td>\n",
       "      <td>5.754</td>\n",
       "      <td>1.15</td>\n",
       "      <td>4.155</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.450590</td>\n",
       "      <td>0.10080</td>\n",
       "      <td>0.037233</td>\n",
       "      <td>26.857784</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091768</td>\n",
       "      <td>0.081094</td>\n",
       "      <td>0.107655</td>\n",
       "      <td>0.110031</td>\n",
       "      <td>0.078640</td>\n",
       "      <td>0.126579</td>\n",
       "      <td>0.130909</td>\n",
       "      <td>0.091104</td>\n",
       "      <td>0.127442</td>\n",
       "      <td>0.100240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41297</th>\n",
       "      <td>41297</td>\n",
       "      <td>5.754</td>\n",
       "      <td>1.15</td>\n",
       "      <td>4.155</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.974188</td>\n",
       "      <td>0.13921</td>\n",
       "      <td>0.065774</td>\n",
       "      <td>15.203686</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101512</td>\n",
       "      <td>0.081279</td>\n",
       "      <td>0.093633</td>\n",
       "      <td>0.095544</td>\n",
       "      <td>0.089637</td>\n",
       "      <td>0.126812</td>\n",
       "      <td>0.113052</td>\n",
       "      <td>0.107118</td>\n",
       "      <td>0.123310</td>\n",
       "      <td>0.115086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41298</th>\n",
       "      <td>41298</td>\n",
       "      <td>5.754</td>\n",
       "      <td>1.15</td>\n",
       "      <td>4.155</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5.497787</td>\n",
       "      <td>0.15595</td>\n",
       "      <td>0.047991</td>\n",
       "      <td>20.837285</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101254</td>\n",
       "      <td>0.074973</td>\n",
       "      <td>0.080116</td>\n",
       "      <td>0.093268</td>\n",
       "      <td>0.081669</td>\n",
       "      <td>0.125937</td>\n",
       "      <td>0.106535</td>\n",
       "      <td>0.100995</td>\n",
       "      <td>0.112274</td>\n",
       "      <td>0.121525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41299 rows × 125 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
