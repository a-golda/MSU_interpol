{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ce34e31",
   "metadata": {
    "code_folding": [],
    "ExecuteTime": {
     "end_time": "2024-01-20T17:14:31.459266Z",
     "start_time": "2024-01-20T17:14:31.456198Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import wandb\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "from torchmetrics import MeanAbsoluteError\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import Callback, LearningRateMonitor, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T17:14:31.482241Z",
     "start_time": "2024-01-20T17:14:31.461231Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "94402bc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T00:54:02.062303Z",
     "start_time": "2024-01-19T00:54:02.047207Z"
    }
   },
   "source": [
    "# FCNN"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "class RMSELoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSELoss,self).__init__()\n",
    "\n",
    "    def forward(self,x,y):\n",
    "        criterion = nn.MSELoss()\n",
    "        loss = torch.sqrt(criterion(x, y))\n",
    "        return loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T17:14:31.492421Z",
     "start_time": "2024-01-20T17:14:31.485220Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "192e02bf",
   "metadata": {
    "code_folding": [],
    "ExecuteTime": {
     "end_time": "2024-01-20T17:14:31.496621Z",
     "start_time": "2024-01-20T17:14:31.491986Z"
    }
   },
   "outputs": [],
   "source": [
    "#params\n",
    "project_name = \"MSU_interpol\"\n",
    "\n",
    "logger_path = './wandb_local_logs'\n",
    "data_path = '../data/clasdb_pi_plus_n.txt'\n",
    "\n",
    "hyperparams_dict = {\n",
    "    'scale_data': False,\n",
    "    'test_size': 0.1,\n",
    "    'batch_size': 32,\n",
    "    'net_architecture': [5,10,10,10,10,10,10,1],\n",
    "    'activation_function': nn.ReLU(),\n",
    "    'loss_func': RMSELoss(),\n",
    "    'optim_func': torch.optim.Adam,\n",
    "    'max_epochs': 2000,\n",
    "    'es_min_delta': 0.0001,\n",
    "    'es_patience': 20,\n",
    "    'lr': 0.00001,\n",
    "    'lr_factor':0.5,\n",
    "    'lr_patience': 3,\n",
    "    'lr_cooldown': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:14:31,552 : DEBUG : Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/andrey.golda/Documents/Study/MSU_interpol, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.2"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>./wandb_local_logs/wandb/run-20240120_171431-8fie7fcj</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/msu_ai/msu_interpol/runs/8fie7fcj' target=\"_blank\">leafy-silence-29</a></strong> to <a href='https://wandb.ai/msu_ai/msu_interpol' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/msu_ai/msu_interpol' target=\"_blank\">https://wandb.ai/msu_ai/msu_interpol</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/msu_ai/msu_interpol/runs/8fie7fcj' target=\"_blank\">https://wandb.ai/msu_ai/msu_interpol/runs/8fie7fcj</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb_logger = WandbLogger(project=project_name,\n",
    "                           save_dir=logger_path)\n",
    "exp_name = wandb_logger.experiment.name\n",
    "\n",
    "logger_full_path = os.path.join(logger_path, project_name, exp_name)\n",
    "\n",
    "os.makedirs(logger_full_path, exist_ok=True)\n",
    "logging.basicConfig(encoding='utf-8',\n",
    "                    level=logging.DEBUG,\n",
    "                    format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                    handlers=[logging.FileHandler(os.path.join(logger_full_path, 'logs.log'), mode='w'),\n",
    "                              logging.StreamHandler(sys.stdout)],\n",
    "                    force=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T17:14:32.767833Z",
     "start_time": "2024-01-20T17:14:31.500876Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a4c8bf4",
   "metadata": {
    "code_folding": [
     0,
     14,
     57
    ],
    "ExecuteTime": {
     "end_time": "2024-01-20T17:14:39.442525Z",
     "start_time": "2024-01-20T17:14:39.422359Z"
    }
   },
   "outputs": [],
   "source": [
    "class InterpolDataSet(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.len = len(labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        feature = self.features[index]\n",
    "        label = self.labels[index]\n",
    "        return feature, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class InterpolDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, hyperparams):\n",
    "        super().__init__()\n",
    "        self.df = None\n",
    "        self.hyperparams = hyperparams\n",
    "    \n",
    "    def setup(self, stage):\n",
    "        # data reading and preprocessing\n",
    "        df = pd.read_csv(data_path, delimiter='\\t', header=None)\n",
    "        df.columns = ['Ebeam', 'W', 'Q2', 'cos_theta', 'phi', 'dsigma_dOmega', 'error', 'id']\n",
    "\n",
    "        df.loc[8314:65671, 'Ebeam'] = 5.754 # peculiarity of this dataset.\n",
    "        df['phi'] = df.phi.apply(lambda x: math.radians(x))\n",
    "        df = df.drop('id', axis=1)\n",
    "        df = df.iloc[df[['Ebeam', 'W', 'Q2', 'cos_theta', 'phi']].drop_duplicates().index]\n",
    "        self.df = df\n",
    "        \n",
    "        #train test split\n",
    "        feature_data = df[['Ebeam', 'W', 'Q2', 'cos_theta', 'phi']]\n",
    "        label_data = df['dsigma_dOmega']\n",
    "        \n",
    "        if self.hyperparams.get('scale_data'):\n",
    "            scaler_feature = StandardScaler()\n",
    "            scaler_target = StandardScaler()\n",
    "            feature_data = scaler_feature.fit_transform(feature_data)\n",
    "            label_data = scaler_target.fit_transform(label_data.values.reshape(-1,1))\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        train_feature_data, val_feature_data, train_label_data, val_label_data = train_test_split(feature_data,\n",
    "                                                                                                  label_data,\n",
    "                                                                                                  test_size=self.hyperparams.get('test_size'),\n",
    "                                                                                                  random_state=1438)\n",
    "        \n",
    "        \n",
    "        self.train_dataset = InterpolDataSet(torch.tensor(train_feature_data.values, dtype=torch.float32), \n",
    "                                             torch.tensor(train_label_data.values, dtype=torch.float32))\n",
    "        \n",
    "        self.val_dataset = InterpolDataSet(torch.tensor(val_feature_data.values, dtype=torch.float32), \n",
    "                                            torch.tensor(val_label_data.values, dtype=torch.float32))\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(dataset = self.train_dataset, batch_size = self.hyperparams.get('batch_size'), shuffle = False, num_workers=0)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(dataset = self.val_dataset, batch_size = self.hyperparams.get('batch_size'), shuffle = False, num_workers=0)\n",
    "\n",
    "class PrintCallbacks(Callback):\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        logging.info(\"Training is starting\")\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        logging.info(\"Training is ending\")\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        logging.info(f\"epoch: {pl_module.current_epoch}; train_loss: {pl_module.train_loss}; train_mae: {pl_module.train_mae}\")\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        logging.info(f\"epoch: {pl_module.current_epoch}; val_loss: {pl_module.val_loss}; val_mae: {pl_module.val_mae}\")\n",
    "\n",
    "class InterpolRegressor(pl.LightningModule):\n",
    "    def __init__(self, hyperparams):\n",
    "        super(InterpolRegressor, self).__init__()\n",
    "\n",
    "        self.train_loss, self.train_mae, self.val_loss, self.val_mae = 0,0,0,0\n",
    "        self.hyperparams = hyperparams\n",
    "        self.save_hyperparameters(self.hyperparams)\n",
    "\n",
    "        self.mae = MeanAbsoluteError()\n",
    "        self.loss_func = self.hyperparams.get('loss_func')\n",
    "\n",
    "        self.optim = self.hyperparams.get('optim_func')\n",
    "\n",
    "        self.net_architecture = self.hyperparams.get('net_architecture')\n",
    "        self.activation_function = self.hyperparams.get('activation_function')\n",
    "\n",
    "        self.net = nn.Sequential()\n",
    "        for i in range(1,len(self.net_architecture)):\n",
    "            self.net.append(nn.Linear(self.net_architecture[i-1], self.net_architecture[i]))\n",
    "            if i!=len(self.net_architecture)-1:\n",
    "                self.net.append(self.activation_function)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "\n",
    "        loss = self.loss_func\n",
    "        self.train_loss = loss(y_hat.reshape(-1), y)\n",
    "        self.train_mae = self.mae(y_hat.reshape(-1), y)\n",
    "\n",
    "        self.log('train_loss', self.train_loss, batch_size=self.hyperparams['batch_size'],\n",
    "                 on_step=False, on_epoch=True, prog_bar=True, sync_dist=True, logger=True)\n",
    "        self.log('train_mae', self.train_mae, batch_size=self.hyperparams['batch_size'],\n",
    "                 on_step=False, on_epoch=True, prog_bar=True, sync_dist=True, logger=True)\n",
    "\n",
    "        return self.train_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "\n",
    "        loss = self.loss_func\n",
    "        self.val_loss = loss(y_hat.reshape(-1), y)\n",
    "        self.val_mae = self.mae(y_hat.reshape(-1), y)\n",
    "\n",
    "        self.log('val_loss', self.val_loss, batch_size=self.hyperparams['batch_size'],\n",
    "                 on_step=False, on_epoch=True, prog_bar=True, sync_dist=True, logger=True)\n",
    "        self.log('val_mae', self.val_mae, batch_size=self.hyperparams['batch_size'],\n",
    "                 on_step=False, on_epoch=True, prog_bar=True, sync_dist=True, logger=True)\n",
    "\n",
    "        return self.val_loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        sch = self.lr_schedulers()\n",
    "        if isinstance(sch, torch.optim.lr_scheduler.ReduceLROnPlateau) and self.trainer.current_epoch!=0:\n",
    "                sch.step(self.trainer.callback_metrics[\"val_loss\"])\n",
    "\n",
    "    def configure_callbacks(self):\n",
    "        early_stop_callback = EarlyStopping(monitor=\"val_loss\", mode=\"min\",\n",
    "                                            min_delta=self.hyperparams.get('es_min_delta'),\n",
    "                                            patience=self.hyperparams.get('es_patience'),\n",
    "                                            verbose=True)\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(save_top_k=3,\n",
    "                                              monitor=\"val_loss\",\n",
    "                                              mode=\"min\",\n",
    "                                              dirpath=f\"{logger_full_path}/checkpoints\",\n",
    "                                              filename=\"{exp_name}{val_loss:.5f}-{epoch:02d}\")\n",
    "\n",
    "        lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "\n",
    "        print_callback = PrintCallbacks()\n",
    "\n",
    "        return [early_stop_callback, checkpoint_callback, print_callback, lr_monitor]\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optim(self.parameters(), lr=self.hyperparams.get('lr'))\n",
    "        lr_optim = ReduceLROnPlateau(optimizer = optimizer,\n",
    "                                     mode = 'min',\n",
    "                                     factor = self.hyperparams.get('lr_factor'),\n",
    "                                     patience = self.hyperparams.get('lr_patience'),\n",
    "                                     cooldown=self.hyperparams.get('lr_cooldown'),\n",
    "                                     threshold=0.01,\n",
    "                                     verbose= True)\n",
    "        return {\"optimizer\": optimizer,\n",
    "                \"lr_scheduler\": {\n",
    "                    \"scheduler\": lr_optim,\n",
    "                    \"interval\": \"epoch\",\n",
    "                    \"monitor\": \"val_loss\",\n",
    "                    \"frequency\": 2,\n",
    "                    \"name\": 'lr_scheduler_monitoring'}\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b5babb2",
   "metadata": {
    "code_folding": [],
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T17:20:05.137117Z",
     "start_time": "2024-01-20T17:14:39.826467Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'activation_function' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_function'])`.\n",
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: ModelCheckpoint\n",
      "\n",
      "  | Name                | Type              | Params\n",
      "----------------------------------------------------------\n",
      "0 | mae                 | MeanAbsoluteError | 0     \n",
      "1 | loss_func           | RMSELoss          | 0     \n",
      "2 | activation_function | ReLU              | 0     \n",
      "3 | net                 | Sequential        | 621   \n",
      "----------------------------------------------------------\n",
      "621       Trainable params\n",
      "0         Non-trainable params\n",
      "621       Total params\n",
      "0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:14:40,102 : INFO : epoch: 0; val_loss: 1.0276641845703125; val_mae: 0.9381320476531982\n",
      "2024-01-20 17:14:40,105 : INFO : Training is starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:14:51,039 : INFO : epoch: 0; val_loss: 1.5381301641464233; val_mae: 1.070046305656433\n",
      "2024-01-20 17:14:51,041 : INFO : epoch: 0; train_loss: 2.8323638439178467; train_mae: 1.604421854019165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 2.325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:14:51,050 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=2.32471-epoch=00.ckpt\n",
      "2024-01-20 17:15:01,423 : INFO : epoch: 1; val_loss: 1.3994128704071045; val_mae: 0.8468100428581238\n",
      "2024-01-20 17:15:01,426 : INFO : epoch: 1; train_loss: 2.724168062210083; train_mae: 1.3916921615600586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.122 >= min_delta = 0.0001. New best score: 2.202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:15:01,434 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=2.20231-epoch=01.ckpt\n",
      "2024-01-20 17:15:12,054 : INFO : epoch: 2; val_loss: 1.2062790393829346; val_mae: 0.5968577861785889\n",
      "2024-01-20 17:15:12,057 : INFO : epoch: 2; train_loss: 2.548346996307373; train_mae: 1.1335967779159546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.178 >= min_delta = 0.0001. New best score: 2.024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:15:12,065 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=2.02442-epoch=02.ckpt\n",
      "2024-01-20 17:15:22,470 : INFO : epoch: 3; val_loss: 1.1601380109786987; val_mae: 0.676896333694458\n",
      "2024-01-20 17:15:22,472 : INFO : epoch: 3; train_loss: 2.453669786453247; train_mae: 1.166300654411316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.061 >= min_delta = 0.0001. New best score: 1.963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:15:22,480 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.96319-epoch=03.ckpt\n",
      "2024-01-20 17:15:32,839 : INFO : epoch: 4; val_loss: 1.150251865386963; val_mae: 0.6962525844573975\n",
      "2024-01-20 17:15:32,841 : INFO : epoch: 4; train_loss: 2.426471710205078; train_mae: 1.1695412397384644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.016 >= min_delta = 0.0001. New best score: 1.947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:15:32,848 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.94743-epoch=04.ckpt\n",
      "2024-01-20 17:15:43,424 : INFO : epoch: 5; val_loss: 1.1224920749664307; val_mae: 0.6752683520317078\n",
      "2024-01-20 17:15:43,426 : INFO : epoch: 5; train_loss: 2.394882917404175; train_mae: 1.148201584815979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.026 >= min_delta = 0.0001. New best score: 1.921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:15:43,434 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.92131-epoch=05.ckpt\n",
      "2024-01-20 17:15:53,811 : INFO : epoch: 6; val_loss: 1.092488169670105; val_mae: 0.6648592948913574\n",
      "2024-01-20 17:15:53,813 : INFO : epoch: 6; train_loss: 2.349783420562744; train_mae: 1.130745768547058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.030 >= min_delta = 0.0001. New best score: 1.891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:15:53,826 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.89120-epoch=06.ckpt\n",
      "2024-01-20 17:16:04,263 : INFO : epoch: 7; val_loss: 1.0437260866165161; val_mae: 0.6397899985313416\n",
      "2024-01-20 17:16:04,265 : INFO : epoch: 7; train_loss: 2.280886650085449; train_mae: 1.099838376045227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.045 >= min_delta = 0.0001. New best score: 1.846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:16:04,276 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.84608-epoch=07.ckpt\n",
      "2024-01-20 17:16:14,867 : INFO : epoch: 8; val_loss: 0.9625066518783569; val_mae: 0.590488612651825\n",
      "2024-01-20 17:16:14,870 : INFO : epoch: 8; train_loss: 2.1710727214813232; train_mae: 1.0491924285888672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.071 >= min_delta = 0.0001. New best score: 1.775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:16:14,878 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.77527-epoch=08.ckpt\n",
      "2024-01-20 17:16:29,429 : INFO : epoch: 9; val_loss: 0.8477510809898376; val_mae: 0.533038318157196\n",
      "2024-01-20 17:16:29,436 : INFO : epoch: 9; train_loss: 2.0095202922821045; train_mae: 0.9782376289367676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.098 >= min_delta = 0.0001. New best score: 1.677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:16:29,444 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.67724-epoch=09.ckpt\n",
      "2024-01-20 17:16:40,157 : INFO : epoch: 10; val_loss: 0.6897841691970825; val_mae: 0.45513463020324707\n",
      "2024-01-20 17:16:40,159 : INFO : epoch: 10; train_loss: 1.7822613716125488; train_mae: 0.8657105565071106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.125 >= min_delta = 0.0001. New best score: 1.552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:16:40,166 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.55198-epoch=10.ckpt\n",
      "2024-01-20 17:16:49,828 : INFO : epoch: 11; val_loss: 0.5181042551994324; val_mae: 0.367775559425354\n",
      "2024-01-20 17:16:49,830 : INFO : epoch: 11; train_loss: 1.5205411911010742; train_mae: 0.7395905256271362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.123 >= min_delta = 0.0001. New best score: 1.429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:16:49,838 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.42938-epoch=11.ckpt\n",
      "2024-01-20 17:16:59,376 : INFO : epoch: 12; val_loss: 0.39444679021835327; val_mae: 0.3033277094364166\n",
      "2024-01-20 17:16:59,379 : INFO : epoch: 12; train_loss: 1.2889070510864258; train_mae: 0.6449753642082214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.086 >= min_delta = 0.0001. New best score: 1.344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:16:59,388 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.34354-epoch=12.ckpt\n",
      "2024-01-20 17:17:09,132 : INFO : epoch: 13; val_loss: 0.34733739495277405; val_mae: 0.26875007152557373\n",
      "2024-01-20 17:17:09,134 : INFO : epoch: 13; train_loss: 1.1351332664489746; train_mae: 0.6030600666999817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.046 >= min_delta = 0.0001. New best score: 1.298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:17:09,144 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.29764-epoch=13.ckpt\n",
      "2024-01-20 17:17:18,771 : INFO : epoch: 14; val_loss: 0.34206581115722656; val_mae: 0.27142879366874695\n",
      "2024-01-20 17:17:18,774 : INFO : epoch: 14; train_loss: 1.054915189743042; train_mae: 0.582827091217041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.023 >= min_delta = 0.0001. New best score: 1.274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:17:18,781 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.27428-epoch=14.ckpt\n",
      "2024-01-20 17:17:28,337 : INFO : epoch: 15; val_loss: 0.345528781414032; val_mae: 0.2727820575237274\n",
      "2024-01-20 17:17:28,341 : INFO : epoch: 15; train_loss: 1.0194789171218872; train_mae: 0.5727779865264893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.014 >= min_delta = 0.0001. New best score: 1.260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:17:28,351 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.25988-epoch=15.ckpt\n",
      "2024-01-20 17:17:37,935 : INFO : epoch: 16; val_loss: 0.3485380709171295; val_mae: 0.27589717507362366\n",
      "2024-01-20 17:17:37,939 : INFO : epoch: 16; train_loss: 1.0040379762649536; train_mae: 0.5651742219924927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.011 >= min_delta = 0.0001. New best score: 1.249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:17:37,946 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.24869-epoch=16.ckpt\n",
      "2024-01-20 17:17:47,439 : INFO : epoch: 17; val_loss: 0.3515513837337494; val_mae: 0.2785610854625702\n",
      "2024-01-20 17:17:47,441 : INFO : epoch: 17; train_loss: 0.9987986087799072; train_mae: 0.5559245944023132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.010 >= min_delta = 0.0001. New best score: 1.239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:17:47,449 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.23882-epoch=17.ckpt\n",
      "2024-01-20 17:17:57,392 : INFO : epoch: 18; val_loss: 0.3529449999332428; val_mae: 0.2781612277030945\n",
      "2024-01-20 17:17:57,394 : INFO : epoch: 18; train_loss: 1.0001111030578613; train_mae: 0.5458493828773499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0001. New best score: 1.229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:17:57,401 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.22944-epoch=18.ckpt\n",
      "2024-01-20 17:18:07,034 : INFO : epoch: 19; val_loss: 0.3557144105434418; val_mae: 0.27803537249565125\n",
      "2024-01-20 17:18:07,036 : INFO : epoch: 19; train_loss: 1.0054157972335815; train_mae: 0.5358638167381287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0001. New best score: 1.220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:18:07,044 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.22036-epoch=19.ckpt\n",
      "2024-01-20 17:18:16,668 : INFO : epoch: 20; val_loss: 0.3577132225036621; val_mae: 0.2785890996456146\n",
      "2024-01-20 17:18:16,670 : INFO : epoch: 20; train_loss: 1.012942910194397; train_mae: 0.5281680822372437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.008 >= min_delta = 0.0001. New best score: 1.212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:18:16,678 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.21196-epoch=20.ckpt\n",
      "2024-01-20 17:18:26,205 : INFO : epoch: 21; val_loss: 0.3573082685470581; val_mae: 0.2762609124183655\n",
      "2024-01-20 17:18:26,208 : INFO : epoch: 21; train_loss: 1.022463083267212; train_mae: 0.5227200984954834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.008 >= min_delta = 0.0001. New best score: 1.204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:18:26,214 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.20433-epoch=21.ckpt\n",
      "2024-01-20 17:18:35,778 : INFO : epoch: 22; val_loss: 0.35736486315727234; val_mae: 0.27298539876937866\n",
      "2024-01-20 17:18:35,781 : INFO : epoch: 22; train_loss: 1.03319251537323; train_mae: 0.5188355445861816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.007 >= min_delta = 0.0001. New best score: 1.197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:18:35,790 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.19735-epoch=22.ckpt\n",
      "2024-01-20 17:18:45,392 : INFO : epoch: 23; val_loss: 0.35709908604621887; val_mae: 0.26912832260131836\n",
      "2024-01-20 17:18:45,394 : INFO : epoch: 23; train_loss: 1.0446699857711792; train_mae: 0.515264093875885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.006 >= min_delta = 0.0001. New best score: 1.191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:18:45,402 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.19095-epoch=23.ckpt\n",
      "2024-01-20 17:18:54,876 : INFO : epoch: 24; val_loss: 0.3564703166484833; val_mae: 0.26501819491386414\n",
      "2024-01-20 17:18:54,878 : INFO : epoch: 24; train_loss: 1.0568374395370483; train_mae: 0.5120647549629211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.006 >= min_delta = 0.0001. New best score: 1.185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:18:54,885 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.18506-epoch=24.ckpt\n",
      "2024-01-20 17:19:04,549 : INFO : epoch: 25; val_loss: 0.35558003187179565; val_mae: 0.26080238819122314\n",
      "2024-01-20 17:19:04,552 : INFO : epoch: 25; train_loss: 1.0694001913070679; train_mae: 0.5093611478805542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0001. New best score: 1.180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:19:04,561 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.17959-epoch=25.ckpt\n",
      "Epoch 00038: reducing learning rate of group 0 to 5.0000e-06.\n",
      "2024-01-20 17:19:14,226 : INFO : epoch: 26; val_loss: 0.35634905099868774; val_mae: 0.2585987150669098\n",
      "2024-01-20 17:19:14,228 : INFO : epoch: 26; train_loss: 1.0804847478866577; train_mae: 0.5083147287368774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0001. New best score: 1.177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:19:14,235 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.17660-epoch=26.ckpt\n",
      "2024-01-20 17:19:23,734 : INFO : epoch: 27; val_loss: 0.35642141103744507; val_mae: 0.2573113739490509\n",
      "2024-01-20 17:19:23,736 : INFO : epoch: 27; train_loss: 1.0874470472335815; train_mae: 0.5088363289833069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0001. New best score: 1.174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:19:23,744 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.17407-epoch=27.ckpt\n",
      "2024-01-20 17:19:33,633 : INFO : epoch: 28; val_loss: 0.35650506615638733; val_mae: 0.2572937607765198\n",
      "2024-01-20 17:19:33,635 : INFO : epoch: 28; train_loss: 1.094012975692749; train_mae: 0.5098598003387451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0001. New best score: 1.172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:19:33,643 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.17165-epoch=28.ckpt\n",
      "2024-01-20 17:19:43,130 : INFO : epoch: 29; val_loss: 0.35663941502571106; val_mae: 0.25716981291770935\n",
      "Epoch 00043: reducing learning rate of group 0 to 2.5000e-06.\n",
      "2024-01-20 17:19:43,133 : INFO : epoch: 29; train_loss: 1.100136160850525; train_mae: 0.5106692314147949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0001. New best score: 1.169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:19:43,139 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.16938-epoch=29.ckpt\n",
      "2024-01-20 17:19:52,662 : INFO : epoch: 30; val_loss: 0.357309490442276; val_mae: 0.2578487694263458\n",
      "2024-01-20 17:19:52,664 : INFO : epoch: 30; train_loss: 1.1050198078155518; train_mae: 0.511613130569458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 1.168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:19:52,671 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/leafy-silence-29/checkpoints/exp_name=0val_loss=1.16815-epoch=30.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "data_module = InterpolDataModule(hyperparams=hyperparams_dict)\n",
    "model = InterpolRegressor(hyperparams=hyperparams_dict)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=hyperparams_dict.get('max_epochs'),\n",
    "                     accelerator='cpu',\n",
    "                     logger=wandb_logger,\n",
    "                     enable_progress_bar=False)\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f33d989",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T17:20:18.469715Z",
     "start_time": "2024-01-20T17:20:05.142611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ccf2327ee5bb4cbda481bd53359444d0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "W&B sync reduced upload amount by 7.2%             "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>lr_scheduler_monitoring</td><td>██████████████████████████▃▃▃▃▁▁</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▆▅▅▅▄▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mae</td><td>█▇▅▄▄▄▄▄▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▇▆▆▆▆▅▅▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_mae</td><td>█▆▄▄▄▄▄▄▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr_scheduler_monitoring</td><td>0.0</td></tr><tr><td>train_loss</td><td>1.19745</td></tr><tr><td>train_mae</td><td>0.58877</td></tr><tr><td>trainer/global_step</td><td>81468</td></tr><tr><td>val_loss</td><td>1.16815</td></tr><tr><td>val_mae</td><td>0.57397</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">leafy-silence-29</strong> at: <a href='https://wandb.ai/msu_ai/msu_interpol/runs/8fie7fcj' target=\"_blank\">https://wandb.ai/msu_ai/msu_interpol/runs/8fie7fcj</a><br/> View job at <a href='https://wandb.ai/msu_ai/msu_interpol/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEzMDk2MzQ1OQ==/version_details/v8' target=\"_blank\">https://wandb.ai/msu_ai/msu_interpol/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEzMDk2MzQ1OQ==/version_details/v8</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb_local_logs/wandb/run-20240120_171431-8fie7fcj/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 17:20:17,792 : DEBUG : Starting new HTTPS connection (17): o151352.ingest.sentry.io:443\n",
      "2024-01-20 17:20:17,893 : DEBUG : Incremented Retry for (url='/api/4504800232407040/envelope/'): Retry(total=2, connect=None, read=None, redirect=None, status=None)\n",
      "2024-01-20 17:20:17,894 : WARNING : Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1002)'))': /api/4504800232407040/envelope/\n",
      "2024-01-20 17:20:17,895 : DEBUG : Starting new HTTPS connection (18): o151352.ingest.sentry.io:443\n",
      "2024-01-20 17:20:17,963 : DEBUG : Incremented Retry for (url='/api/4504800232407040/envelope/'): Retry(total=1, connect=None, read=None, redirect=None, status=None)\n",
      "2024-01-20 17:20:17,965 : WARNING : Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1002)'))': /api/4504800232407040/envelope/\n",
      "2024-01-20 17:20:17,966 : DEBUG : Starting new HTTPS connection (19): o151352.ingest.sentry.io:443\n",
      "2024-01-20 17:20:18,056 : DEBUG : Incremented Retry for (url='/api/4504800232407040/envelope/'): Retry(total=0, connect=None, read=None, redirect=None, status=None)\n",
      "2024-01-20 17:20:18,057 : WARNING : Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1002)'))': /api/4504800232407040/envelope/\n",
      "2024-01-20 17:20:18,058 : DEBUG : Starting new HTTPS connection (20): o151352.ingest.sentry.io:443\n",
      "2024-01-20 17:20:18,127 : DEBUG : Starting new HTTPS connection (21): o151352.ingest.sentry.io:443\n",
      "2024-01-20 17:20:18,198 : DEBUG : Incremented Retry for (url='/api/4504800232407040/envelope/'): Retry(total=2, connect=None, read=None, redirect=None, status=None)\n",
      "2024-01-20 17:20:18,199 : WARNING : Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1002)'))': /api/4504800232407040/envelope/\n",
      "2024-01-20 17:20:18,201 : DEBUG : Starting new HTTPS connection (22): o151352.ingest.sentry.io:443\n",
      "2024-01-20 17:20:18,292 : DEBUG : Incremented Retry for (url='/api/4504800232407040/envelope/'): Retry(total=1, connect=None, read=None, redirect=None, status=None)\n",
      "2024-01-20 17:20:18,293 : WARNING : Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1002)'))': /api/4504800232407040/envelope/\n",
      "2024-01-20 17:20:18,294 : DEBUG : Starting new HTTPS connection (23): o151352.ingest.sentry.io:443\n",
      "2024-01-20 17:20:18,394 : DEBUG : Incremented Retry for (url='/api/4504800232407040/envelope/'): Retry(total=0, connect=None, read=None, redirect=None, status=None)\n",
      "2024-01-20 17:20:18,395 : WARNING : Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1002)'))': /api/4504800232407040/envelope/\n",
      "2024-01-20 17:20:18,396 : DEBUG : Starting new HTTPS connection (24): o151352.ingest.sentry.io:443\n"
     ]
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
