{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daf713df",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#import\n",
    "import math\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import lightning.pytorch as pl\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f493366",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#notebook { padding-top:0px !important;margin-left:-30px !important; } .container { width:100% !important; } .end_space { min-height:0px !important; } </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make screen wide\n",
    "from IPython.core.display import display, HTML\n",
    "from IPython import get_ipython as get_ipython\n",
    "display(HTML(\n",
    "    '<style>'\n",
    "        '#notebook { padding-top:0px !important;margin-left:-30px !important; } ' \n",
    "        '.container { width:100% !important; } '\n",
    "        '.end_space { min-height:0px !important; } '\n",
    "    '</style>'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd33fa6",
   "metadata": {},
   "source": [
    "# FCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed5a57fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_path = './csv_logs'\n",
    "data_path = '../data/clasdb_pi_plus_n.txt'\n",
    "\n",
    "name_of_the_experiment = 'first'\n",
    "logger_version = '1.0001'\n",
    "\n",
    "\n",
    "scale_data = False\n",
    "test_size = 0.1\n",
    "batch_size = 16\n",
    "\n",
    "hyperparams_dict = {\n",
    "    'scale_data': scale_data,\n",
    "    'test_size': test_size,\n",
    "    'batch_size': batch_size,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "915d702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = CSVLogger(save_dir=logger_path, \n",
    "                   name=name_of_the_experiment,\n",
    "                   version=logger_version)\n",
    "\n",
    "logger.log_hyperparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaed7855",
   "metadata": {
    "code_folding": [
     0,
     14
    ]
   },
   "outputs": [],
   "source": [
    "class InterpolDataSet(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.len = len(labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        feature = self.features[index]\n",
    "        label = self.labels[index]\n",
    "        return feature, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class InterpolDataModule(pl.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.df = None\n",
    "    \n",
    "    def setup(self, stage):\n",
    "        # data reading and preprocessing\n",
    "        df = pd.read_csv(data_path, delimiter='\\t', header=None)\n",
    "        df.columns = ['Ebeam', 'W', 'Q2', 'cos_theta', 'phi', 'dsigma_dOmega', 'error', 'id']\n",
    "\n",
    "        df.loc[8314:65671, 'Ebeam'] = 5.754 # peculiarity of this dataset.\n",
    "        df['phi'] = df.phi.apply(lambda x: math.radians(x))\n",
    "        df = df.drop('id', axis=1)\n",
    "        df = df.iloc[df[['Ebeam', 'W', 'Q2', 'cos_theta', 'phi']].drop_duplicates().index]\n",
    "        self.df = df\n",
    "        \n",
    "        #train test split\n",
    "        feature_data = df[['Ebeam', 'W', 'Q2', 'cos_theta', 'phi']]\n",
    "        label_data = df['dsigma_dOmega']\n",
    "        \n",
    "        if scale_data:\n",
    "            scaler_feature = StandardScaler()\n",
    "            scaler_target = StandardScaler()\n",
    "            feature_data = scaler_feature.fit_transform(feature_data)\n",
    "            label_data = scaler_target.fit_transform(label_data.values.reshape(-1,1))\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        train_feature_data, test_feature_data, train_label_data, test_label_data = train_test_split(feature_data, label_data, \n",
    "                                                                                                    test_size=test_size, random_state=1438)\n",
    "        \n",
    "        \n",
    "        self.train_dataset = InterpolDataSet(torch.tensor(train_feature_data.values, dtype=torch.float32), \n",
    "                                             torch.tensor(train_label_data.values, dtype=torch.float32))\n",
    "        self.test_dataset = InterpolDataSet(torch.tensor(test_feature_data.values, dtype=torch.float32), \n",
    "                                            torch.tensor(test_label_data.values, dtype=torch.float32))\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(dataset = self.train_dataset, batch_size = batch_size, shuffle = False, num_workers=0)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(dataset = self.test_dataset, batch_size = batch_size, shuffle = False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b60cd3d",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class InterpolRegressor(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(InterpolRegressor, self).__init__()\n",
    "        \n",
    "        input_dim = 5\n",
    "        hidden_dim_1 = 60\n",
    "        hidden_dim_2 = 80\n",
    "        hidden_dim_3 = 100\n",
    "        hidden_dim_4 = 120\n",
    "        hidden_dim_5 = 140\n",
    "        hidden_dim_6 = 140\n",
    "        hidden_dim_7 = 140\n",
    "        hidden_dim_8 = 140\n",
    "        hidden_dim_9 = 100\n",
    "        hidden_dim_10 = 80\n",
    "        hidden_dim_11 = 60\n",
    "        output_dim = 1\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "                    nn.Linear(input_dim, hidden_dim_1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_dim_1, hidden_dim_2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_dim_2, hidden_dim_3),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_dim_3, hidden_dim_4),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_dim_4, hidden_dim_5),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_dim_5, hidden_dim_6),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_dim_6, hidden_dim_7),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_dim_7, hidden_dim_8),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_dim_8, hidden_dim_9),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_dim_9, hidden_dim_10),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_dim_10, hidden_dim_11),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_dim_11, output_dim)\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = nn.MSELoss()\n",
    "        loss = loss(y_hat.reshape(-1), y)\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        global ta\n",
    "        ta = batch\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = nn.MSELoss()\n",
    "        loss = loss(y_hat.reshape(-1), y)\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86b4fb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | net  | Sequential | 128 K \n",
      "------------------------------------\n",
      "128 K     Trainable params\n",
      "0         Non-trainable params\n",
      "128 K     Total params\n",
      "0.515     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrey.golda/.pyenv/versions/3.9.0/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/Users/andrey.golda/.pyenv/versions/3.9.0/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6451a4fb11174f4da2982524b763a648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrey.golda/.pyenv/versions/3.9.0/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "data_module = InterpolDataModule()\n",
    "model = InterpolRegressor()\n",
    "\n",
    "early_stop_callback = [EarlyStopping(monitor=\"val_loss\", mode=\"min\", min_delta=0.005, patience=2, verbose=True)]\n",
    "trainer = pl.Trainer(max_epochs=1000,\n",
    "                     accelerator='cpu',\n",
    "                     callbacks=early_stop_callback)\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81131e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8475419"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.forward(data_module.train_dataset.features)\n",
    "mean_squared_error(data_module.train_dataset.labels, preds.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "033289b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7896977"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.forward(data_module.test_dataset.features)\n",
    "mean_squared_error(data_module.test_dataset.labels, preds.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b6d23d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "# lr\n",
    "# optimizer\n",
    "# architecture\n",
    "# batch_size\n",
    "# early_stopping - min_delta, patience"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
