{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9309cf61",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#import\n",
    "import math\n",
    "import torch\n",
    "import torchmetrics\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import lightning.pytorch as pl\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e16cd3a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#notebook { padding-top:0px !important;margin-left:-30px !important; } .container { width:100% !important; } .end_space { min-height:0px !important; } </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make screen wide\n",
    "from IPython.core.display import display, HTML\n",
    "from IPython import get_ipython as get_ipython\n",
    "display(HTML(\n",
    "    '<style>'\n",
    "        '#notebook { padding-top:0px !important;margin-left:-30px !important; } ' \n",
    "        '.container { width:100% !important; } '\n",
    "        '.end_space { min-height:0px !important; } '\n",
    "    '</style>'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a26aa4",
   "metadata": {},
   "source": [
    "# FCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c867e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_path = './csv_logs'\n",
    "data_path = '../data/clasdb_pi_plus_n.txt'\n",
    "\n",
    "name_of_the_experiment = 'first'\n",
    "logger_version = '1.0015'\n",
    "\n",
    "\n",
    "scale_data = False\n",
    "test_size = 0.1\n",
    "batch_size = 16\n",
    "net_architecture = [5, 60, 80, 100, 120, 140, 140, 140, 140, 140, 140, 140, 140, 140, 100, 80, 60, 20, 1]\n",
    "lr = 0.00005\n",
    "activation_function = nn.ReLU()\n",
    "loss_func = RMSELoss()\n",
    "optim_func = 'ADAM'\n",
    "max_epochs = 2000\n",
    "min_delta = 0.0001\n",
    "patience = 20\n",
    "\n",
    "hyperparams_dict = {\n",
    "    'scale_data': scale_data,\n",
    "    'test_size': test_size,\n",
    "    'batch_size': batch_size,\n",
    "    'lr': lr,\n",
    "    'net_architecture': net_architecture,\n",
    "    'activation_function': activation_function,\n",
    "    'loss_func': loss_func,\n",
    "    'optim_func': optim_func,\n",
    "    'max_epochs': max_epochs,\n",
    "    'min_delta': min_delta,\n",
    "    'patience': patience\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0398dc5",
   "metadata": {
    "code_folding": [
     0,
     14,
     57
    ]
   },
   "outputs": [],
   "source": [
    "class InterpolDataSet(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.len = len(labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        feature = self.features[index]\n",
    "        label = self.labels[index]\n",
    "        return feature, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class InterpolDataModule(pl.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.df = None\n",
    "    \n",
    "    def setup(self, stage):\n",
    "        # data reading and preprocessing\n",
    "        df = pd.read_csv(data_path, delimiter='\\t', header=None)\n",
    "        df.columns = ['Ebeam', 'W', 'Q2', 'cos_theta', 'phi', 'dsigma_dOmega', 'error', 'id']\n",
    "\n",
    "        df.loc[8314:65671, 'Ebeam'] = 5.754 # peculiarity of this dataset.\n",
    "        df['phi'] = df.phi.apply(lambda x: math.radians(x))\n",
    "        df = df.drop('id', axis=1)\n",
    "        df = df.iloc[df[['Ebeam', 'W', 'Q2', 'cos_theta', 'phi']].drop_duplicates().index]\n",
    "        self.df = df\n",
    "        \n",
    "        #train test split\n",
    "        feature_data = df[['Ebeam', 'W', 'Q2', 'cos_theta', 'phi']]\n",
    "        label_data = df['dsigma_dOmega']\n",
    "        \n",
    "        if scale_data:\n",
    "            scaler_feature = StandardScaler()\n",
    "            scaler_target = StandardScaler()\n",
    "            feature_data = scaler_feature.fit_transform(feature_data)\n",
    "            label_data = scaler_target.fit_transform(label_data.values.reshape(-1,1))\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        train_feature_data, test_feature_data, train_label_data, test_label_data = train_test_split(feature_data, label_data, \n",
    "                                                                                                    test_size=test_size, random_state=1438)\n",
    "        \n",
    "        \n",
    "        self.train_dataset = InterpolDataSet(torch.tensor(train_feature_data.values, dtype=torch.float32), \n",
    "                                             torch.tensor(train_label_data.values, dtype=torch.float32))\n",
    "        self.test_dataset = InterpolDataSet(torch.tensor(test_feature_data.values, dtype=torch.float32), \n",
    "                                            torch.tensor(test_label_data.values, dtype=torch.float32))\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(dataset = self.train_dataset, batch_size = batch_size, shuffle = False, num_workers=0)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(dataset = self.test_dataset, batch_size = batch_size, shuffle = False, num_workers=0)\n",
    "    \n",
    "class RMSELoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSELoss,self).__init__()\n",
    "\n",
    "    def forward(self,x,y):\n",
    "        criterion = nn.MSELoss()\n",
    "        loss = torch.sqrt(criterion(x, y))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5a9cbcc",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class InterpolRegressor(pl.LightningModule):\n",
    "    def __init__(self, hyperparams):\n",
    "        super(InterpolRegressor, self).__init__()\n",
    "        \n",
    "        self.hyperparams = hyperparams\n",
    "        self.loss_func = self.hyperparams.get('loss_func')\n",
    "        self.net_architecture = self.hyperparams.get('net_architecture')\n",
    "        self.activation_function = self.hyperparams.get('activation_function')\n",
    "        self.net = nn.Sequential()\n",
    "        self.train_loss = 0\n",
    "        self.val_loss = 0\n",
    "                \n",
    "        for i in range(1,len(self.net_architecture)):\n",
    "            self.net.append(nn.Linear(self.net_architecture[i-1], self.net_architecture[i]))\n",
    "            if i!=len(self.net_architecture)-1:\n",
    "                self.net.append(self.activation_function)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        self.save_hyperparameters()\n",
    "        logger.log_hyperparams(self.hyperparams)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss_func\n",
    "        self.train_loss = loss(y_hat.reshape(-1), y)\n",
    "        self.log('train_loss', self.train_loss, on_step=False, on_epoch=True, prog_bar=False)\n",
    "        return self.train_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss_func\n",
    "        self.val_loss = loss(y_hat.reshape(-1), y)\n",
    "        self.log('val_loss', self.val_loss, on_step=False, on_epoch=True, prog_bar=False)\n",
    "        return self.val_loss\n",
    "    \n",
    "#     def on_train_epoch_end(self):\n",
    "#         self.log('train_loss', self.train_loss, on_step=False, on_epoch=True, prog_bar=False)\n",
    "\n",
    "#     def on_validation_epoch_end(self):\n",
    "#         self.log('step', self.trainer.current_epoch)\n",
    "#         self.log('val_loss', self.val_loss, on_step=False, on_epoch=True, prog_bar=False)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f8e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e2b2b1a",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrey.golda/.pyenv/versions/3.9.0/lib/python3.9/site-packages/lightning/fabric/loggers/csv_logs.py:198: Experiment logs directory ./csv_logs/first/1.0015 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "/Users/andrey.golda/.pyenv/versions/3.9.0/lib/python3.9/site-packages/lightning/pytorch/utilities/parsing.py:43: attribute 'hyperparams' removed from hparams because it cannot be pickled\n",
      "/Users/andrey.golda/.pyenv/versions/3.9.0/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:639: Checkpoint directory ./csv_logs/first/1.0015/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name                | Type       | Params\n",
      "---------------------------------------------------\n",
      "0 | loss_func           | RMSELoss   | 0     \n",
      "1 | activation_function | ReLU       | 0     \n",
      "2 | net                 | Sequential | 228 K \n",
      "---------------------------------------------------\n",
      "228 K     Trainable params\n",
      "0         Non-trainable params\n",
      "228 K     Total params\n",
      "0.914     Total estimated model params size (MB)\n",
      "/Users/andrey.golda/.pyenv/versions/3.9.0/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/Users/andrey.golda/.pyenv/versions/3.9.0/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/Users/andrey.golda/.pyenv/versions/3.9.0/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "data_module = InterpolDataModule()\n",
    "logger = CSVLogger(save_dir=logger_path, \n",
    "                   name=name_of_the_experiment,\n",
    "                   version=logger_version)\n",
    "model = InterpolRegressor(hyperparams=hyperparams_dict)\n",
    "\n",
    "early_stop_callback = [EarlyStopping(monitor=\"val_loss\", mode=\"min\", min_delta=min_delta, patience=patience, verbose=True)]\n",
    "trainer = pl.Trainer(max_epochs=max_epochs,\n",
    "                     accelerator='cpu',\n",
    "                     callbacks=early_stop_callback,\n",
    "                     logger=logger,\n",
    "                     enable_progress_bar=False,\n",
    "                     val_check_interval = 1)\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70482b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0293056"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.forward(data_module.train_dataset.features)\n",
    "mean_squared_error(data_module.train_dataset.labels, preds.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e0d5f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9479398"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.forward(data_module.test_dataset.features)\n",
    "mean_squared_error(data_module.test_dataset.labels, preds.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46c1b9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>step</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.780708</td>\n",
       "      <td>5255</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5255</td>\n",
       "      <td>0</td>\n",
       "      <td>0.813510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.780709</td>\n",
       "      <td>10511</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10511</td>\n",
       "      <td>1</td>\n",
       "      <td>0.813444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.780724</td>\n",
       "      <td>15767</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>15767</td>\n",
       "      <td>2</td>\n",
       "      <td>0.813409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.780734</td>\n",
       "      <td>21023</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>21023</td>\n",
       "      <td>3</td>\n",
       "      <td>0.813390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.780734</td>\n",
       "      <td>26279</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>26279</td>\n",
       "      <td>4</td>\n",
       "      <td>0.813384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.780734</td>\n",
       "      <td>31535</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>31535</td>\n",
       "      <td>5</td>\n",
       "      <td>0.813384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.780734</td>\n",
       "      <td>36791</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>36791</td>\n",
       "      <td>6</td>\n",
       "      <td>0.813384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.780734</td>\n",
       "      <td>42047</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>42047</td>\n",
       "      <td>7</td>\n",
       "      <td>0.813384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.780734</td>\n",
       "      <td>47303</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>47303</td>\n",
       "      <td>8</td>\n",
       "      <td>0.813384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.780734</td>\n",
       "      <td>52559</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>52559</td>\n",
       "      <td>9</td>\n",
       "      <td>0.813384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.780734</td>\n",
       "      <td>57815</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>57815</td>\n",
       "      <td>10</td>\n",
       "      <td>0.813384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.780734</td>\n",
       "      <td>63071</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>63071</td>\n",
       "      <td>11</td>\n",
       "      <td>0.813384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.780734</td>\n",
       "      <td>68327</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>68327</td>\n",
       "      <td>12</td>\n",
       "      <td>0.813384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.780734</td>\n",
       "      <td>73583</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>73583</td>\n",
       "      <td>13</td>\n",
       "      <td>0.813384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.780734</td>\n",
       "      <td>78839</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>78839</td>\n",
       "      <td>14</td>\n",
       "      <td>0.813384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.780734</td>\n",
       "      <td>84095</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>84095</td>\n",
       "      <td>15</td>\n",
       "      <td>0.813384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.780734</td>\n",
       "      <td>89351</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>89351</td>\n",
       "      <td>16</td>\n",
       "      <td>0.813384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.780734</td>\n",
       "      <td>94607</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>94607</td>\n",
       "      <td>17</td>\n",
       "      <td>0.813384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.780734</td>\n",
       "      <td>99863</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>99863</td>\n",
       "      <td>18</td>\n",
       "      <td>0.813384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.780734</td>\n",
       "      <td>105119</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>105119</td>\n",
       "      <td>19</td>\n",
       "      <td>0.813384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    val_loss    step  epoch  train_loss\n",
       "0   0.780708    5255      0         NaN\n",
       "1        NaN    5255      0    0.813510\n",
       "2   0.780709   10511      1         NaN\n",
       "3        NaN   10511      1    0.813444\n",
       "4   0.780724   15767      2         NaN\n",
       "5        NaN   15767      2    0.813409\n",
       "6   0.780734   21023      3         NaN\n",
       "7        NaN   21023      3    0.813390\n",
       "8   0.780734   26279      4         NaN\n",
       "9        NaN   26279      4    0.813384\n",
       "10  0.780734   31535      5         NaN\n",
       "11       NaN   31535      5    0.813384\n",
       "12  0.780734   36791      6         NaN\n",
       "13       NaN   36791      6    0.813384\n",
       "14  0.780734   42047      7         NaN\n",
       "15       NaN   42047      7    0.813384\n",
       "16  0.780734   47303      8         NaN\n",
       "17       NaN   47303      8    0.813384\n",
       "18  0.780734   52559      9         NaN\n",
       "19       NaN   52559      9    0.813384\n",
       "20  0.780734   57815     10         NaN\n",
       "21       NaN   57815     10    0.813384\n",
       "22  0.780734   63071     11         NaN\n",
       "23       NaN   63071     11    0.813384\n",
       "24  0.780734   68327     12         NaN\n",
       "25       NaN   68327     12    0.813384\n",
       "26  0.780734   73583     13         NaN\n",
       "27       NaN   73583     13    0.813384\n",
       "28  0.780734   78839     14         NaN\n",
       "29       NaN   78839     14    0.813384\n",
       "30  0.780734   84095     15         NaN\n",
       "31       NaN   84095     15    0.813384\n",
       "32  0.780734   89351     16         NaN\n",
       "33       NaN   89351     16    0.813384\n",
       "34  0.780734   94607     17         NaN\n",
       "35       NaN   94607     17    0.813384\n",
       "36  0.780734   99863     18         NaN\n",
       "37       NaN   99863     18    0.813384\n",
       "38  0.780734  105119     19         NaN\n",
       "39       NaN  105119     19    0.813384"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = InterpolRegressor.load_from_checkpoint('./csv_logs/first/1.0002/checkpoints/epoch=9-step=52560.ckpt')\n",
    "# model.eval()\n",
    "\n",
    "df = pd.read_csv(f'./csv_logs/first/{logger_version}/metrics.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93b3534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b6afc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57f1ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5577054a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
