{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8ce34e31",
   "metadata": {
    "code_folding": [],
    "ExecuteTime": {
     "end_time": "2024-02-02T16:14:27.031019Z",
     "start_time": "2024-02-02T16:14:27.028583Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import wandb\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "from torchmetrics import MeanAbsoluteError\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import Callback, LearningRateMonitor, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:14:27.319994Z",
     "start_time": "2024-02-02T16:14:27.299344Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "94402bc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T23:58:44.971727Z",
     "start_time": "2024-01-25T23:58:41.434963Z"
    }
   },
   "source": [
    "# FCNN"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: You can find your API key in your browser here: https://wandb.ai/authorize\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \r\n",
      "Aborted!\r\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "class RMSELoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSELoss,self).__init__()\n",
    "\n",
    "    def forward(self,x,y,w):\n",
    "        criterion = nn.MSELoss()\n",
    "        loss = torch.sqrt(criterion(x, y))*w\n",
    "        return loss.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:14:28.140299Z",
     "start_time": "2024-02-02T16:14:28.130185Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "192e02bf",
   "metadata": {
    "code_folding": [],
    "ExecuteTime": {
     "end_time": "2024-02-02T16:14:28.600291Z",
     "start_time": "2024-02-02T16:14:28.592103Z"
    }
   },
   "outputs": [],
   "source": [
    "#params\n",
    "project_name = \"MSU_interpol\"\n",
    "\n",
    "logger_path = './wandb_local_logs'\n",
    "data_path = '../data/clasdb_pi_plus_n.txt'\n",
    "\n",
    "hyperparams_dict = {\n",
    "    'scale_data': False,\n",
    "    'test_size': 0.1,\n",
    "    'batch_size': 32,\n",
    "    'net_architecture': [5,60,80,100,120,140,240,340,440,640,2000,1040,640,340,240,140,100,80,60,20,1],\n",
    "    'activation_function': nn.ReLU(),\n",
    "    'loss_func': RMSELoss(),\n",
    "    'optim_func': torch.optim.Adam,\n",
    "    'max_epochs': 2000,\n",
    "    'es_min_delta': 0.00001,\n",
    "    'es_patience': 20,\n",
    "    'lr': 0.001,\n",
    "    'lr_factor':0.5,\n",
    "    'lr_patience': 5,\n",
    "    'lr_cooldown': 20,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 16:14:29,478 : DEBUG : Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/andrey.golda/Documents/Study/MSU_interpol, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.2"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>./wandb_local_logs/wandb/run-20240202_161429-cizzvejg</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/msu_ai/msu_interpol/runs/cizzvejg' target=\"_blank\">visionary-dew-39</a></strong> to <a href='https://wandb.ai/msu_ai/msu_interpol' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/msu_ai/msu_interpol' target=\"_blank\">https://wandb.ai/msu_ai/msu_interpol</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/msu_ai/msu_interpol/runs/cizzvejg' target=\"_blank\">https://wandb.ai/msu_ai/msu_interpol/runs/cizzvejg</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb_logger = WandbLogger(project=project_name,\n",
    "                           save_dir=logger_path)\n",
    "exp_name = wandb_logger.experiment.name\n",
    "\n",
    "logger_full_path = os.path.join(logger_path, project_name, exp_name)\n",
    "\n",
    "os.makedirs(logger_full_path, exist_ok=True)\n",
    "logging.basicConfig(encoding='utf-8',\n",
    "                    level=logging.DEBUG,\n",
    "                    format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                    handlers=[logging.FileHandler(os.path.join(logger_full_path, 'logs.log'), mode='w'),\n",
    "                              logging.StreamHandler(sys.stdout)],\n",
    "                    force=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:14:30.554788Z",
     "start_time": "2024-02-02T16:14:29.410872Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1a4c8bf4",
   "metadata": {
    "code_folding": [
     0,
     14,
     57
    ],
    "ExecuteTime": {
     "end_time": "2024-02-02T16:14:30.609222Z",
     "start_time": "2024-02-02T16:14:30.589121Z"
    }
   },
   "outputs": [],
   "source": [
    "class InterpolDataSet(Dataset):\n",
    "    def __init__(self, features, labels, weights):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.weights = weights\n",
    "        self.len = len(labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        feature = self.features[index]\n",
    "        label = self.labels[index]\n",
    "        weights = self.weights[index]\n",
    "        return feature, label, weights\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class InterpolDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, hyperparams):\n",
    "        super().__init__()\n",
    "        self.df = None\n",
    "        self.hyperparams = hyperparams\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "    \n",
    "    def setup(self, stage):\n",
    "        # data reading and preprocessing\n",
    "        df = pd.read_csv(data_path, delimiter='\\t', header=None)\n",
    "        df.columns = ['Ebeam', 'W', 'Q2', 'cos_theta', 'phi', 'dsigma_dOmega', 'error', 'id']\n",
    "        df.loc[8314:65671, 'Ebeam'] = 5.754 # peculiarity of this dataset.\n",
    "        df['phi'] = df.phi.apply(lambda x: math.radians(x))\n",
    "        df['weight'] = df['error'].apply(lambda x: x and 1 / x or 100) # x and 1 / x or 100  is just a reversed error but with validation 1/0 error in this case it will return 100\n",
    "        df = df.drop('id', axis=1)\n",
    "        df = df.iloc[df[['Ebeam', 'W', 'Q2', 'cos_theta', 'phi']].drop_duplicates().index]\n",
    "        self.df = df\n",
    "\n",
    "\n",
    "        #train test split\n",
    "        feature_columns = ['Ebeam', 'W', 'Q2', 'cos_theta', 'phi']\n",
    "        feature_columns_with_weights = ['Ebeam', 'W', 'Q2', 'cos_theta', 'phi', 'weight']\n",
    "\n",
    "        feature_data = df[feature_columns_with_weights]\n",
    "        label_data = df['dsigma_dOmega']\n",
    "        \n",
    "        if self.hyperparams.get('scale_data'):\n",
    "            scaler_feature = StandardScaler()\n",
    "            scaler_target = StandardScaler()\n",
    "            feature_data = scaler_feature.fit_transform(feature_data)\n",
    "            label_data = scaler_target.fit_transform(label_data.values.reshape(-1,1))\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        train_feature_data, val_feature_data, train_label_data, val_label_data = train_test_split(feature_data,\n",
    "                                                                                                  label_data,\n",
    "                                                                                                  test_size=self.hyperparams.get('test_size'),\n",
    "                                                                                                  random_state=1438)\n",
    "        \n",
    "        \n",
    "        self.train_dataset = InterpolDataSet(torch.tensor(train_feature_data[feature_columns].values, dtype=torch.float32),\n",
    "                                             torch.tensor(train_label_data.values, dtype=torch.float32),\n",
    "                                             torch.tensor(train_feature_data['weight'].values, dtype=torch.float32))\n",
    "        \n",
    "        self.val_dataset = InterpolDataSet(torch.tensor(val_feature_data[feature_columns].values, dtype=torch.float32),\n",
    "                                           torch.tensor(val_label_data.values, dtype=torch.float32),\n",
    "                                           torch.tensor(val_feature_data['weight'].values, dtype=torch.float32))\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(dataset = self.train_dataset, batch_size = self.hyperparams.get('batch_size'), shuffle = False, num_workers=0)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(dataset = self.val_dataset, batch_size = self.hyperparams.get('batch_size'), shuffle = False, num_workers=0)\n",
    "\n",
    "class PrintCallbacks(Callback):\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        logging.info(\"Training is starting\")\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        logging.info(\"Training is ending\")\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        epoch_mean = torch.stack(pl_module.training_step_outputs).mean()\n",
    "        logging.info(f\"epoch: {pl_module.current_epoch}; train_loss: {epoch_mean}\")\n",
    "        pl_module.training_step_outputs.clear()\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        epoch_mean = torch.stack(pl_module.validation_step_outputs).mean()\n",
    "        logging.info(f\"epoch: {pl_module.current_epoch}; val_loss: {epoch_mean}\")\n",
    "        pl_module.validation_step_outputs.clear()\n",
    "\n",
    "class InterpolRegressor(pl.LightningModule):\n",
    "    def __init__(self, hyperparams):\n",
    "        super(InterpolRegressor, self).__init__()\n",
    "\n",
    "        self.train_loss, self.train_mae, self.val_loss, self.val_mae = 0,0,0,0\n",
    "        self.hyperparams = hyperparams\n",
    "        self.save_hyperparameters(self.hyperparams)\n",
    "\n",
    "        self.mae = MeanAbsoluteError()\n",
    "        self.loss_func = self.hyperparams.get('loss_func')\n",
    "\n",
    "        self.optim = self.hyperparams.get('optim_func')\n",
    "\n",
    "        self.net_architecture = self.hyperparams.get('net_architecture')\n",
    "        self.activation_function = self.hyperparams.get('activation_function')\n",
    "\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "        self.net = nn.Sequential()\n",
    "        for i in range(1,len(self.net_architecture)):\n",
    "            self.net.append(nn.Linear(self.net_architecture[i-1], self.net_architecture[i]))\n",
    "            if i!=len(self.net_architecture)-1:\n",
    "                self.net.append(self.activation_function)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, w = batch\n",
    "        y_hat = self.forward(x)\n",
    "\n",
    "        loss = self.loss_func\n",
    "        self.train_loss = loss.forward(y_hat.reshape(-1), y, w)\n",
    "        self.train_mae = self.mae(y_hat.reshape(-1), y)\n",
    "\n",
    "        self.log('train_loss', self.train_loss, batch_size=self.hyperparams['batch_size'],\n",
    "                 on_step=False, on_epoch=True, prog_bar=True, sync_dist=True, logger=True)\n",
    "        self.log('train_mae', self.train_mae, batch_size=self.hyperparams['batch_size'],\n",
    "                 on_step=False, on_epoch=True, prog_bar=True, sync_dist=True, logger=True)\n",
    "\n",
    "        self.training_step_outputs.append(self.train_loss)\n",
    "        return self.train_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, w = batch\n",
    "        y_hat = self.forward(x)\n",
    "\n",
    "        loss = self.loss_func\n",
    "        self.val_loss = loss.forward(y_hat.reshape(-1), y, w)\n",
    "        self.val_mae = self.mae(y_hat.reshape(-1), y)\n",
    "\n",
    "        self.log('val_loss', self.val_loss, batch_size=self.hyperparams['batch_size'],\n",
    "                 on_step=False, on_epoch=True, prog_bar=True, sync_dist=True, logger=True)\n",
    "        self.log('val_mae', self.val_mae, batch_size=self.hyperparams['batch_size'],\n",
    "                 on_step=False, on_epoch=True, prog_bar=True, sync_dist=True, logger=True)\n",
    "\n",
    "        self.validation_step_outputs.append(self.val_loss)\n",
    "        return self.val_loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        sch = self.lr_schedulers()\n",
    "        if isinstance(sch, torch.optim.lr_scheduler.ReduceLROnPlateau) and self.trainer.current_epoch!=0:\n",
    "                sch.step(self.trainer.callback_metrics[\"val_loss\"])\n",
    "\n",
    "    def configure_callbacks(self):\n",
    "        early_stop_callback = EarlyStopping(monitor=\"val_loss\", mode=\"min\",\n",
    "                                            min_delta=self.hyperparams.get('es_min_delta'),\n",
    "                                            patience=self.hyperparams.get('es_patience'),\n",
    "                                            verbose=True)\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(save_top_k=3,\n",
    "                                              monitor=\"val_loss\",\n",
    "                                              mode=\"min\",\n",
    "                                              dirpath=f\"{logger_full_path}/checkpoints\",\n",
    "                                              filename=\"{exp_name}{val_loss:.5f}-{epoch:02d}\")\n",
    "\n",
    "        lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "\n",
    "        print_callback = PrintCallbacks()\n",
    "\n",
    "        return [early_stop_callback, checkpoint_callback, print_callback, lr_monitor]\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optim(self.parameters(), lr=self.hyperparams.get('lr'))\n",
    "        lr_optim = ReduceLROnPlateau(optimizer = optimizer,\n",
    "                                     mode = 'min',\n",
    "                                     factor = self.hyperparams.get('lr_factor'),\n",
    "                                     patience = self.hyperparams.get('lr_patience'),\n",
    "                                     cooldown=self.hyperparams.get('lr_cooldown'),\n",
    "                                     threshold=0.01,\n",
    "                                     verbose= True)\n",
    "        return {\"optimizer\": optimizer,\n",
    "                \"lr_scheduler\": {\n",
    "                    \"scheduler\": lr_optim,\n",
    "                    \"interval\": \"epoch\",\n",
    "                    \"monitor\": \"val_loss\",\n",
    "                    \"frequency\": 2,\n",
    "                    \"name\": 'lr_scheduler_monitoring'}\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5babb2",
   "metadata": {
    "code_folding": [],
    "scrolled": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-02-02T16:14:34.916676Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'activation_function' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_function'])`.\n",
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: ModelCheckpoint\n",
      "\n",
      "  | Name                | Type              | Params\n",
      "----------------------------------------------------------\n",
      "0 | mae                 | MeanAbsoluteError | 0     \n",
      "1 | loss_func           | RMSELoss          | 0     \n",
      "2 | activation_function | ReLU              | 0     \n",
      "3 | net                 | Sequential        | 5.0 M \n",
      "----------------------------------------------------------\n",
      "5.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.0 M     Total params\n",
      "19.926    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 16:14:35,276 : INFO : epoch: 0; val_loss: 18.674592971801758\n",
      "2024-02-02 16:14:35,281 : INFO : Training is starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 16:17:05,922 : INFO : epoch: 0; val_loss: 13.89778995513916\n",
      "2024-02-02 16:17:05,927 : INFO : epoch: 0; train_loss: 17.809070587158203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 13.898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 16:17:06,091 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=13.89779-epoch=00.ckpt\n",
      "2024-02-02 16:19:42,266 : INFO : epoch: 1; val_loss: 12.569906234741211\n",
      "2024-02-02 16:19:42,273 : INFO : epoch: 1; train_loss: 14.843350410461426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 1.328 >= min_delta = 1e-05. New best score: 12.570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 16:19:42,477 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=12.56991-epoch=01.ckpt\n",
      "2024-02-02 16:22:22,631 : INFO : epoch: 2; val_loss: 10.14493465423584\n",
      "2024-02-02 16:22:22,639 : INFO : epoch: 2; train_loss: 12.701802253723145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 2.425 >= min_delta = 1e-05. New best score: 10.145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 16:22:22,805 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=10.14494-epoch=02.ckpt\n",
      "2024-02-02 16:25:10,384 : INFO : epoch: 3; val_loss: 9.686511993408203\n",
      "2024-02-02 16:25:10,393 : INFO : epoch: 3; train_loss: 11.01168441772461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.458 >= min_delta = 1e-05. New best score: 9.687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 16:25:10,623 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=9.68652-epoch=03.ckpt\n",
      "2024-02-02 16:28:24,689 : INFO : epoch: 4; val_loss: 9.099124908447266\n",
      "2024-02-02 16:28:24,699 : INFO : epoch: 4; train_loss: 9.462930679321289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.587 >= min_delta = 1e-05. New best score: 9.099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 16:28:24,928 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=9.09912-epoch=04.ckpt\n",
      "2024-02-02 16:31:22,601 : INFO : epoch: 5; val_loss: 8.970876693725586\n",
      "2024-02-02 16:31:22,607 : INFO : epoch: 5; train_loss: 9.115650177001953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.128 >= min_delta = 1e-05. New best score: 8.971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 16:31:22,769 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=8.97088-epoch=05.ckpt\n",
      "2024-02-02 16:33:52,883 : INFO : epoch: 6; val_loss: 6.396556377410889\n",
      "2024-02-02 16:33:52,889 : INFO : epoch: 6; train_loss: 8.365659713745117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 2.574 >= min_delta = 1e-05. New best score: 6.397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 16:33:53,065 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=6.39655-epoch=06.ckpt\n",
      "2024-02-02 16:36:34,911 : INFO : epoch: 7; val_loss: 7.189112186431885\n",
      "2024-02-02 16:36:34,916 : INFO : epoch: 7; train_loss: 8.177916526794434\n",
      "2024-02-02 16:36:35,074 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=7.18911-epoch=07.ckpt\n",
      "2024-02-02 16:39:03,539 : INFO : epoch: 8; val_loss: 6.5800323486328125\n",
      "2024-02-02 16:39:03,544 : INFO : epoch: 8; train_loss: 8.224462509155273\n",
      "2024-02-02 16:39:03,701 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=6.58003-epoch=08.ckpt\n",
      "2024-02-02 16:41:33,635 : INFO : epoch: 9; val_loss: 6.198523998260498\n",
      "2024-02-02 16:41:33,641 : INFO : epoch: 9; train_loss: 7.718321323394775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.198 >= min_delta = 1e-05. New best score: 6.199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 16:41:33,802 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=6.19853-epoch=09.ckpt\n",
      "2024-02-02 16:44:03,228 : INFO : epoch: 10; val_loss: 7.3740034103393555\n",
      "2024-02-02 16:44:03,234 : INFO : epoch: 10; train_loss: 7.732532501220703\n",
      "2024-02-02 16:46:43,481 : INFO : epoch: 11; val_loss: 6.5831451416015625\n",
      "2024-02-02 16:46:43,488 : INFO : epoch: 11; train_loss: 7.386973857879639\n",
      "2024-02-02 16:49:14,426 : INFO : epoch: 12; val_loss: 6.824430465698242\n",
      "2024-02-02 16:49:14,432 : INFO : epoch: 12; train_loss: 7.430947780609131\n",
      "2024-02-02 16:51:45,974 : INFO : epoch: 13; val_loss: 8.354735374450684\n",
      "Epoch 00019: reducing learning rate of group 0 to 5.0000e-04.\n",
      "2024-02-02 16:51:45,980 : INFO : epoch: 13; train_loss: 7.342649459838867\n",
      "2024-02-02 16:54:26,916 : INFO : epoch: 14; val_loss: 5.907252311706543\n",
      "2024-02-02 16:54:26,923 : INFO : epoch: 14; train_loss: 6.244832515716553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.291 >= min_delta = 1e-05. New best score: 5.907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 16:54:27,108 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=5.90725-epoch=14.ckpt\n",
      "2024-02-02 16:57:06,921 : INFO : epoch: 15; val_loss: 6.51002836227417\n",
      "2024-02-02 16:57:06,926 : INFO : epoch: 15; train_loss: 6.199605941772461\n",
      "2024-02-02 16:59:47,338 : INFO : epoch: 16; val_loss: 5.671895980834961\n",
      "2024-02-02 16:59:47,346 : INFO : epoch: 16; train_loss: 6.10825252532959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.235 >= min_delta = 1e-05. New best score: 5.672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 16:59:47,535 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=5.67190-epoch=16.ckpt\n",
      "2024-02-02 17:02:19,334 : INFO : epoch: 17; val_loss: 5.549639701843262\n",
      "2024-02-02 17:02:19,340 : INFO : epoch: 17; train_loss: 6.08781099319458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.122 >= min_delta = 1e-05. New best score: 5.550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 17:02:19,530 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=5.54964-epoch=17.ckpt\n",
      "2024-02-02 17:04:49,890 : INFO : epoch: 18; val_loss: 5.970808982849121\n",
      "2024-02-02 17:04:49,895 : INFO : epoch: 18; train_loss: 6.019715785980225\n",
      "2024-02-02 17:07:34,799 : INFO : epoch: 19; val_loss: 5.949369430541992\n",
      "2024-02-02 17:07:34,805 : INFO : epoch: 19; train_loss: 6.043981552124023\n",
      "2024-02-02 17:10:08,359 : INFO : epoch: 20; val_loss: 5.603267192840576\n",
      "2024-02-02 17:10:08,365 : INFO : epoch: 20; train_loss: 5.937986850738525\n",
      "2024-02-02 17:10:08,541 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=5.60327-epoch=20.ckpt\n",
      "2024-02-02 17:12:44,723 : INFO : epoch: 21; val_loss: 5.751530170440674\n",
      "2024-02-02 17:12:44,729 : INFO : epoch: 21; train_loss: 5.919928550720215\n",
      "2024-02-02 17:15:47,691 : INFO : epoch: 22; val_loss: 5.636458873748779\n",
      "2024-02-02 17:15:47,698 : INFO : epoch: 22; train_loss: 5.967928886413574\n",
      "2024-02-02 17:15:47,876 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=5.63646-epoch=22.ckpt\n",
      "2024-02-02 17:18:43,457 : INFO : epoch: 23; val_loss: 5.720905780792236\n",
      "2024-02-02 17:18:43,463 : INFO : epoch: 23; train_loss: 5.925353050231934\n",
      "2024-02-02 17:21:41,154 : INFO : epoch: 24; val_loss: 5.694940567016602\n",
      "2024-02-02 17:21:41,160 : INFO : epoch: 24; train_loss: 5.856786251068115\n",
      "2024-02-02 17:24:40,799 : INFO : epoch: 25; val_loss: 6.295735836029053\n",
      "2024-02-02 17:24:40,806 : INFO : epoch: 25; train_loss: 5.848223686218262\n",
      "2024-02-02 17:27:41,682 : INFO : epoch: 26; val_loss: 5.662886619567871\n",
      "2024-02-02 17:27:41,688 : INFO : epoch: 26; train_loss: 5.848160743713379\n",
      "2024-02-02 17:30:43,595 : INFO : epoch: 27; val_loss: 6.096295356750488\n",
      "2024-02-02 17:30:43,601 : INFO : epoch: 27; train_loss: 5.795596122741699\n",
      "2024-02-02 17:33:46,420 : INFO : epoch: 28; val_loss: 5.890768527984619\n",
      "2024-02-02 17:33:46,426 : INFO : epoch: 28; train_loss: 5.751018047332764\n",
      "2024-02-02 17:36:50,414 : INFO : epoch: 29; val_loss: 6.019993305206299\n",
      "2024-02-02 17:36:50,420 : INFO : epoch: 29; train_loss: 5.6784186363220215\n",
      "2024-02-02 17:39:54,033 : INFO : epoch: 30; val_loss: 5.9079413414001465\n",
      "Epoch 00045: reducing learning rate of group 0 to 2.5000e-04.\n",
      "2024-02-02 17:39:54,041 : INFO : epoch: 30; train_loss: 5.589992046356201\n",
      "2024-02-02 17:42:58,649 : INFO : epoch: 31; val_loss: 5.088557720184326\n",
      "2024-02-02 17:42:58,656 : INFO : epoch: 31; train_loss: 5.213781833648682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.461 >= min_delta = 1e-05. New best score: 5.089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 17:42:58,836 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=5.08856-epoch=31.ckpt\n",
      "2024-02-02 17:45:47,043 : INFO : epoch: 32; val_loss: 5.48366117477417\n",
      "2024-02-02 17:45:47,049 : INFO : epoch: 32; train_loss: 5.120527267456055\n",
      "2024-02-02 17:45:47,229 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=5.48366-epoch=32.ckpt\n",
      "2024-02-02 17:48:34,829 : INFO : epoch: 33; val_loss: 5.044585227966309\n",
      "2024-02-02 17:48:34,834 : INFO : epoch: 33; train_loss: 5.097151756286621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.044 >= min_delta = 1e-05. New best score: 5.045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 17:48:35,017 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=5.04459-epoch=33.ckpt\n",
      "2024-02-02 17:51:22,616 : INFO : epoch: 34; val_loss: 4.995327949523926\n",
      "2024-02-02 17:51:22,622 : INFO : epoch: 34; train_loss: 5.052473545074463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.049 >= min_delta = 1e-05. New best score: 4.995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 17:51:22,806 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.99533-epoch=34.ckpt\n",
      "2024-02-02 17:54:10,627 : INFO : epoch: 35; val_loss: 5.01591682434082\n",
      "2024-02-02 17:54:10,633 : INFO : epoch: 35; train_loss: 5.034736156463623\n",
      "2024-02-02 17:54:10,808 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=5.01592-epoch=35.ckpt\n",
      "2024-02-02 17:56:58,517 : INFO : epoch: 36; val_loss: 5.056362628936768\n",
      "2024-02-02 17:56:58,524 : INFO : epoch: 36; train_loss: 5.014590263366699\n",
      "2024-02-02 18:00:03,326 : INFO : epoch: 37; val_loss: 5.123875617980957\n",
      "2024-02-02 18:00:03,332 : INFO : epoch: 37; train_loss: 4.989715099334717\n",
      "2024-02-02 18:02:51,350 : INFO : epoch: 38; val_loss: 5.058656692504883\n",
      "2024-02-02 18:02:51,355 : INFO : epoch: 38; train_loss: 4.985382556915283\n",
      "2024-02-02 18:05:55,597 : INFO : epoch: 39; val_loss: 5.053332328796387\n",
      "2024-02-02 18:05:55,603 : INFO : epoch: 39; train_loss: 4.964240074157715\n",
      "2024-02-02 18:08:43,813 : INFO : epoch: 40; val_loss: 5.043074607849121\n",
      "2024-02-02 18:08:43,818 : INFO : epoch: 40; train_loss: 4.91786003112793\n",
      "2024-02-02 18:08:44,003 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=5.04307-epoch=40.ckpt\n",
      "2024-02-02 18:11:47,942 : INFO : epoch: 41; val_loss: 5.184686660766602\n",
      "2024-02-02 18:11:47,950 : INFO : epoch: 41; train_loss: 4.917168617248535\n",
      "2024-02-02 18:14:49,839 : INFO : epoch: 42; val_loss: 4.946407318115234\n",
      "2024-02-02 18:14:49,845 : INFO : epoch: 42; train_loss: 4.907651424407959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.049 >= min_delta = 1e-05. New best score: 4.946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 18:14:50,024 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.94641-epoch=42.ckpt\n",
      "2024-02-02 18:19:20,882 : INFO : epoch: 43; val_loss: 5.201143741607666\n",
      "2024-02-02 18:19:20,890 : INFO : epoch: 43; train_loss: 4.886948108673096\n",
      "2024-02-02 20:29:42,575 : INFO : epoch: 44; val_loss: 5.359710693359375\n",
      "2024-02-02 20:29:42,660 : INFO : epoch: 44; train_loss: 4.879541397094727\n",
      "2024-02-02 20:33:45,786 : INFO : epoch: 45; val_loss: 5.297131061553955\n",
      "2024-02-02 20:33:45,793 : INFO : epoch: 45; train_loss: 4.870675563812256\n",
      "2024-02-02 20:36:47,059 : INFO : epoch: 46; val_loss: 5.258267402648926\n",
      "2024-02-02 20:36:47,065 : INFO : epoch: 46; train_loss: 4.841917037963867\n",
      "2024-02-02 20:39:37,758 : INFO : epoch: 47; val_loss: 5.315807342529297\n",
      "2024-02-02 20:39:37,764 : INFO : epoch: 47; train_loss: 4.850797653198242\n",
      "Epoch 00071: reducing learning rate of group 0 to 1.2500e-04.\n",
      "2024-02-02 20:42:41,941 : INFO : epoch: 48; val_loss: 4.658149719238281\n",
      "2024-02-02 20:42:41,948 : INFO : epoch: 48; train_loss: 4.641221046447754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.288 >= min_delta = 1e-05. New best score: 4.658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 20:42:42,155 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.65815-epoch=48.ckpt\n",
      "2024-02-02 20:45:44,887 : INFO : epoch: 49; val_loss: 4.654748916625977\n",
      "2024-02-02 20:45:44,894 : INFO : epoch: 49; train_loss: 4.612788677215576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 1e-05. New best score: 4.655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 20:45:45,089 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.65475-epoch=49.ckpt\n",
      "2024-02-02 20:48:49,149 : INFO : epoch: 50; val_loss: 4.646838665008545\n",
      "2024-02-02 20:48:49,155 : INFO : epoch: 50; train_loss: 4.599214553833008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.008 >= min_delta = 1e-05. New best score: 4.647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 20:48:49,344 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.64684-epoch=50.ckpt\n",
      "2024-02-02 20:51:50,414 : INFO : epoch: 51; val_loss: 4.635341644287109\n",
      "2024-02-02 20:51:50,419 : INFO : epoch: 51; train_loss: 4.592110633850098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.011 >= min_delta = 1e-05. New best score: 4.635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 20:51:50,615 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.63534-epoch=51.ckpt\n",
      "2024-02-02 20:54:52,785 : INFO : epoch: 52; val_loss: 4.6446919441223145\n",
      "2024-02-02 20:54:52,792 : INFO : epoch: 52; train_loss: 4.58595609664917\n",
      "2024-02-02 20:54:52,964 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.64469-epoch=52.ckpt\n",
      "2024-02-02 20:57:42,938 : INFO : epoch: 53; val_loss: 4.6612324714660645\n",
      "2024-02-02 20:57:42,945 : INFO : epoch: 53; train_loss: 4.566359519958496\n",
      "2024-02-02 21:00:43,906 : INFO : epoch: 54; val_loss: 4.654221057891846\n",
      "2024-02-02 21:00:43,912 : INFO : epoch: 54; train_loss: 4.56739616394043\n",
      "2024-02-02 21:03:31,634 : INFO : epoch: 55; val_loss: 4.654208183288574\n",
      "2024-02-02 21:03:31,640 : INFO : epoch: 55; train_loss: 4.560777187347412\n",
      "2024-02-02 21:06:33,856 : INFO : epoch: 56; val_loss: 4.644581317901611\n",
      "2024-02-02 21:06:33,862 : INFO : epoch: 56; train_loss: 4.553366661071777\n",
      "2024-02-02 21:06:34,038 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.64458-epoch=56.ckpt\n",
      "2024-02-02 21:09:36,353 : INFO : epoch: 57; val_loss: 4.652532577514648\n",
      "2024-02-02 21:09:36,359 : INFO : epoch: 57; train_loss: 4.543282985687256\n",
      "2024-02-02 21:12:38,101 : INFO : epoch: 58; val_loss: 4.646650314331055\n",
      "2024-02-02 21:12:38,106 : INFO : epoch: 58; train_loss: 4.538187026977539\n",
      "2024-02-02 21:15:40,453 : INFO : epoch: 59; val_loss: 4.660423278808594\n",
      "2024-02-02 21:15:40,461 : INFO : epoch: 59; train_loss: 4.532156467437744\n",
      "2024-02-02 21:18:42,577 : INFO : epoch: 60; val_loss: 4.649324893951416\n",
      "2024-02-02 21:18:42,585 : INFO : epoch: 60; train_loss: 4.526174068450928\n",
      "2024-02-02 21:21:45,965 : INFO : epoch: 61; val_loss: 4.654179096221924\n",
      "2024-02-02 21:21:45,971 : INFO : epoch: 61; train_loss: 4.519862174987793\n",
      "2024-02-02 21:24:48,815 : INFO : epoch: 62; val_loss: 4.646844387054443\n",
      "2024-02-02 21:24:48,822 : INFO : epoch: 62; train_loss: 4.517062664031982\n",
      "2024-02-02 21:27:52,581 : INFO : epoch: 63; val_loss: 4.65007209777832\n",
      "2024-02-02 21:27:52,587 : INFO : epoch: 63; train_loss: 4.510903835296631\n",
      "2024-02-02 21:30:56,275 : INFO : epoch: 64; val_loss: 4.645263195037842\n",
      "2024-02-02 21:30:56,280 : INFO : epoch: 64; train_loss: 4.510288238525391\n",
      "2024-02-02 21:33:59,937 : INFO : epoch: 65; val_loss: 4.639533996582031\n",
      "Epoch 00097: reducing learning rate of group 0 to 6.2500e-05.\n",
      "2024-02-02 21:33:59,943 : INFO : epoch: 65; train_loss: 4.499297142028809\n",
      "2024-02-02 21:34:00,123 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.63954-epoch=65.ckpt\n",
      "2024-02-02 21:36:49,510 : INFO : epoch: 66; val_loss: 4.52545690536499\n",
      "2024-02-02 21:36:49,516 : INFO : epoch: 66; train_loss: 4.409276485443115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.110 >= min_delta = 1e-05. New best score: 4.525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 21:36:49,720 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.52546-epoch=66.ckpt\n",
      "2024-02-02 21:39:53,573 : INFO : epoch: 67; val_loss: 4.52344274520874\n",
      "2024-02-02 21:39:53,579 : INFO : epoch: 67; train_loss: 4.393800258636475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 1e-05. New best score: 4.523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 21:39:53,779 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.52344-epoch=67.ckpt\n",
      "2024-02-02 21:42:57,667 : INFO : epoch: 68; val_loss: 4.513409614562988\n",
      "2024-02-02 21:42:57,673 : INFO : epoch: 68; train_loss: 4.38801908493042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.010 >= min_delta = 1e-05. New best score: 4.513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 21:42:57,888 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.51341-epoch=68.ckpt\n",
      "2024-02-02 21:47:33,596 : INFO : epoch: 69; val_loss: 4.519779682159424\n",
      "2024-02-02 21:47:33,603 : INFO : epoch: 69; train_loss: 4.381381511688232\n",
      "2024-02-02 21:47:33,772 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.51978-epoch=69.ckpt\n",
      "2024-02-02 21:53:06,765 : INFO : epoch: 70; val_loss: 4.514081001281738\n",
      "2024-02-02 21:53:06,772 : INFO : epoch: 70; train_loss: 4.377162456512451\n",
      "2024-02-02 21:53:06,960 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.51408-epoch=70.ckpt\n",
      "2024-02-02 21:58:40,427 : INFO : epoch: 71; val_loss: 4.517697811126709\n",
      "2024-02-02 21:58:40,433 : INFO : epoch: 71; train_loss: 4.373814105987549\n",
      "2024-02-02 21:58:40,605 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.51770-epoch=71.ckpt\n",
      "2024-02-02 22:04:14,267 : INFO : epoch: 72; val_loss: 4.512768745422363\n",
      "2024-02-02 22:04:14,273 : INFO : epoch: 72; train_loss: 4.366074085235596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 1e-05. New best score: 4.513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 22:04:14,453 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.51277-epoch=72.ckpt\n",
      "2024-02-02 22:10:19,791 : INFO : epoch: 73; val_loss: 4.507742881774902\n",
      "2024-02-02 22:10:19,796 : INFO : epoch: 73; train_loss: 4.3655242919921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 1e-05. New best score: 4.508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 22:10:19,972 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.50774-epoch=73.ckpt\n",
      "2024-02-02 22:15:53,051 : INFO : epoch: 74; val_loss: 4.510360240936279\n",
      "2024-02-02 22:15:53,058 : INFO : epoch: 74; train_loss: 4.362704277038574\n",
      "2024-02-02 22:15:53,236 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.51036-epoch=74.ckpt\n",
      "2024-02-02 22:21:30,414 : INFO : epoch: 75; val_loss: 4.50709342956543\n",
      "2024-02-02 22:21:30,420 : INFO : epoch: 75; train_loss: 4.357779502868652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 1e-05. New best score: 4.507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 22:21:30,601 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.50709-epoch=75.ckpt\n",
      "2024-02-02 22:27:05,526 : INFO : epoch: 76; val_loss: 4.507728099822998\n",
      "2024-02-02 22:27:05,532 : INFO : epoch: 76; train_loss: 4.354898452758789\n",
      "2024-02-02 22:27:05,704 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.50773-epoch=76.ckpt\n",
      "2024-02-02 22:32:42,235 : INFO : epoch: 77; val_loss: 4.507563591003418\n",
      "2024-02-02 22:32:42,240 : INFO : epoch: 77; train_loss: 4.350592613220215\n",
      "2024-02-02 22:32:42,414 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.50756-epoch=77.ckpt\n",
      "2024-02-02 22:38:17,423 : INFO : epoch: 78; val_loss: 4.5100579261779785\n",
      "2024-02-02 22:38:17,429 : INFO : epoch: 78; train_loss: 4.348645210266113\n",
      "2024-02-02 22:44:20,529 : INFO : epoch: 79; val_loss: 4.511715888977051\n",
      "2024-02-02 22:44:20,535 : INFO : epoch: 79; train_loss: 4.345664978027344\n",
      "2024-02-02 22:50:24,867 : INFO : epoch: 80; val_loss: 4.506687164306641\n",
      "2024-02-02 22:50:24,873 : INFO : epoch: 80; train_loss: 4.3410210609436035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 1e-05. New best score: 4.507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 22:50:25,051 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.50669-epoch=80.ckpt\n",
      "2024-02-02 22:56:02,661 : INFO : epoch: 81; val_loss: 4.506224632263184\n",
      "2024-02-02 22:56:02,666 : INFO : epoch: 81; train_loss: 4.338267803192139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 1e-05. New best score: 4.506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 22:56:02,843 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.50622-epoch=81.ckpt\n",
      "2024-02-02 23:01:44,234 : INFO : epoch: 82; val_loss: 4.495099067687988\n",
      "Epoch 00123: reducing learning rate of group 0 to 3.1250e-05.\n",
      "2024-02-02 23:01:44,240 : INFO : epoch: 82; train_loss: 4.335699081420898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.011 >= min_delta = 1e-05. New best score: 4.495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 23:01:44,436 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.49510-epoch=82.ckpt\n",
      "2024-02-02 23:07:50,394 : INFO : epoch: 83; val_loss: 4.48472261428833\n",
      "2024-02-02 23:07:50,399 : INFO : epoch: 83; train_loss: 4.297994613647461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.010 >= min_delta = 1e-05. New best score: 4.485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 23:07:50,558 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.48472-epoch=83.ckpt\n",
      "2024-02-02 23:13:56,841 : INFO : epoch: 84; val_loss: 4.4887237548828125\n",
      "2024-02-02 23:13:56,847 : INFO : epoch: 84; train_loss: 4.289949893951416\n",
      "2024-02-02 23:13:57,037 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.48872-epoch=84.ckpt\n",
      "2024-02-02 23:19:34,473 : INFO : epoch: 85; val_loss: 4.482151985168457\n",
      "2024-02-02 23:19:34,479 : INFO : epoch: 85; train_loss: 4.2870192527771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 1e-05. New best score: 4.482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 23:19:34,657 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/visionary-dew-39/checkpoints/exp_name=0val_loss=4.48215-epoch=85.ckpt\n"
     ]
    }
   ],
   "source": [
    "data_module = InterpolDataModule(hyperparams=hyperparams_dict)\n",
    "model = InterpolRegressor(hyperparams=hyperparams_dict)\n",
    "# model = InterpolRegressor.load_from_checkpoint(f'./wandb_local_logs/MSU_interpol/fresh-surf-31/checkpoints/exp_name=0val_loss=0.32796-epoch=57.ckpt', hyperparams=hyperparams_dict)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=hyperparams_dict.get('max_epochs'),\n",
    "                     accelerator='cpu',\n",
    "                     logger=wandb_logger,\n",
    "                     enable_progress_bar=False)\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9f33d989",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T16:12:19.809882Z",
     "start_time": "2024-02-02T16:11:59.688776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c69152ea1994eab9d848dee2c3f6405"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▁▂▁▂▁▁▂▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇█▁▂▂▃▁▂▂▃▃▁▂▁▁</td></tr><tr><td>lr_scheduler_monitoring</td><td>████████████████▄▄▄▄▄▂▂▂▂▂▁███▄███▄█████</td></tr><tr><td>train_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█</td></tr><tr><td>train_mae</td><td>▃▃▃▃██▄▃▃▆▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▂▂▂▂▁▁▁▁▁▂▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▂▁▂▁▂▂▂▂▂▂▂▂▃▃▄▄▅▅▆▆▇▇▇█▁▂▂▃▁▂▂▃▃▁▂▁▂</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█</td></tr><tr><td>val_mae</td><td>▃▃▃▃██▄▃▃▅▅█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▂▂▂▂▁▁▁▁▁▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>lr_scheduler_monitoring</td><td>0.0</td></tr><tr><td>train_loss</td><td>31.04678</td></tr><tr><td>train_mae</td><td>1.04107</td></tr><tr><td>trainer/global_step</td><td>5256</td></tr><tr><td>val_loss</td><td>29.64243</td></tr><tr><td>val_mae</td><td>1.00007</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">worldly-frost-38</strong> at: <a href='https://wandb.ai/msu_ai/msu_interpol/runs/3auuhc8a' target=\"_blank\">https://wandb.ai/msu_ai/msu_interpol/runs/3auuhc8a</a><br/> View job at <a href='https://wandb.ai/msu_ai/msu_interpol/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEzMDk2MzQ1OQ==/version_details/v9' target=\"_blank\">https://wandb.ai/msu_ai/msu_interpol/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEzMDk2MzQ1OQ==/version_details/v9</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb_local_logs/wandb/run-20240202_140341-3auuhc8a/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-02 16:12:17,798 : DEBUG : Starting new HTTPS connection (1): o151352.ingest.sentry.io:443\n",
      "2024-02-02 16:12:18,195 : DEBUG : Incremented Retry for (url='/api/4504800232407040/envelope/'): Retry(total=2, connect=None, read=None, redirect=None, status=None)\n",
      "2024-02-02 16:12:18,197 : WARNING : Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1002)'))': /api/4504800232407040/envelope/\n",
      "2024-02-02 16:12:18,198 : DEBUG : Starting new HTTPS connection (2): o151352.ingest.sentry.io:443\n",
      "2024-02-02 16:12:18,572 : DEBUG : Incremented Retry for (url='/api/4504800232407040/envelope/'): Retry(total=1, connect=None, read=None, redirect=None, status=None)\n",
      "2024-02-02 16:12:18,573 : WARNING : Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1002)'))': /api/4504800232407040/envelope/\n",
      "2024-02-02 16:12:18,574 : DEBUG : Starting new HTTPS connection (3): o151352.ingest.sentry.io:443\n",
      "2024-02-02 16:12:18,942 : DEBUG : Incremented Retry for (url='/api/4504800232407040/envelope/'): Retry(total=0, connect=None, read=None, redirect=None, status=None)\n",
      "2024-02-02 16:12:18,942 : WARNING : Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1002)'))': /api/4504800232407040/envelope/\n",
      "2024-02-02 16:12:18,943 : DEBUG : Starting new HTTPS connection (4): o151352.ingest.sentry.io:443\n",
      "2024-02-02 16:12:19,441 : DEBUG : Starting new HTTPS connection (5): o151352.ingest.sentry.io:443\n"
     ]
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
