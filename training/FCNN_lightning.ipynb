{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ce34e31",
   "metadata": {
    "code_folding": [],
    "ExecuteTime": {
     "end_time": "2024-01-20T16:22:52.828556Z",
     "start_time": "2024-01-20T16:22:52.823598Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import wandb\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "from torchmetrics import MeanAbsoluteError\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import Callback, LearningRateMonitor, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T16:22:53.121542Z",
     "start_time": "2024-01-20T16:22:53.093607Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "94402bc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T00:54:02.062303Z",
     "start_time": "2024-01-19T00:54:02.047207Z"
    }
   },
   "source": [
    "# FCNN"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "class RMSELoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSELoss,self).__init__()\n",
    "\n",
    "    def forward(self,x,y):\n",
    "        criterion = nn.MSELoss()\n",
    "        loss = torch.sqrt(criterion(x, y))\n",
    "        return loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T16:22:55.052169Z",
     "start_time": "2024-01-20T16:22:55.042233Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "192e02bf",
   "metadata": {
    "code_folding": [],
    "ExecuteTime": {
     "end_time": "2024-01-20T16:22:55.531264Z",
     "start_time": "2024-01-20T16:22:55.525009Z"
    }
   },
   "outputs": [],
   "source": [
    "#params\n",
    "project_name = \"MSU_interpol\"\n",
    "\n",
    "logger_path = './wandb_local_logs'\n",
    "data_path = '../data/clasdb_pi_plus_n.txt'\n",
    "\n",
    "hyperparams_dict = {\n",
    "    'scale_data': False,\n",
    "    'test_size': 0.1,\n",
    "    'batch_size': 32,\n",
    "    'net_architecture': [5, 60, 80, 20, 1],\n",
    "    'activation_function': nn.ReLU(),\n",
    "    'loss_func': RMSELoss(),\n",
    "    'optim_func': torch.optim.Adam,\n",
    "    'max_epochs': 2000,\n",
    "    'es_min_delta': 0.0001,\n",
    "    'es_patience': 20,\n",
    "    'lr': 0.00001,\n",
    "    'lr_factor':0.5,\n",
    "    'lr_patience': 20,\n",
    "    'lr_cooldown': 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "wandb_logger = WandbLogger(project=project_name,\n",
    "                           save_dir=logger_path)\n",
    "exp_name = wandb_logger.experiment.name\n",
    "\n",
    "logger_full_path = os.path.join(logger_path, project_name, exp_name)\n",
    "\n",
    "os.makedirs(logger_full_path, exist_ok=True)\n",
    "logging.basicConfig(encoding='utf-8',\n",
    "                    level=logging.DEBUG,\n",
    "                    format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                    handlers=[logging.FileHandler(os.path.join(logger_full_path, 'logs.log'), mode='w'),\n",
    "                              logging.StreamHandler(sys.stdout)],\n",
    "                    force=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T16:23:06.256913Z",
     "start_time": "2024-01-20T16:23:06.248559Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1a4c8bf4",
   "metadata": {
    "code_folding": [
     0,
     14,
     57
    ],
    "ExecuteTime": {
     "end_time": "2024-01-20T16:23:08.118175Z",
     "start_time": "2024-01-20T16:23:08.086445Z"
    }
   },
   "outputs": [],
   "source": [
    "class InterpolDataSet(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.len = len(labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        feature = self.features[index]\n",
    "        label = self.labels[index]\n",
    "        return feature, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class InterpolDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, hyperparams):\n",
    "        super().__init__()\n",
    "        self.df = None\n",
    "        self.hyperparams = hyperparams\n",
    "    \n",
    "    def setup(self, stage):\n",
    "        # data reading and preprocessing\n",
    "        df = pd.read_csv(data_path, delimiter='\\t', header=None)\n",
    "        df.columns = ['Ebeam', 'W', 'Q2', 'cos_theta', 'phi', 'dsigma_dOmega', 'error', 'id']\n",
    "\n",
    "        df.loc[8314:65671, 'Ebeam'] = 5.754 # peculiarity of this dataset.\n",
    "        df['phi'] = df.phi.apply(lambda x: math.radians(x))\n",
    "        df = df.drop('id', axis=1)\n",
    "        df = df.iloc[df[['Ebeam', 'W', 'Q2', 'cos_theta', 'phi']].drop_duplicates().index]\n",
    "        self.df = df\n",
    "        \n",
    "        #train test split\n",
    "        feature_data = df[['Ebeam', 'W', 'Q2', 'cos_theta', 'phi']]\n",
    "        label_data = df['dsigma_dOmega']\n",
    "        \n",
    "        if self.hyperparams.get('scale_data'):\n",
    "            scaler_feature = StandardScaler()\n",
    "            scaler_target = StandardScaler()\n",
    "            feature_data = scaler_feature.fit_transform(feature_data)\n",
    "            label_data = scaler_target.fit_transform(label_data.values.reshape(-1,1))\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        train_feature_data, val_feature_data, train_label_data, val_label_data = train_test_split(feature_data,\n",
    "                                                                                                  label_data,\n",
    "                                                                                                  test_size=self.hyperparams.get('test_size'),\n",
    "                                                                                                  random_state=1438)\n",
    "        \n",
    "        \n",
    "        self.train_dataset = InterpolDataSet(torch.tensor(train_feature_data.values, dtype=torch.float32), \n",
    "                                             torch.tensor(train_label_data.values, dtype=torch.float32))\n",
    "        \n",
    "        self.val_dataset = InterpolDataSet(torch.tensor(val_feature_data.values, dtype=torch.float32), \n",
    "                                            torch.tensor(val_label_data.values, dtype=torch.float32))\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(dataset = self.train_dataset, batch_size = self.hyperparams.get('batch_size'), shuffle = False, num_workers=0)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(dataset = self.val_dataset, batch_size = self.hyperparams.get('batch_size'), shuffle = False, num_workers=0)\n",
    "\n",
    "class PrintCallbacks(Callback):\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        logging.info(\"Training is starting\")\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        logging.info(\"Training is ending\")\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        logging.info(f\"epoch: {pl_module.current_epoch}; train_loss: {pl_module.train_loss}; train_mae: {pl_module.train_mae}\")\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        logging.info(f\"epoch: {pl_module.current_epoch}; val_loss: {pl_module.val_loss}; val_mae: {pl_module.val_mae}\")\n",
    "\n",
    "class InterpolRegressor(pl.LightningModule):\n",
    "    def __init__(self, hyperparams):\n",
    "        super(InterpolRegressor, self).__init__()\n",
    "\n",
    "        self.train_loss, self.train_mae, self.val_loss, self.val_mae = 0,0,0,0\n",
    "        self.hyperparams = hyperparams\n",
    "        self.save_hyperparameters(self.hyperparams)\n",
    "\n",
    "        self.mae = MeanAbsoluteError()\n",
    "        self.loss_func = self.hyperparams.get('loss_func')\n",
    "\n",
    "        self.optim = self.hyperparams.get('optim_func')\n",
    "\n",
    "        self.net_architecture = self.hyperparams.get('net_architecture')\n",
    "        self.activation_function = self.hyperparams.get('activation_function')\n",
    "\n",
    "        self.net = nn.Sequential()\n",
    "        for i in range(1,len(self.net_architecture)):\n",
    "            self.net.append(nn.Linear(self.net_architecture[i-1], self.net_architecture[i]))\n",
    "            if i!=len(self.net_architecture)-1:\n",
    "                self.net.append(self.activation_function)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "\n",
    "        loss = self.loss_func\n",
    "        self.train_loss = loss(y_hat.reshape(-1), y)\n",
    "\n",
    "        self.train_mae = self.mae(y_hat.reshape(-1), y)\n",
    "\n",
    "        self.log('train_loss', self.train_loss, batch_size=self.hyperparams['batch_size'],\n",
    "                 on_step=False, on_epoch=True, prog_bar=True, sync_dist=True, logger=True)\n",
    "        self.log('train_mae', self.train_mae, batch_size=self.hyperparams['batch_size'],\n",
    "                 on_step=False, on_epoch=True, prog_bar=True, sync_dist=True, logger=True)\n",
    "\n",
    "        return self.train_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "\n",
    "        loss = self.loss_func\n",
    "        self.val_loss = loss(y_hat.reshape(-1), y)\n",
    "        self.val_mae = self.mae(y_hat.reshape(-1), y)\n",
    "\n",
    "        self.log('val_loss', self.val_loss, batch_size=self.hyperparams['batch_size'],\n",
    "                 on_step=False, on_epoch=True, prog_bar=True, sync_dist=True, logger=True)\n",
    "        self.log('val_mae', self.val_mae, batch_size=self.hyperparams['batch_size'],\n",
    "                 on_step=False, on_epoch=True, prog_bar=True, sync_dist=True, logger=True)\n",
    "\n",
    "        sch = self.lr_schedulers()\n",
    "        if isinstance(sch, torch.optim.lr_scheduler.ReduceLROnPlateau) and self.trainer.current_epoch!=0 and self.trainer.is_last_batch:\n",
    "                sch.step(self.trainer.callback_metrics[\"val_loss\"])\n",
    "\n",
    "        return self.val_loss\n",
    "\n",
    "    def configure_callbacks(self):\n",
    "        early_stop_callback = EarlyStopping(monitor=\"val_loss\", mode=\"min\",\n",
    "                                            min_delta=self.hyperparams.get('es_min_delta'),\n",
    "                                            patience=self.hyperparams.get('es_patience'),\n",
    "                                            verbose=True)\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(save_top_k=3,\n",
    "                                              monitor=\"val_loss\",\n",
    "                                              mode=\"min\",\n",
    "                                              dirpath=f\"{logger_full_path}/checkpoints\",\n",
    "                                              filename=\"{exp_name}{val_loss:.5f}-{epoch:02d}\")\n",
    "        print_callback = PrintCallbacks()\n",
    "\n",
    "        return [early_stop_callback, checkpoint_callback, print_callback]\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optim(self.parameters(), lr=self.hyperparams.get('lr'))\n",
    "        lr_optim = ReduceLROnPlateau(optimizer = optimizer,\n",
    "                                     mode = 'min',\n",
    "                                     factor = self.hyperparams.get('lr_factor'),\n",
    "                                     patience = self.hyperparams.get('lr_patience'),\n",
    "                                     cooldown=self.hyperparams.get('lr_cooldown'),\n",
    "                                     verbose= True)\n",
    "        return {\"optimizer\": optimizer,\n",
    "                \"lr_scheduler\": {\n",
    "                    \"scheduler\": lr_optim,\n",
    "                    \"interval\": \"epoch\",\n",
    "                    \"monitor\": \"val_loss\",\n",
    "                    \"frequency\": 2,\n",
    "                    \"name\": 'lr_scheduler_monitoring'}\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b5babb2",
   "metadata": {
    "code_folding": [],
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T16:24:40.351319Z",
     "start_time": "2024-01-20T16:24:02.332056Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'activation_function' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_function'])`.\n",
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: ModelCheckpoint\n",
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:639: Checkpoint directory /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/revived-gorge-25/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name                | Type              | Params\n",
      "----------------------------------------------------------\n",
      "0 | mae                 | MeanAbsoluteError | 0     \n",
      "1 | loss_func           | RMSELoss          | 0     \n",
      "2 | activation_function | ReLU              | 0     \n",
      "3 | net                 | Sequential        | 6.9 K \n",
      "----------------------------------------------------------\n",
      "6.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.9 K     Total params\n",
      "0.028     Total estimated model params size (MB)\n",
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 16:24:02,572 : INFO : epoch: 0; val_loss: 0.785344123840332; val_mae: 0.6692865490913391\n",
      "2024-01-20 16:24:02,579 : INFO : Training is starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 16:24:11,261 : INFO : epoch: 0; val_loss: 1.0730516910552979; val_mae: 0.5716284513473511\n",
      "2024-01-20 16:24:11,263 : INFO : epoch: 0; train_loss: 2.3556277751922607; train_mae: 1.0446885824203491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 1.902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 16:24:11,270 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/revived-gorge-25/checkpoints/exp_name=0val_loss=1.90159-epoch=00.ckpt\n",
      "Epoch 00022: reducing learning rate of group 0 to 5.0000e-06.\n",
      "Epoch 00093: reducing learning rate of group 0 to 2.5000e-06.\n",
      "Epoch 00164: reducing learning rate of group 0 to 1.2500e-06.\n",
      "Epoch 00235: reducing learning rate of group 0 to 6.2500e-07.\n",
      "2024-01-20 16:24:19,222 : INFO : epoch: 1; val_loss: 0.8166549205780029; val_mae: 0.45048069953918457\n",
      "2024-01-20 16:24:19,224 : INFO : epoch: 1; train_loss: 1.9984688758850098; train_mae: 0.8364319801330566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.196 >= min_delta = 0.0001. New best score: 1.706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 16:24:19,231 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/revived-gorge-25/checkpoints/exp_name=0val_loss=1.70601-epoch=01.ckpt\n",
      "Epoch 00314: reducing learning rate of group 0 to 3.1250e-07.\n",
      "Epoch 00385: reducing learning rate of group 0 to 1.5625e-07.\n",
      "Epoch 00456: reducing learning rate of group 0 to 7.8125e-08.\n",
      "Epoch 00527: reducing learning rate of group 0 to 3.9063e-08.\n",
      "2024-01-20 16:24:27,524 : INFO : epoch: 2; val_loss: 0.8025331497192383; val_mae: 0.4531887173652649\n",
      "2024-01-20 16:24:27,527 : INFO : epoch: 2; train_loss: 1.9712343215942383; train_mae: 0.8263707756996155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.011 >= min_delta = 0.0001. New best score: 1.695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 16:24:27,536 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/revived-gorge-25/checkpoints/exp_name=0val_loss=1.69463-epoch=02.ckpt\n",
      "Epoch 00607: reducing learning rate of group 0 to 1.9531e-08.\n",
      "2024-01-20 16:24:36,974 : INFO : epoch: 3; val_loss: 0.8015747666358948; val_mae: 0.4529813528060913\n",
      "2024-01-20 16:24:36,978 : INFO : epoch: 3; train_loss: 1.9697351455688477; train_mae: 0.8258571624755859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 1.694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 16:24:36,984 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/revived-gorge-25/checkpoints/exp_name=0val_loss=1.69394-epoch=03.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "data_module = InterpolDataModule(hyperparams=hyperparams_dict)\n",
    "model = InterpolRegressor(hyperparams=hyperparams_dict)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=hyperparams_dict.get('max_epochs'),\n",
    "                     accelerator='cpu',\n",
    "                     logger=wandb_logger,\n",
    "                     enable_progress_bar=False)\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f33d989",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T16:01:57.728279Z",
     "start_time": "2024-01-20T16:01:46.136354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df75233d92024e1bb9efdceb872a1b6f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "W&B sync reduced upload amount by 9.7%             "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▃▃▅▅▆▆██</td></tr><tr><td>train_loss</td><td>█▄▁▁▁</td></tr><tr><td>train_mae</td><td>█▄▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▃▃▅▅▆▆██</td></tr><tr><td>val_loss</td><td>█▁▁▁▁</td></tr><tr><td>val_mae</td><td>█▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_loss</td><td>1.83145</td></tr><tr><td>train_mae</td><td>0.78899</td></tr><tr><td>trainer/global_step</td><td>13139</td></tr><tr><td>val_loss</td><td>1.75001</td></tr><tr><td>val_mae</td><td>0.75887</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">zany-durian-24</strong> at: <a href='https://wandb.ai/msu_ai/msu_interpol/runs/sxvux2au' target=\"_blank\">https://wandb.ai/msu_ai/msu_interpol/runs/sxvux2au</a><br/> View job at <a href='https://wandb.ai/msu_ai/msu_interpol/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEzMDk2MzQ1OQ==/version_details/v6' target=\"_blank\">https://wandb.ai/msu_ai/msu_interpol/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEzMDk2MzQ1OQ==/version_details/v6</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb_local_logs/wandb/run-20240120_155634-sxvux2au/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 16:01:57,253 : WARNING : Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1002)'))': /api/4504800232407040/envelope/\n",
      "2024-01-20 16:01:57,329 : WARNING : Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1002)'))': /api/4504800232407040/envelope/\n",
      "2024-01-20 16:01:57,397 : WARNING : Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1002)'))': /api/4504800232407040/envelope/\n",
      "2024-01-20 16:01:57,526 : WARNING : Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1002)'))': /api/4504800232407040/envelope/\n",
      "2024-01-20 16:01:57,588 : WARNING : Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1002)'))': /api/4504800232407040/envelope/\n",
      "2024-01-20 16:01:57,648 : WARNING : Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1002)'))': /api/4504800232407040/envelope/\n"
     ]
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
