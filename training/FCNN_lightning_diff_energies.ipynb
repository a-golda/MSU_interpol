{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8ce34e31",
   "metadata": {
    "code_folding": [],
    "ExecuteTime": {
     "end_time": "2024-03-30T11:09:03.256835Z",
     "start_time": "2024-03-30T11:09:03.228773Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import tqdm\n",
    "import wandb\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "from torchmetrics import MeanAbsoluteError\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import Callback, LearningRateMonitor, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T11:09:03.669003Z",
     "start_time": "2024-03-30T11:09:03.659283Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "94402bc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T11:21:16.752953Z",
     "start_time": "2024-03-07T11:21:16.740004Z"
    }
   },
   "source": [
    "# FCNN"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "class RMSELoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSELoss,self).__init__()\n",
    "\n",
    "    def forward(self,x,y,w):\n",
    "        criterion = nn.MSELoss()\n",
    "        loss = torch.sqrt(criterion(x, y))*w\n",
    "        return loss.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T11:09:04.517816Z",
     "start_time": "2024-03-30T11:09:04.514400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "192e02bf",
   "metadata": {
    "code_folding": [],
    "ExecuteTime": {
     "end_time": "2024-03-30T11:09:04.950940Z",
     "start_time": "2024-03-30T11:09:04.947169Z"
    }
   },
   "outputs": [],
   "source": [
    "#params\n",
    "project_name = \"MSU_interpol_by_energy\"\n",
    "\n",
    "logger_path = './wandb_local_logs'\n",
    "data_path = '../data/clasdb_pi_plus_n.txt'\n",
    "\n",
    "hyperparams_dict = {\n",
    "    'scale_data': False,\n",
    "    'augment': True,\n",
    "    'augment_factor': 25,\n",
    "    'test_size': 0.1,\n",
    "    'batch_size': 256,\n",
    "    'net_architecture': [5,60,80,100,120,140,240,340,440,640,2000,1040,640,340,240,140,100,80,60,20,1],\n",
    "    'activation_function': nn.ReLU(),\n",
    "    'loss_func': RMSELoss(),\n",
    "    'optim_func': torch.optim.Adam,\n",
    "    'max_epochs': 2000,\n",
    "    'es_min_delta': 0.00001,\n",
    "    'es_patience': 20,\n",
    "    'lr': 0.001,\n",
    "    'lr_factor':0.5,\n",
    "    'lr_patience': 5,\n",
    "    'lr_cooldown': 20,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 11:09:05,583 : DEBUG : Popen(['git', 'cat-file', '--batch-check'], cwd=/Users/andrey.golda/Documents/Study/MSU_interpol, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.16.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.2"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>./wandb_local_logs/wandb/run-20240330_110905-nqe97tro</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/msu_ai/msu_interpol_by_energy/runs/nqe97tro' target=\"_blank\">eager-violet-5</a></strong> to <a href='https://wandb.ai/msu_ai/msu_interpol_by_energy' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/msu_ai/msu_interpol_by_energy' target=\"_blank\">https://wandb.ai/msu_ai/msu_interpol_by_energy</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/msu_ai/msu_interpol_by_energy/runs/nqe97tro' target=\"_blank\">https://wandb.ai/msu_ai/msu_interpol_by_energy/runs/nqe97tro</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb_logger = WandbLogger(project=project_name,\n",
    "                           save_dir=logger_path)\n",
    "exp_name = wandb_logger.experiment.name\n",
    "\n",
    "logger_full_path = os.path.join(logger_path, project_name, exp_name)\n",
    "\n",
    "os.makedirs(logger_full_path, exist_ok=True)\n",
    "logging.basicConfig(encoding='utf-8',\n",
    "                    level=logging.DEBUG,\n",
    "                    format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                    handlers=[logging.FileHandler(os.path.join(logger_full_path, 'logs.log'), mode='w'),\n",
    "                              logging.StreamHandler(sys.stdout)],\n",
    "                    force=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T11:09:10.653612Z",
     "start_time": "2024-03-30T11:09:05.534595Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1a4c8bf4",
   "metadata": {
    "code_folding": [
     0,
     14,
     57
    ],
    "ExecuteTime": {
     "end_time": "2024-03-30T11:09:16.931673Z",
     "start_time": "2024-03-30T11:09:16.910365Z"
    }
   },
   "outputs": [],
   "source": [
    "class InterpolDataSet(Dataset):\n",
    "    def __init__(self, features, labels, weights):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.weights = weights\n",
    "        self.len = len(labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        feature = self.features[index]\n",
    "        label = self.labels[index]\n",
    "        weights = self.weights[index]\n",
    "        return feature, label, weights\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class InterpolDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, hyperparams):\n",
    "        super().__init__()\n",
    "        self.df = None\n",
    "        self.hyperparams = hyperparams\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "\n",
    "    def augment(self, new_augm):\n",
    "        augm = pd.Series({'Ebeam': np.random.normal(loc=new_augm.Ebeam, scale=new_augm.Ebeam/30),\n",
    "                           'W': np.random.normal(loc=new_augm.W, scale=new_augm.W/30),\n",
    "                           'Q2': np.random.normal(loc=new_augm.Q2, scale=new_augm.Q2/30),\n",
    "                           'cos_theta': np.clip(np.random.normal(loc=new_augm.cos_theta, scale=abs(new_augm.cos_theta/30)), -1, 1),\n",
    "                           'phi': np.clip(np.random.normal(loc=new_augm.phi, scale=new_augm.phi/30), 0, 2*np.pi),\n",
    "                           'dsigma_dOmega': np.random.normal(loc=new_augm.dsigma_dOmega, scale=new_augm.error/3),\n",
    "                           'error': new_augm.error,\n",
    "                           'weight': new_augm.weight,\n",
    "                          })\n",
    "        return augm\n",
    "    \n",
    "    def setup(self, stage):\n",
    "        # data reading and preprocessing\n",
    "        df = pd.read_csv(data_path, delimiter='\\t', header=None)\n",
    "        df.columns = ['Ebeam', 'W', 'Q2', 'cos_theta', 'phi', 'dsigma_dOmega', 'error', 'id']\n",
    "        df.loc[8314:65671, 'Ebeam'] = 5.754 # peculiarity of this dataset.\n",
    "        df['phi'] = df.phi.apply(lambda x: math.radians(x))\n",
    "        df['weight'] = df['error'].apply(lambda x: x and 1 / x or 100) # x and 1 / x or 100  is just a reversed error but with validation 1/0 error in this case it will return 100\n",
    "        df = df.drop('id', axis=1)\n",
    "        df = df.iloc[df[['Ebeam', 'W', 'Q2', 'cos_theta', 'phi']].drop_duplicates().index]\n",
    "\n",
    "        #critical\n",
    "        # Ebeam = [5.754]\n",
    "        # Q2 = [1.72, 2.05, 2.44, 2.91, 3.48, 4.155]\n",
    "        # df = df[(df.Q2.isin(Q2))&(df.Ebeam.isin(Ebeam))]\n",
    "\n",
    "        # Ebeam = [5.499]\n",
    "        # W = [1.830, 1.890, 1.780, 1.950, 2.010, 1.620, 1.660, 1.700, 1.740]\n",
    "        # df = df[df.Ebeam.isin(Ebeam)&(df.W.isin(W))]\n",
    "\n",
    "        Ebeam = [1.515]\n",
    "        df = df[df.Ebeam.isin(Ebeam)]\n",
    "\n",
    "        #train test split\n",
    "        feature_columns = ['Ebeam', 'W', 'Q2', 'cos_theta', 'phi']\n",
    "        feature_columns_with_weights = ['Ebeam', 'W', 'Q2', 'cos_theta', 'phi', 'weight']\n",
    "\n",
    "        feature_data = df[feature_columns_with_weights]\n",
    "        label_data = df['dsigma_dOmega']\n",
    "        \n",
    "        if self.hyperparams.get('scale_data'):\n",
    "            scaler_feature = StandardScaler()\n",
    "            scaler_target = StandardScaler()\n",
    "            feature_data = scaler_feature.fit_transform(feature_data)\n",
    "            label_data = scaler_target.fit_transform(label_data.values.reshape(-1,1))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if self.hyperparams.get('augment'):\n",
    "            aug_series_list = []\n",
    "            for i in tqdm.tqdm(df.itertuples()):\n",
    "                for _ in range(self.hyperparams.get('augment_factor')):\n",
    "                    aug_series_list.append(self.augment(i))\n",
    "\n",
    "            aug_df = pd.DataFrame(aug_series_list)\n",
    "            df = pd.concat([df, aug_df])\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        self.df = df\n",
    "        \n",
    "        train_feature_data, val_feature_data, train_label_data, val_label_data = train_test_split(feature_data,\n",
    "                                                                                                  label_data,\n",
    "                                                                                                  test_size=self.hyperparams.get('test_size'),\n",
    "                                                                                                  random_state=1438)\n",
    "        \n",
    "        \n",
    "        self.train_dataset = InterpolDataSet(torch.tensor(train_feature_data[feature_columns].values, dtype=torch.float32),\n",
    "                                             torch.tensor(train_label_data.values, dtype=torch.float32),\n",
    "                                             torch.tensor(train_feature_data['weight'].values, dtype=torch.float32))\n",
    "        \n",
    "        self.val_dataset = InterpolDataSet(torch.tensor(val_feature_data[feature_columns].values, dtype=torch.float32),\n",
    "                                           torch.tensor(val_label_data.values, dtype=torch.float32),\n",
    "                                           torch.tensor(val_feature_data['weight'].values, dtype=torch.float32))\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(dataset = self.train_dataset, batch_size = self.hyperparams.get('batch_size'), shuffle = False, num_workers=0)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(dataset = self.val_dataset, batch_size = self.hyperparams.get('batch_size'), shuffle = False, num_workers=0)\n",
    "\n",
    "class PrintCallbacks(Callback):\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        logging.info(\"Training is starting\")\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        logging.info(\"Training is ending\")\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        epoch_mean = torch.stack(pl_module.training_step_outputs).mean()\n",
    "        logging.info(f\"epoch: {pl_module.current_epoch}; train_loss: {epoch_mean}\")\n",
    "        pl_module.training_step_outputs.clear()\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        epoch_mean = torch.stack(pl_module.validation_step_outputs).mean()\n",
    "        logging.info(f\"epoch: {pl_module.current_epoch}; val_loss: {epoch_mean}\")\n",
    "        pl_module.validation_step_outputs.clear()\n",
    "\n",
    "class InterpolRegressor(pl.LightningModule):\n",
    "    def __init__(self, hyperparams):\n",
    "        super(InterpolRegressor, self).__init__()\n",
    "\n",
    "        self.train_loss, self.train_mae, self.val_loss, self.val_mae = 0,0,0,0\n",
    "        self.hyperparams = hyperparams\n",
    "        self.save_hyperparameters(self.hyperparams)\n",
    "\n",
    "        self.mae = MeanAbsoluteError()\n",
    "        self.loss_func = self.hyperparams.get('loss_func')\n",
    "\n",
    "        self.optim = self.hyperparams.get('optim_func')\n",
    "\n",
    "        self.net_architecture = self.hyperparams.get('net_architecture')\n",
    "        self.activation_function = self.hyperparams.get('activation_function')\n",
    "\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "        self.net = nn.Sequential()\n",
    "        for i in range(1,len(self.net_architecture)):\n",
    "            self.net.append(nn.Linear(self.net_architecture[i-1], self.net_architecture[i]))\n",
    "            if i!=len(self.net_architecture)-1:\n",
    "                self.net.append(self.activation_function)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, w = batch\n",
    "        y_hat = self.forward(x)\n",
    "\n",
    "        loss = self.loss_func\n",
    "        self.train_loss = loss.forward(y_hat.reshape(-1), y, w)\n",
    "        self.train_mae = self.mae(y_hat.reshape(-1), y)\n",
    "\n",
    "        self.log('train_loss', self.train_loss, batch_size=self.hyperparams['batch_size'],\n",
    "                 on_step=False, on_epoch=True, prog_bar=True, sync_dist=True, logger=True)\n",
    "        self.log('train_mae', self.train_mae, batch_size=self.hyperparams['batch_size'],\n",
    "                 on_step=False, on_epoch=True, prog_bar=True, sync_dist=True, logger=True)\n",
    "\n",
    "        self.training_step_outputs.append(self.train_loss)\n",
    "        return self.train_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, w = batch\n",
    "        y_hat = self.forward(x)\n",
    "\n",
    "        loss = self.loss_func\n",
    "        self.val_loss = loss.forward(y_hat.reshape(-1), y, w)\n",
    "        self.val_mae = self.mae(y_hat.reshape(-1), y)\n",
    "\n",
    "        self.log('val_loss', self.val_loss, batch_size=self.hyperparams['batch_size'],\n",
    "                 on_step=False, on_epoch=True, prog_bar=True, sync_dist=True, logger=True)\n",
    "        self.log('val_mae', self.val_mae, batch_size=self.hyperparams['batch_size'],\n",
    "                 on_step=False, on_epoch=True, prog_bar=True, sync_dist=True, logger=True)\n",
    "\n",
    "        self.validation_step_outputs.append(self.val_loss)\n",
    "        return self.val_loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        sch = self.lr_schedulers()\n",
    "        if isinstance(sch, torch.optim.lr_scheduler.ReduceLROnPlateau) and self.trainer.current_epoch!=0:\n",
    "                sch.step(self.trainer.callback_metrics[\"val_loss\"])\n",
    "\n",
    "    def configure_callbacks(self):\n",
    "        early_stop_callback = EarlyStopping(monitor=\"val_loss\", mode=\"min\",\n",
    "                                            min_delta=self.hyperparams.get('es_min_delta'),\n",
    "                                            patience=self.hyperparams.get('es_patience'),\n",
    "                                            verbose=True)\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(save_top_k=3,\n",
    "                                              monitor=\"val_loss\",\n",
    "                                              mode=\"min\",\n",
    "                                              dirpath=f\"{logger_full_path}/checkpoints\",\n",
    "                                              filename=\"{exp_name}{val_loss:.5f}-{epoch:02d}\")\n",
    "\n",
    "        lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "\n",
    "        print_callback = PrintCallbacks()\n",
    "\n",
    "        return [early_stop_callback, checkpoint_callback, print_callback, lr_monitor]\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optim(self.parameters(), lr=self.hyperparams.get('lr'))\n",
    "        lr_optim = ReduceLROnPlateau(optimizer = optimizer,\n",
    "                                     mode = 'min',\n",
    "                                     factor = self.hyperparams.get('lr_factor'),\n",
    "                                     patience = self.hyperparams.get('lr_patience'),\n",
    "                                     cooldown=self.hyperparams.get('lr_cooldown'),\n",
    "                                     threshold=0.01,\n",
    "                                     verbose= True)\n",
    "        return {\"optimizer\": optimizer,\n",
    "                \"lr_scheduler\": {\n",
    "                    \"scheduler\": lr_optim,\n",
    "                    \"interval\": \"epoch\",\n",
    "                    \"monitor\": \"val_loss\",\n",
    "                    \"frequency\": 2,\n",
    "                    \"name\": 'lr_scheduler_monitoring'}\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8b5babb2",
   "metadata": {
    "code_folding": [],
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T11:14:54.217678Z",
     "start_time": "2024-03-30T11:09:22.400787Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'activation_function' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_function'])`.\n",
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: ModelCheckpoint\n",
      "8314it [00:29, 284.33it/s]\n",
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "\n",
      "  | Name                | Type              | Params\n",
      "----------------------------------------------------------\n",
      "0 | mae                 | MeanAbsoluteError | 0     \n",
      "1 | loss_func           | RMSELoss          | 0     \n",
      "2 | activation_function | ReLU              | 0     \n",
      "3 | net                 | Sequential        | 5.0 M \n",
      "----------------------------------------------------------\n",
      "5.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.0 M     Total params\n",
      "19.926    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 11:10:04,740 : INFO : epoch: 0; val_loss: 14.265295028686523\n",
      "2024-03-30 11:10:04,744 : INFO : Training is starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (30) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 11:10:09,160 : INFO : epoch: 0; val_loss: 8.682622909545898\n",
      "2024-03-30 11:10:09,163 : INFO : epoch: 0; train_loss: 10.988037109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 8.683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 11:10:09,234 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=8.68262-epoch=00.ckpt\n",
      "2024-03-30 11:10:13,672 : INFO : epoch: 1; val_loss: 7.706509590148926\n",
      "2024-03-30 11:10:13,674 : INFO : epoch: 1; train_loss: 7.918800354003906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.976 >= min_delta = 1e-05. New best score: 7.707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 11:10:13,740 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=7.70651-epoch=01.ckpt\n",
      "2024-03-30 11:10:18,068 : INFO : epoch: 2; val_loss: 7.581689834594727\n",
      "2024-03-30 11:10:18,071 : INFO : epoch: 2; train_loss: 7.356789588928223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.125 >= min_delta = 1e-05. New best score: 7.582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 11:10:18,151 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=7.58169-epoch=02.ckpt\n",
      "2024-03-30 11:10:22,751 : INFO : epoch: 3; val_loss: 7.611301422119141\n",
      "2024-03-30 11:10:22,754 : INFO : epoch: 3; train_loss: 7.1851301193237305\n",
      "2024-03-30 11:10:22,824 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=7.61130-epoch=03.ckpt\n",
      "2024-03-30 11:10:27,126 : INFO : epoch: 4; val_loss: 7.023857593536377\n",
      "2024-03-30 11:10:27,129 : INFO : epoch: 4; train_loss: 6.826742172241211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.558 >= min_delta = 1e-05. New best score: 7.024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 11:10:27,195 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=7.02386-epoch=04.ckpt\n",
      "2024-03-30 11:10:31,521 : INFO : epoch: 5; val_loss: 8.27336597442627\n",
      "2024-03-30 11:10:31,523 : INFO : epoch: 5; train_loss: 6.56088924407959\n",
      "2024-03-30 11:10:35,858 : INFO : epoch: 6; val_loss: 6.6450886726379395\n",
      "2024-03-30 11:10:35,860 : INFO : epoch: 6; train_loss: 6.709530353546143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.379 >= min_delta = 1e-05. New best score: 6.645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 11:10:35,933 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=6.64509-epoch=06.ckpt\n",
      "2024-03-30 11:10:40,204 : INFO : epoch: 7; val_loss: 6.799571514129639\n",
      "2024-03-30 11:10:40,206 : INFO : epoch: 7; train_loss: 6.149912357330322\n",
      "2024-03-30 11:10:40,268 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=6.79957-epoch=07.ckpt\n",
      "2024-03-30 11:10:44,760 : INFO : epoch: 8; val_loss: 6.902472019195557\n",
      "2024-03-30 11:10:44,763 : INFO : epoch: 8; train_loss: 6.055094242095947\n",
      "2024-03-30 11:10:44,834 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=6.90247-epoch=08.ckpt\n",
      "2024-03-30 11:10:49,103 : INFO : epoch: 9; val_loss: 6.456174850463867\n",
      "2024-03-30 11:10:49,105 : INFO : epoch: 9; train_loss: 6.013442516326904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.189 >= min_delta = 1e-05. New best score: 6.456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 11:10:49,176 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=6.45617-epoch=09.ckpt\n",
      "2024-03-30 11:10:53,481 : INFO : epoch: 10; val_loss: 6.16740608215332\n",
      "2024-03-30 11:10:53,483 : INFO : epoch: 10; train_loss: 5.864798069000244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.289 >= min_delta = 1e-05. New best score: 6.167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 11:10:53,551 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=6.16741-epoch=10.ckpt\n",
      "2024-03-30 11:10:57,900 : INFO : epoch: 11; val_loss: 5.405523777008057\n",
      "2024-03-30 11:10:57,902 : INFO : epoch: 11; train_loss: 5.636384963989258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.762 >= min_delta = 1e-05. New best score: 5.406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 11:10:57,978 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=5.40552-epoch=11.ckpt\n",
      "2024-03-30 11:11:02,389 : INFO : epoch: 12; val_loss: 6.513152122497559\n",
      "2024-03-30 11:11:02,392 : INFO : epoch: 12; train_loss: 5.020949840545654\n",
      "2024-03-30 11:11:06,659 : INFO : epoch: 13; val_loss: 4.074276924133301\n",
      "2024-03-30 11:11:06,661 : INFO : epoch: 13; train_loss: 4.825209140777588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 1.331 >= min_delta = 1e-05. New best score: 4.074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 11:11:06,792 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=4.07428-epoch=13.ckpt\n",
      "2024-03-30 11:11:11,140 : INFO : epoch: 14; val_loss: 4.042821407318115\n",
      "2024-03-30 11:11:11,142 : INFO : epoch: 14; train_loss: 4.537109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.031 >= min_delta = 1e-05. New best score: 4.043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 11:11:11,211 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=4.04282-epoch=14.ckpt\n",
      "2024-03-30 11:11:15,475 : INFO : epoch: 15; val_loss: 4.752250671386719\n",
      "2024-03-30 11:11:15,477 : INFO : epoch: 15; train_loss: 3.880427360534668\n",
      "2024-03-30 11:11:15,550 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=4.75225-epoch=15.ckpt\n",
      "2024-03-30 11:11:19,964 : INFO : epoch: 16; val_loss: 4.393248558044434\n",
      "2024-03-30 11:11:19,968 : INFO : epoch: 16; train_loss: 3.7454030513763428\n",
      "2024-03-30 11:11:20,042 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=4.39325-epoch=16.ckpt\n",
      "2024-03-30 11:11:24,347 : INFO : epoch: 17; val_loss: 3.7149369716644287\n",
      "2024-03-30 11:11:24,349 : INFO : epoch: 17; train_loss: 3.397869348526001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.328 >= min_delta = 1e-05. New best score: 3.715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 11:11:24,425 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=3.71494-epoch=17.ckpt\n",
      "2024-03-30 11:11:28,675 : INFO : epoch: 18; val_loss: 3.5878007411956787\n",
      "2024-03-30 11:11:28,677 : INFO : epoch: 18; train_loss: 3.3559534549713135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.127 >= min_delta = 1e-05. New best score: 3.588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 11:11:28,744 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=3.58780-epoch=18.ckpt\n",
      "2024-03-30 11:11:33,205 : INFO : epoch: 19; val_loss: 4.45113468170166\n",
      "2024-03-30 11:11:33,207 : INFO : epoch: 19; train_loss: 3.802239418029785\n",
      "2024-03-30 11:11:37,440 : INFO : epoch: 20; val_loss: 2.9823687076568604\n",
      "2024-03-30 11:11:37,443 : INFO : epoch: 20; train_loss: 3.420135974884033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.605 >= min_delta = 1e-05. New best score: 2.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 11:11:37,518 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=2.98237-epoch=20.ckpt\n",
      "2024-03-30 11:11:41,948 : INFO : epoch: 21; val_loss: 2.926678419113159\n",
      "2024-03-30 11:11:41,950 : INFO : epoch: 21; train_loss: 3.1683592796325684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.056 >= min_delta = 1e-05. New best score: 2.927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 11:11:42,023 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=2.92668-epoch=21.ckpt\n",
      "2024-03-30 11:11:46,493 : INFO : epoch: 22; val_loss: 4.068388938903809\n",
      "2024-03-30 11:11:46,506 : INFO : epoch: 22; train_loss: 3.1457536220550537\n",
      "2024-03-30 11:11:50,776 : INFO : epoch: 23; val_loss: 2.940657377243042\n",
      "2024-03-30 11:11:50,778 : INFO : epoch: 23; train_loss: 2.873232126235962\n",
      "2024-03-30 11:11:50,842 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=2.94066-epoch=23.ckpt\n",
      "2024-03-30 11:11:55,344 : INFO : epoch: 24; val_loss: 3.5547945499420166\n",
      "2024-03-30 11:11:55,347 : INFO : epoch: 24; train_loss: 3.2903237342834473\n",
      "2024-03-30 11:11:59,652 : INFO : epoch: 25; val_loss: 3.024230480194092\n",
      "2024-03-30 11:11:59,654 : INFO : epoch: 25; train_loss: 3.4921345710754395\n",
      "2024-03-30 11:12:03,883 : INFO : epoch: 26; val_loss: 2.707918643951416\n",
      "2024-03-30 11:12:03,885 : INFO : epoch: 26; train_loss: 2.527944326400757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.219 >= min_delta = 1e-05. New best score: 2.708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 11:12:03,952 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=2.70792-epoch=26.ckpt\n",
      "2024-03-30 11:12:08,350 : INFO : epoch: 27; val_loss: 2.7805943489074707\n",
      "2024-03-30 11:12:08,352 : INFO : epoch: 27; train_loss: 2.4414148330688477\n",
      "2024-03-30 11:12:08,415 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=2.78059-epoch=27.ckpt\n",
      "2024-03-30 11:12:12,699 : INFO : epoch: 28; val_loss: 2.824042558670044\n",
      "2024-03-30 11:12:12,701 : INFO : epoch: 28; train_loss: 2.5285470485687256\n",
      "2024-03-30 11:12:12,765 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=2.82404-epoch=28.ckpt\n",
      "2024-03-30 11:12:17,171 : INFO : epoch: 29; val_loss: 2.8157103061676025\n",
      "2024-03-30 11:12:17,175 : INFO : epoch: 29; train_loss: 2.501593828201294\n",
      "2024-03-30 11:12:17,260 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=2.81571-epoch=29.ckpt\n",
      "2024-03-30 11:12:21,700 : INFO : epoch: 30; val_loss: 2.8356878757476807\n",
      "2024-03-30 11:12:21,702 : INFO : epoch: 30; train_loss: 2.4718830585479736\n",
      "2024-03-30 11:12:25,912 : INFO : epoch: 31; val_loss: 2.8150458335876465\n",
      "2024-03-30 11:12:25,914 : INFO : epoch: 31; train_loss: 2.4837262630462646\n",
      "2024-03-30 11:12:25,977 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=2.81505-epoch=31.ckpt\n",
      "2024-03-30 11:12:30,450 : INFO : epoch: 32; val_loss: 2.835237979888916\n",
      "2024-03-30 11:12:30,452 : INFO : epoch: 32; train_loss: 2.4623777866363525\n",
      "2024-03-30 11:12:34,690 : INFO : epoch: 33; val_loss: 2.889084577560425\n",
      "2024-03-30 11:12:34,692 : INFO : epoch: 33; train_loss: 2.455528974533081\n",
      "2024-03-30 11:12:38,909 : INFO : epoch: 34; val_loss: 2.860004425048828\n",
      "2024-03-30 11:12:38,911 : INFO : epoch: 34; train_loss: 2.4600071907043457\n",
      "2024-03-30 11:12:43,293 : INFO : epoch: 35; val_loss: 2.842484712600708\n",
      "2024-03-30 11:12:43,295 : INFO : epoch: 35; train_loss: 2.4761805534362793\n",
      "2024-03-30 11:12:47,550 : INFO : epoch: 36; val_loss: 2.8376762866973877\n",
      "2024-03-30 11:12:47,553 : INFO : epoch: 36; train_loss: 2.461296796798706\n",
      "2024-03-30 11:12:51,867 : INFO : epoch: 37; val_loss: 2.994893789291382\n",
      "2024-03-30 11:12:51,869 : INFO : epoch: 37; train_loss: 2.545590400695801\n",
      "2024-03-30 11:12:56,214 : INFO : epoch: 38; val_loss: 3.2611899375915527\n",
      "2024-03-30 11:12:56,216 : INFO : epoch: 38; train_loss: 2.5148847103118896\n",
      "2024-03-30 11:13:00,522 : INFO : epoch: 39; val_loss: 2.9748406410217285\n",
      "2024-03-30 11:13:00,524 : INFO : epoch: 39; train_loss: 2.574244260787964\n",
      "2024-03-30 11:13:04,845 : INFO : epoch: 40; val_loss: 2.8562698364257812\n",
      "2024-03-30 11:13:04,848 : INFO : epoch: 40; train_loss: 2.503028154373169\n",
      "2024-03-30 11:13:09,211 : INFO : epoch: 41; val_loss: 2.8235034942626953\n",
      "2024-03-30 11:13:09,213 : INFO : epoch: 41; train_loss: 2.3605611324310303\n",
      "2024-03-30 11:13:13,410 : INFO : epoch: 42; val_loss: 2.9552202224731445\n",
      "2024-03-30 11:13:13,412 : INFO : epoch: 42; train_loss: 2.4231436252593994\n",
      "2024-03-30 11:13:17,795 : INFO : epoch: 43; val_loss: 2.6112778186798096\n",
      "2024-03-30 11:13:17,797 : INFO : epoch: 43; train_loss: 2.349919319152832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.097 >= min_delta = 1e-05. New best score: 2.611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 11:13:17,862 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=2.61128-epoch=43.ckpt\n",
      "2024-03-30 11:13:22,231 : INFO : epoch: 44; val_loss: 2.588564872741699\n",
      "2024-03-30 11:13:22,233 : INFO : epoch: 44; train_loss: 2.237534761428833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.023 >= min_delta = 1e-05. New best score: 2.589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 11:13:22,299 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=2.58856-epoch=44.ckpt\n",
      "2024-03-30 11:13:26,573 : INFO : epoch: 45; val_loss: 2.578803539276123\n",
      "2024-03-30 11:13:26,575 : INFO : epoch: 45; train_loss: 2.2337098121643066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.010 >= min_delta = 1e-05. New best score: 2.579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 11:13:26,654 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=2.57880-epoch=45.ckpt\n",
      "2024-03-30 11:13:31,090 : INFO : epoch: 46; val_loss: 2.583540678024292\n",
      "2024-03-30 11:13:31,093 : INFO : epoch: 46; train_loss: 2.22794771194458\n",
      "2024-03-30 11:13:31,167 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=2.58354-epoch=46.ckpt\n",
      "2024-03-30 11:13:35,380 : INFO : epoch: 47; val_loss: 2.589299440383911\n",
      "2024-03-30 11:13:35,382 : INFO : epoch: 47; train_loss: 2.2245941162109375\n",
      "2024-03-30 11:13:39,778 : INFO : epoch: 48; val_loss: 2.5844430923461914\n",
      "2024-03-30 11:13:39,781 : INFO : epoch: 48; train_loss: 2.2204360961914062\n",
      "2024-03-30 11:13:39,849 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=2.58444-epoch=48.ckpt\n",
      "2024-03-30 11:13:44,194 : INFO : epoch: 49; val_loss: 2.582218647003174\n",
      "2024-03-30 11:13:44,196 : INFO : epoch: 49; train_loss: 2.2185990810394287\n",
      "2024-03-30 11:13:44,267 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=2.58222-epoch=49.ckpt\n",
      "2024-03-30 11:13:48,744 : INFO : epoch: 50; val_loss: 2.591557741165161\n",
      "2024-03-30 11:13:48,746 : INFO : epoch: 50; train_loss: 2.2156107425689697\n",
      "2024-03-30 11:13:52,679 : INFO : epoch: 51; val_loss: 2.5881783962249756\n",
      "2024-03-30 11:13:52,685 : INFO : epoch: 51; train_loss: 2.216974973678589\n",
      "2024-03-30 11:13:56,963 : INFO : epoch: 52; val_loss: 2.5890092849731445\n",
      "2024-03-30 11:13:56,965 : INFO : epoch: 52; train_loss: 2.2148005962371826\n",
      "2024-03-30 11:14:01,274 : INFO : epoch: 53; val_loss: 2.586991310119629\n",
      "2024-03-30 11:14:01,276 : INFO : epoch: 53; train_loss: 2.2121963500976562\n",
      "2024-03-30 11:14:05,508 : INFO : epoch: 54; val_loss: 2.5841622352600098\n",
      "2024-03-30 11:14:05,510 : INFO : epoch: 54; train_loss: 2.2093138694763184\n",
      "2024-03-30 11:14:09,813 : INFO : epoch: 55; val_loss: 2.5855226516723633\n",
      "2024-03-30 11:14:09,816 : INFO : epoch: 55; train_loss: 2.2098162174224854\n",
      "2024-03-30 11:14:14,111 : INFO : epoch: 56; val_loss: 2.590853691101074\n",
      "2024-03-30 11:14:14,114 : INFO : epoch: 56; train_loss: 2.2105283737182617\n",
      "2024-03-30 11:14:18,442 : INFO : epoch: 57; val_loss: 2.589390277862549\n",
      "2024-03-30 11:14:18,444 : INFO : epoch: 57; train_loss: 2.205049753189087\n",
      "2024-03-30 11:14:22,821 : INFO : epoch: 58; val_loss: 2.5878026485443115\n",
      "2024-03-30 11:14:22,824 : INFO : epoch: 58; train_loss: 2.2040491104125977\n",
      "2024-03-30 11:14:27,100 : INFO : epoch: 59; val_loss: 2.5855329036712646\n",
      "2024-03-30 11:14:27,102 : INFO : epoch: 59; train_loss: 2.2023165225982666\n",
      "2024-03-30 11:14:31,391 : INFO : epoch: 60; val_loss: 2.612302303314209\n",
      "2024-03-30 11:14:31,393 : INFO : epoch: 60; train_loss: 2.1828534603118896\n",
      "2024-03-30 11:14:36,062 : INFO : epoch: 61; val_loss: 2.5825705528259277\n",
      "2024-03-30 11:14:36,068 : INFO : epoch: 61; train_loss: 2.1677463054656982\n",
      "2024-03-30 11:14:36,193 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=2.58257-epoch=61.ckpt\n",
      "2024-03-30 11:14:40,790 : INFO : epoch: 62; val_loss: 2.5864720344543457\n",
      "2024-03-30 11:14:40,792 : INFO : epoch: 62; train_loss: 2.1495487689971924\n",
      "2024-03-30 11:14:45,097 : INFO : epoch: 63; val_loss: 2.5863192081451416\n",
      "2024-03-30 11:14:45,099 : INFO : epoch: 63; train_loss: 2.1475627422332764\n",
      "2024-03-30 11:14:49,477 : INFO : epoch: 64; val_loss: 2.588226318359375\n",
      "2024-03-30 11:14:49,479 : INFO : epoch: 64; train_loss: 2.1460633277893066\n",
      "2024-03-30 11:14:54,028 : INFO : epoch: 65; val_loss: 2.581427574157715\n",
      "2024-03-30 11:14:54,030 : INFO : epoch: 65; train_loss: 2.1463208198547363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 20 records. Best score: 2.579. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 11:14:54,096 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol_by_energy/eager-violet-5/checkpoints/exp_name=0val_loss=2.58143-epoch=65.ckpt\n",
      "2024-03-30 11:14:54,143 : INFO : Training is ending\n"
     ]
    }
   ],
   "source": [
    "data_module = InterpolDataModule(hyperparams=hyperparams_dict)\n",
    "model = InterpolRegressor(hyperparams=hyperparams_dict)\n",
    "# model = InterpolRegressor.load_from_checkpoint(f'./wandb_local_logs/MSU_interpol/blooming-plasma-40/checkpoints/exp_name=0val_loss=6.43574-epoch=14.ckpt', hyperparams=hyperparams_dict)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=hyperparams_dict.get('max_epochs'),\n",
    "                     accelerator='cpu',\n",
    "                     logger=wandb_logger,\n",
    "                     enable_progress_bar=False)\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9f33d989",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T11:15:01.987378Z",
     "start_time": "2024-03-30T11:14:54.158047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53654ab56d3d4b20991fc3016add2105"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>lr_scheduler_monitoring</td><td>████████████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▆▅▄▅▄▄▄▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mae</td><td>█▆▅▄▄▄▄▄▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>█▇▇█▆▆▅▄▃▃▃▂▁▁▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_mae</td><td>█▆▇█▅▆▅▄▃▃▃▂▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>65</td></tr><tr><td>lr_scheduler_monitoring</td><td>0.00013</td></tr><tr><td>train_loss</td><td>2.14632</td></tr><tr><td>train_mae</td><td>0.76364</td></tr><tr><td>trainer/global_step</td><td>1979</td></tr><tr><td>val_loss</td><td>2.58143</td></tr><tr><td>val_mae</td><td>0.90808</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">eager-violet-5</strong> at: <a href='https://wandb.ai/msu_ai/msu_interpol_by_energy/runs/nqe97tro' target=\"_blank\">https://wandb.ai/msu_ai/msu_interpol_by_energy/runs/nqe97tro</a><br/> View job at <a href='https://wandb.ai/msu_ai/msu_interpol_by_energy/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE1MzcyODQzNg==/version_details/v0' target=\"_blank\">https://wandb.ai/msu_ai/msu_interpol_by_energy/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE1MzcyODQzNg==/version_details/v0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb_local_logs/wandb/run-20240330_110905-nqe97tro/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T11:31:33.016950Z",
     "start_time": "2024-03-07T11:31:33.013710Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
