{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85e14e0e",
   "metadata": {
    "code_folding": [],
    "ExecuteTime": {
     "end_time": "2024-03-07T11:21:09.308135Z",
     "start_time": "2024-03-07T11:21:03.382232Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xz/1q44kbwx25g7j6b7qsjs_x4r0000gp/T/ipykernel_2530/2713701154.py:13: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "#import\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import tqdm\n",
    "import math\n",
    "import wandb\n",
    "import torch\n",
    "import pylab\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import lightning.pytorch as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import randint\n",
    "from scipy.stats import chisquare, kstest\n",
    "from scipy.optimize import curve_fit\n",
    "from torchmetrics import MeanAbsoluteError\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import Callback, LearningRateMonitor, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94775e58",
   "metadata": {},
   "source": [
    "# Reading model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee41d69b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-03-07T10:24:02.490388Z",
     "start_time": "2024-03-07T10:24:01.236085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-07 10:24:02,095 : DEBUG : open file: /Users/andrey.golda/Documents/Study/MSU_interpol/training/wandb_local_logs/MSU_interpol/spring-feather-42/checkpoints/exp_name=0val_loss=5.32146-epoch=201.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'activation_function' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_function'])`.\n",
      "/Users/andrey.golda/Library/Caches/pypoetry/virtualenvs/msu-interpol--lw2ADYE-py3.11/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_func'])`.\n"
     ]
    },
    {
     "data": {
      "text/plain": "__main__.InterpolRegressor"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RMSELoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSELoss,self).__init__()\n",
    "\n",
    "    def forward(self,x,y,w):\n",
    "        criterion = nn.MSELoss()\n",
    "        loss = torch.sqrt(criterion(x, y))*w\n",
    "        return loss.mean()\n",
    "\n",
    "#params\n",
    "project_name = \"MSU_interpol\"\n",
    "\n",
    "logger_path = './wandb_local_logs'\n",
    "data_path = '../data/clasdb_pi_plus_n.txt'\n",
    "\n",
    "hyperparams_dict = {\n",
    "    'scale_data': False,\n",
    "    'test_size': 0.1,\n",
    "    'batch_size': 32,\n",
    "    'net_architecture': [5,60,80,100,120,140,240,340,440,640,2000,1040,640,340,240,140,100,80,60,20,1],\n",
    "    'activation_function': nn.ReLU(),\n",
    "    'loss_func': RMSELoss(),\n",
    "    'optim_func': torch.optim.Adam,\n",
    "    'max_epochs': 2000,\n",
    "    'es_min_delta': 0.00001,\n",
    "    'es_patience': 20,\n",
    "    'lr': 0.001,\n",
    "    'lr_factor':0.5,\n",
    "    'lr_patience': 5,\n",
    "    'lr_cooldown': 20,\n",
    "}\n",
    "\n",
    "logger_full_path = os.path.join(logger_path, project_name, 'spring-feather-42')\n",
    "\n",
    "os.makedirs(logger_full_path, exist_ok=True)\n",
    "logging.basicConfig(encoding='utf-8',\n",
    "                    level=logging.DEBUG,\n",
    "                    format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                    handlers=[logging.FileHandler(os.path.join(logger_full_path, 'logs.log'), mode='w'),\n",
    "                              logging.StreamHandler(sys.stdout)],\n",
    "                    force=True)\n",
    "\n",
    "class InterpolDataSet(Dataset):\n",
    "    def __init__(self, features, labels, weights):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.weights = weights\n",
    "        self.len = len(labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        feature = self.features[index]\n",
    "        label = self.labels[index]\n",
    "        weights = self.weights[index]\n",
    "        return feature, label, weights\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class InterpolDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, hyperparams):\n",
    "        super().__init__()\n",
    "        self.df = None\n",
    "        self.hyperparams = hyperparams\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "\n",
    "    def augment(self, new_augm):\n",
    "        augm = pd.Series({'Ebeam': np.random.normal(loc=new_augm.Ebeam, scale=new_augm.Ebeam/30),\n",
    "                           'W': np.random.normal(loc=new_augm.W, scale=new_augm.W/30),\n",
    "                           'Q2': np.random.normal(loc=new_augm.Q2, scale=new_augm.Q2/30),\n",
    "                           'cos_theta': np.clip(np.random.normal(loc=new_augm.cos_theta, scale=abs(new_augm.cos_theta/30)), -1, 1),\n",
    "                           'phi': np.clip(np.random.normal(loc=new_augm.phi, scale=new_augm.phi/30), 0, 2*np.pi),\n",
    "                           'dsigma_dOmega': np.random.normal(loc=new_augm.dsigma_dOmega, scale=new_augm.error/3),\n",
    "                           'error': new_augm.error,\n",
    "                           'weight': new_augm.weight,\n",
    "                          })\n",
    "        return augm\n",
    "\n",
    "    def setup(self, stage):\n",
    "        # data reading and preprocessing\n",
    "        df = pd.read_csv(data_path, delimiter='\\t', header=None)\n",
    "        df.columns = ['Ebeam', 'W', 'Q2', 'cos_theta', 'phi', 'dsigma_dOmega', 'error', 'id']\n",
    "        df.loc[8314:65671, 'Ebeam'] = 5.754 # peculiarity of this dataset.\n",
    "        df['phi'] = df.phi.apply(lambda x: math.radians(x))\n",
    "        df['weight'] = df['error'].apply(lambda x: x and 1 / x or 100) # x and 1 / x or 100  is just a reversed error but with validation 1/0 error in this case it will return 100\n",
    "        df = df.drop('id', axis=1)\n",
    "        df = df.iloc[df[['Ebeam', 'W', 'Q2', 'cos_theta', 'phi']].drop_duplicates().index]\n",
    "\n",
    "        #train test split\n",
    "        feature_columns = ['Ebeam', 'W', 'Q2', 'cos_theta', 'phi']\n",
    "        feature_columns_with_weights = ['Ebeam', 'W', 'Q2', 'cos_theta', 'phi', 'weight']\n",
    "\n",
    "        feature_data = df[feature_columns_with_weights]\n",
    "        label_data = df['dsigma_dOmega']\n",
    "\n",
    "        if self.hyperparams.get('scale_data'):\n",
    "            scaler_feature = StandardScaler()\n",
    "            scaler_target = StandardScaler()\n",
    "            feature_data = scaler_feature.fit_transform(feature_data)\n",
    "            label_data = scaler_target.fit_transform(label_data.values.reshape(-1,1))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if self.hyperparams.get('augment'):\n",
    "            aug_series_list = []\n",
    "            for i in tqdm.tqdm(df.itertuples()):\n",
    "                for _ in range(self.hyperparams.get('augment_factor')):\n",
    "                    aug_series_list.append(self.augment(i))\n",
    "\n",
    "            aug_df = pd.DataFrame(aug_series_list)\n",
    "            df = pd.concat([df, aug_df])\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        self.df = df\n",
    "\n",
    "        train_feature_data, val_feature_data, train_label_data, val_label_data = train_test_split(feature_data,\n",
    "                                                                                                  label_data,\n",
    "                                                                                                  test_size=self.hyperparams.get('test_size'),\n",
    "                                                                                                  random_state=1438)\n",
    "\n",
    "\n",
    "        self.train_dataset = InterpolDataSet(torch.tensor(train_feature_data[feature_columns].values, dtype=torch.float32),\n",
    "                                             torch.tensor(train_label_data.values, dtype=torch.float32),\n",
    "                                             torch.tensor(train_feature_data['weight'].values, dtype=torch.float32))\n",
    "\n",
    "        self.val_dataset = InterpolDataSet(torch.tensor(val_feature_data[feature_columns].values, dtype=torch.float32),\n",
    "                                           torch.tensor(val_label_data.values, dtype=torch.float32),\n",
    "                                           torch.tensor(val_feature_data['weight'].values, dtype=torch.float32))\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(dataset = self.train_dataset, batch_size = self.hyperparams.get('batch_size'), shuffle = False, num_workers=0)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(dataset = self.val_dataset, batch_size = self.hyperparams.get('batch_size'), shuffle = False, num_workers=0)\n",
    "\n",
    "class PrintCallbacks(Callback):\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        logging.info(\"Training is starting\")\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        logging.info(\"Training is ending\")\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        epoch_mean = torch.stack(pl_module.training_step_outputs).mean()\n",
    "        logging.info(f\"epoch: {pl_module.current_epoch}; train_loss: {epoch_mean}\")\n",
    "        pl_module.training_step_outputs.clear()\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        epoch_mean = torch.stack(pl_module.validation_step_outputs).mean()\n",
    "        logging.info(f\"epoch: {pl_module.current_epoch}; val_loss: {epoch_mean}\")\n",
    "        pl_module.validation_step_outputs.clear()\n",
    "\n",
    "class InterpolRegressor(pl.LightningModule):\n",
    "    def __init__(self, hyperparams):\n",
    "        super(InterpolRegressor, self).__init__()\n",
    "\n",
    "        self.train_loss, self.train_mae, self.val_loss, self.val_mae = 0,0,0,0\n",
    "        self.hyperparams = hyperparams\n",
    "        self.save_hyperparameters(self.hyperparams)\n",
    "\n",
    "        self.mae = MeanAbsoluteError()\n",
    "        self.loss_func = self.hyperparams.get('loss_func')\n",
    "\n",
    "        self.optim = self.hyperparams.get('optim_func')\n",
    "\n",
    "        self.net_architecture = self.hyperparams.get('net_architecture')\n",
    "        self.activation_function = self.hyperparams.get('activation_function')\n",
    "\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "        self.net = nn.Sequential()\n",
    "        for i in range(1,len(self.net_architecture)):\n",
    "            self.net.append(nn.Linear(self.net_architecture[i-1], self.net_architecture[i]))\n",
    "            if i!=len(self.net_architecture)-1:\n",
    "                self.net.append(self.activation_function)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, w = batch\n",
    "        y_hat = self.forward(x)\n",
    "\n",
    "        loss = self.loss_func\n",
    "        self.train_loss = loss.forward(y_hat.reshape(-1), y, w)\n",
    "        self.train_mae = self.mae(y_hat.reshape(-1), y)\n",
    "\n",
    "        self.log('train_loss', self.train_loss, batch_size=self.hyperparams['batch_size'],\n",
    "                 on_step=False, on_epoch=True, prog_bar=True, sync_dist=True, logger=True)\n",
    "        self.log('train_mae', self.train_mae, batch_size=self.hyperparams['batch_size'],\n",
    "                 on_step=False, on_epoch=True, prog_bar=True, sync_dist=True, logger=True)\n",
    "\n",
    "        self.training_step_outputs.append(self.train_loss)\n",
    "        return self.train_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, w = batch\n",
    "        y_hat = self.forward(x)\n",
    "\n",
    "        loss = self.loss_func\n",
    "        self.val_loss = loss.forward(y_hat.reshape(-1), y, w)\n",
    "        self.val_mae = self.mae(y_hat.reshape(-1), y)\n",
    "\n",
    "        self.log('val_loss', self.val_loss, batch_size=self.hyperparams['batch_size'],\n",
    "                 on_step=False, on_epoch=True, prog_bar=True, sync_dist=True, logger=True)\n",
    "        self.log('val_mae', self.val_mae, batch_size=self.hyperparams['batch_size'],\n",
    "                 on_step=False, on_epoch=True, prog_bar=True, sync_dist=True, logger=True)\n",
    "\n",
    "        self.validation_step_outputs.append(self.val_loss)\n",
    "        return self.val_loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        sch = self.lr_schedulers()\n",
    "        if isinstance(sch, torch.optim.lr_scheduler.ReduceLROnPlateau) and self.trainer.current_epoch!=0:\n",
    "                sch.step(self.trainer.callback_metrics[\"val_loss\"])\n",
    "\n",
    "    def configure_callbacks(self):\n",
    "        early_stop_callback = EarlyStopping(monitor=\"val_loss\", mode=\"min\",\n",
    "                                            min_delta=self.hyperparams.get('es_min_delta'),\n",
    "                                            patience=self.hyperparams.get('es_patience'),\n",
    "                                            verbose=True)\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(save_top_k=3,\n",
    "                                              monitor=\"val_loss\",\n",
    "                                              mode=\"min\",\n",
    "                                              dirpath=f\"{logger_full_path}/checkpoints\",\n",
    "                                              filename=\"{exp_name}{val_loss:.5f}-{epoch:02d}\")\n",
    "\n",
    "        lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "\n",
    "        print_callback = PrintCallbacks()\n",
    "\n",
    "        return [early_stop_callback, checkpoint_callback, print_callback, lr_monitor]\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optim(self.parameters(), lr=self.hyperparams.get('lr'))\n",
    "        lr_optim = ReduceLROnPlateau(optimizer = optimizer,\n",
    "                                     mode = 'min',\n",
    "                                     factor = self.hyperparams.get('lr_factor'),\n",
    "                                     patience = self.hyperparams.get('lr_patience'),\n",
    "                                     cooldown=self.hyperparams.get('lr_cooldown'),\n",
    "                                     threshold=0.01,\n",
    "                                     verbose= True)\n",
    "        return {\"optimizer\": optimizer,\n",
    "                \"lr_scheduler\": {\n",
    "                    \"scheduler\": lr_optim,\n",
    "                    \"interval\": \"epoch\",\n",
    "                    \"monitor\": \"val_loss\",\n",
    "                    \"frequency\": 2,\n",
    "                    \"name\": 'lr_scheduler_monitoring'}\n",
    "                }\n",
    "\n",
    "data = InterpolDataModule(hyperparams_dict)\n",
    "data.setup('test')\n",
    "df = data.df\n",
    "df_all = df[['Ebeam', 'W', 'Q2', 'cos_theta', 'phi']]\n",
    "df_target = df[['dsigma_dOmega']]\n",
    "\n",
    "model = InterpolRegressor.load_from_checkpoint(f'./wandb_local_logs/MSU_interpol/spring-feather-42/checkpoints/exp_name=0val_loss=5.32146-epoch=201.ckpt', hyperparams=hyperparams_dict)\n",
    "model.eval()\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0014b7",
   "metadata": {},
   "source": [
    "# Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.collections.PathCollection at 0x138441e10>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df[df.Ebeam == 5.754].W, df[df.Ebeam == 5.754].Q2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T10:46:23.978631Z",
     "start_time": "2024-03-07T10:46:23.426023Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(df[df.Ebeam == 5.754].W, df[df.Ebeam == 5.754].Q2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "       Ebeam     W  cos_theta   phi  dsigma_dOmega  error  weight\nQ2                                                               \n1.715   5606  5606       5606  5606           5606   5606    5606\n1.720   4402  4402       4402  4402           4402   4402    4402\n1.800      1     1          1     1              1      1       1\n2.050   7087  7087       7087  7087           7087   7087    7087\n2.115    234   234        234   234            234    234     234\n2.440   5452  5452       5452  5452           5452   5452    5452\n2.445   7073  7073       7073  7073           7073   7073    7073\n2.910   1378  1378       1378  1378           1378   1378    1378\n2.915   7233  7233       7233  7233           7233   7233    7233\n3.480   7265  7265       7265  7265           7265   7265    7265\n4.155   7035  7035       7035  7035           7035   7035    7035",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Ebeam</th>\n      <th>W</th>\n      <th>cos_theta</th>\n      <th>phi</th>\n      <th>dsigma_dOmega</th>\n      <th>error</th>\n      <th>weight</th>\n    </tr>\n    <tr>\n      <th>Q2</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1.715</th>\n      <td>5606</td>\n      <td>5606</td>\n      <td>5606</td>\n      <td>5606</td>\n      <td>5606</td>\n      <td>5606</td>\n      <td>5606</td>\n    </tr>\n    <tr>\n      <th>1.720</th>\n      <td>4402</td>\n      <td>4402</td>\n      <td>4402</td>\n      <td>4402</td>\n      <td>4402</td>\n      <td>4402</td>\n      <td>4402</td>\n    </tr>\n    <tr>\n      <th>1.800</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2.050</th>\n      <td>7087</td>\n      <td>7087</td>\n      <td>7087</td>\n      <td>7087</td>\n      <td>7087</td>\n      <td>7087</td>\n      <td>7087</td>\n    </tr>\n    <tr>\n      <th>2.115</th>\n      <td>234</td>\n      <td>234</td>\n      <td>234</td>\n      <td>234</td>\n      <td>234</td>\n      <td>234</td>\n      <td>234</td>\n    </tr>\n    <tr>\n      <th>2.440</th>\n      <td>5452</td>\n      <td>5452</td>\n      <td>5452</td>\n      <td>5452</td>\n      <td>5452</td>\n      <td>5452</td>\n      <td>5452</td>\n    </tr>\n    <tr>\n      <th>2.445</th>\n      <td>7073</td>\n      <td>7073</td>\n      <td>7073</td>\n      <td>7073</td>\n      <td>7073</td>\n      <td>7073</td>\n      <td>7073</td>\n    </tr>\n    <tr>\n      <th>2.910</th>\n      <td>1378</td>\n      <td>1378</td>\n      <td>1378</td>\n      <td>1378</td>\n      <td>1378</td>\n      <td>1378</td>\n      <td>1378</td>\n    </tr>\n    <tr>\n      <th>2.915</th>\n      <td>7233</td>\n      <td>7233</td>\n      <td>7233</td>\n      <td>7233</td>\n      <td>7233</td>\n      <td>7233</td>\n      <td>7233</td>\n    </tr>\n    <tr>\n      <th>3.480</th>\n      <td>7265</td>\n      <td>7265</td>\n      <td>7265</td>\n      <td>7265</td>\n      <td>7265</td>\n      <td>7265</td>\n      <td>7265</td>\n    </tr>\n    <tr>\n      <th>4.155</th>\n      <td>7035</td>\n      <td>7035</td>\n      <td>7035</td>\n      <td>7035</td>\n      <td>7035</td>\n      <td>7035</td>\n      <td>7035</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Ebeam == 5.754].groupby('Q2').count().sort_values('Q2')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T10:55:24.303812Z",
     "start_time": "2024-03-07T10:55:24.269939Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "[1.715, 1.72, 1.8, 2.05, 2.115, 2.44, 2.445, 2.91, 2.915, 3.48, 4.155]"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df[df.Ebeam == 5.754].Q2.unique())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T10:55:57.465527Z",
     "start_time": "2024-03-07T10:55:57.453415Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Crossections"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ad29580",
   "metadata": {
    "code_folding": [
     0
    ],
    "ExecuteTime": {
     "end_time": "2024-03-07T10:24:08.236983Z",
     "start_time": "2024-03-07T10:24:08.218433Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_sections_check(df, E_beam, W, Q2, cos_theta):\n",
    "    df_example_set = df[(df.Ebeam == E_beam)&\n",
    "                        (df.W == W)&\n",
    "                        (df.Q2 == Q2)&\n",
    "                        (df.cos_theta == cos_theta)].sort_values('phi')\n",
    "    if len(df_example_set)==0:\n",
    "        print(len(df_example_set), E_beam, W, Q2, cos_theta)\n",
    "        return None\n",
    "\n",
    "    df_example_set_for_prediction = pd.DataFrame({'Ebeam' : [E_beam for _ in np.arange(0, 2*np.pi, 0.01)],\n",
    "                                                  'W' : [W for _ in np.arange(0, 2*np.pi, 0.01)],\n",
    "                                                  'Q2' : [Q2 for _ in np.arange(0, 2*np.pi, 0.01)],\n",
    "                                                  'cos_theta' : [cos_theta for _ in np.arange(0, 2*np.pi, 0.01)],\n",
    "                                                  'phi' : [phi for phi in np.arange(0, 2*np.pi, 0.01)]})\n",
    "\n",
    "#     return df_example_set\n",
    "    with torch.no_grad():\n",
    "        dsigma_dOmega_predicted = model.forward(torch.tensor(df_example_set_for_prediction.to_numpy(),dtype=torch.float32)).detach()\n",
    "        df_example_set_for_prediction['dsigma_dOmega_predicted'] = dsigma_dOmega_predicted\n",
    "\n",
    "    def func_cos(x, a, b, c): \n",
    "        return a + b*np.cos(2*x) + c*np.cos(x) \n",
    "\n",
    "    #input data \n",
    "    xdata = df_example_set.phi\n",
    "    ydata = df_example_set.dsigma_dOmega\n",
    "    ydata_error = df_example_set.error\n",
    "\n",
    "    #fitting the data \n",
    "    popt, pcov = curve_fit(func_cos, xdata, ydata, sigma=ydata_error, absolute_sigma=True)\n",
    "\n",
    "    a, b, c = popt[0], popt[1], popt[2]\n",
    "    #print the fitted parameters \n",
    "    print(\"a = %s , b = %s, c = %s\" % (a, b, c))\n",
    "    phi_theory = [i for i in np.arange(0, 2*np.pi, 0.01)]\n",
    "    dsigma_dOmega_theory = [func_cos(x, a, b, c) for x in phi_theory]\n",
    "\n",
    "    df_theory = pd.DataFrame({'phi_theory': phi_theory,\n",
    "                              'dsigma_dOmega_theory': dsigma_dOmega_theory})\n",
    "\n",
    "    df_chi_2 = pd.merge_asof(df_example_set, df_theory, left_on='phi', right_on='phi_theory')\n",
    "    df_chi_2 = pd.merge_asof(df_chi_2, df_example_set_for_prediction, on='phi')\n",
    "    df_chi_2 = df_chi_2[['phi', 'dsigma_dOmega', 'dsigma_dOmega_theory', 'dsigma_dOmega_predicted']]\n",
    "\n",
    "    real = df_chi_2['dsigma_dOmega'].apply(lambda x: np.round(x, 6)).values\n",
    "    theory = df_chi_2['dsigma_dOmega_theory'].apply(lambda x: np.round(x, 6)).values\n",
    "    preds = df_chi_2['dsigma_dOmega_predicted'].apply(lambda x: np.round(x, 6)).values\n",
    "\n",
    "    stat_theory_chi, p_value_theory_chi = np.round(chisquare(real, np.sum(real)/np.sum(theory)*theory), 3)\n",
    "    stat_preds_chi, p_value_preds_chi = np.round(chisquare(real, np.sum(real)/np.sum(preds)*preds), 3)\n",
    "\n",
    "    stat_theory_ks, p_value_theory_ks = np.round(kstest(real, theory), 2)\n",
    "    stat_preds_ks, p_value_preds_ks = np.round(kstest(real, preds), 2)\n",
    "\n",
    "    plt.figure(figsize=(22, 6), dpi=80)\n",
    "    plt.plot(phi_theory, \n",
    "             dsigma_dOmega_theory, \n",
    "             label=f'fitted, chi^2 = {stat_theory_chi}, p_value = {p_value_theory_chi}, ks = {stat_theory_ks}, p_value = {p_value_theory_ks}')\n",
    "    plt.plot(df_example_set_for_prediction.phi, \n",
    "             dsigma_dOmega_predicted, \n",
    "             color='green',\n",
    "             label=f'predicted; chi^2 = {stat_preds_chi}, p_value = {p_value_preds_chi}, ks = {stat_preds_ks}, p_value = {p_value_preds_ks}')\n",
    "    plt.scatter(x=df_example_set.phi, \n",
    "                y=df_example_set.dsigma_dOmega,\n",
    "                color='red', marker='*', label=f\"real_data with params Ebeam: {E_beam}, W: {W}, Q2: {Q2}, cos_theta: {cos_theta}\")\n",
    "    plt.errorbar(x=df_example_set.phi,\n",
    "                 y=df_example_set.dsigma_dOmega,\n",
    "                 yerr=df_example_set.error,\n",
    "                 color='red',\n",
    "                 fmt='o')\n",
    "\n",
    "    plt.xlabel(\"phi: rad\", fontsize=\"20\")\n",
    "    plt.ylabel(\"dsigma_dOmega: barn\", fontsize=\"20\")\n",
    "    \n",
    "    plt.legend(loc =\"upper right\", fontsize=\"15\")\n",
    "    plt.savefig(f'./check_screenshots/E_beam={E_beam}/Q2={Q2}/W={W}/E_beam={E_beam}_Q2={Q2}_W={W}_cos_theta={cos_theta}.png')\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37b88315",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T23:42:44.942449Z",
     "start_time": "2024-03-06T23:42:44.926549Z"
    }
   },
   "outputs": [],
   "source": [
    "E_beam = 5.499\n",
    "\n",
    "for Q2 in tqdm.tqdm(np.sort(df[df.Ebeam == E_beam].Q2.unique())):\n",
    "    # os.makedirs(f\"./check_screenshots/E_beam={E_beam}/Q2={Q2}\")\n",
    "    for W in tqdm.tqdm([1.23, 1.53, 1.71, 1.95]):\n",
    "        # os.makedirs(f\"./check_screenshots/E_beam={E_beam}/Q2={Q2}/W={W}\")\n",
    "        for cos_theta in [-0.9,-0.8,-0.7,-0.6,-0.5,-0.4,-0.3,-0.2,-0.1,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "            try:\n",
    "                cross_sections_check(df, E_beam, W, Q2, cos_theta)\n",
    "            except:\n",
    "                print(E_beam, W, Q2, cos_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Structure functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f205d33c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-02-15T00:10:10.727463Z",
     "start_time": "2024-02-15T00:09:44.345085Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 221/221 [00:16<00:00, 13.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# df_grid\n",
    "Ebeam = 5.754\n",
    "step_W = 0.005\n",
    "step_Q2 = 0.1\n",
    "step_cos_theta = 0.1\n",
    "step_phi = 0.05\n",
    "\n",
    "\n",
    "data_grid = []\n",
    "for W in tqdm.tqdm(np.arange(1.1, 2.2 + step_W, step_W)):\n",
    "    for Q2 in np.arange(1.6, 4.3 + step_Q2, step_Q2):\n",
    "         for cos_theta in np.arange(-1, 1+step_cos_theta, step_cos_theta):\n",
    "                for phi in np.arange(0, 2*np.pi, step_phi):\n",
    "                    data_grid.append([Ebeam,\n",
    "                                      W,\n",
    "                                      Q2,\n",
    "                                      cos_theta,\n",
    "                                      phi])\n",
    "\n",
    "df_grid = pd.DataFrame(data_grid)\n",
    "df_grid.columns = ['Ebeam', 'W', 'Q2', 'cos_theta', 'phi']\n",
    "\n",
    "\n",
    "df_grid.W = np.round(df_grid.W, 3)\n",
    "df_grid.Q2 = np.round(df_grid.Q2, 3)\n",
    "df_grid.cos_theta = np.round(df_grid.cos_theta, 3)\n",
    "df_grid.phi = np.round(df_grid.phi, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
